{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77f2329b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/surya/Documents/sky/starburst/starburst/utils\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "'''\n",
    "sys.path.append('/Users/suryaven/Documents/personal/sky/skyburst')\n",
    "sys.path.append('/Users/suryaven/Documents/personal/sky/starburst/')\n",
    "sys.path.append('/Users/suryaven/Documents/personal/sky/starburst/starburst/utils')\n",
    "'''\n",
    "# TODO: Generalize differences between sky laptop and personal latop paths\n",
    "sys.path.append('/Users/surya/Documents/sky/skyburst/')\n",
    "sys.path.append('/Users/surya/Documents/sky/starburst/')\n",
    "sys.path.append('/Users/surya/Documents/sky/starburst/utils')\n",
    "\n",
    "import starburst\n",
    "import skyburst\n",
    "from starburst import utils\n",
    "import log_jobs\n",
    "import submit_jobs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import time \n",
    "import copy \n",
    "from collections import OrderedDict \n",
    "import math\n",
    "import heapq \n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26235ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<' not supported between instances of 'NoneType' and 'NoneType'\n"
     ]
    }
   ],
   "source": [
    "LOGS = {\n",
    "    \"05_01_2023\": 1682925843,\n",
    "    \"05_02_2023\": 1683099273,\n",
    "    \"05_03_2023\": 1683132152,\n",
    "    \"05_03_2023_2\": 1683173965,\n",
    "    \"05_04_2023_1\": 1683184792, \n",
    "    \"05_04_2023_2\": 1683196845,\n",
    "    \"05_04_2023_3\": 1683259533,\n",
    "    \"05_05_2023_4\": 1683343491,\n",
    "    \"05_06_2023_4\": 1683410859,\n",
    "    \"05_06_2023_5\": 1683418719,\n",
    "    \"05_06_2023_6\": 1683442154,\n",
    "    \"05_06_2023_7\": 1683452077,\n",
    "    \"05_07_2023_1\": 1683486242,\n",
    "    \"05_07_2023_2\": 1683489564,\n",
    "    \"05_07_2023_3\": 1683496107,\n",
    "    \"05_07_2023_4\": 1683497538,\n",
    "    \"1683498468\": 1683497538, \n",
    "    \"1683498857\": 1683498857,\n",
    "    \"1683499283\": 1683499283,\n",
    "    \"1683528723\": 1683528723, # Fixed JCT values\n",
    "    \"1683534589\": 1683534589, # Large sweep with greater arrival rates\n",
    "    \"1683607638\": 1683607638, # Modified arrival rate values to match simulator\n",
    "    \"1683625643\": 1683625643, # Policy waits until cluster state is updated\n",
    "    \"1683627780\": 1683627780, # Policy waits until cluster state and running pods are updated\n",
    "    \"1683680278\": 1683680278, # Sweep with uniform wait (4 sec) and constant timeout (3 sec)\n",
    "    \"1683705558\": 1683705558, # 30 second inter arrival time and 5 second job time\n",
    "    \"1683707012\": 1683707012, # 30 second inter arrival time and 5 second job time (ROUND 2)\n",
    "    \"1683757260\": 1683757260, # 30 second inter arrival time and 5 second job time (ROUND 3)\n",
    "    \"1683758384\": 1683758384, # 5 second inter arrival time and 5 second job time (ROUND 3)\n",
    "    \"1683759834\": 1683759834, # 5 second arrival 5 second job 1 second wait\n",
    "}\n",
    "\n",
    "logs = LOGS[\"1683759834\"]\n",
    "\n",
    "log_jobs.pull_vm_scheduler_logs(event_number=logs, force=True)\n",
    "jobs_df = log_jobs.retrieve_df(event_number=logs, avoid_congestion=False)\n",
    "jobs_df = jobs_df.assign(gpus_per_node=jobs_df['cpus_per_node'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90f8fc02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allocated_gpus</th>\n",
       "      <th>arrival</th>\n",
       "      <th>arrival_rate</th>\n",
       "      <th>arrival_rate_sweep</th>\n",
       "      <th>batch_time</th>\n",
       "      <th>batch_time_sweep</th>\n",
       "      <th>cloud_cluster_nodes</th>\n",
       "      <th>cloud_cluster_nodes_sweep</th>\n",
       "      <th>cloud_cpu_per_node</th>\n",
       "      <th>cloud_cpu_per_node_sweep</th>\n",
       "      <th>cluster_size</th>\n",
       "      <th>cluster_size_sweep</th>\n",
       "      <th>cpu_dist</th>\n",
       "      <th>cpu_dist_sweep</th>\n",
       "      <th>cpu_sizes</th>\n",
       "      <th>cpu_sizes_sweep</th>\n",
       "      <th>cpus</th>\n",
       "      <th>cpus_per_node</th>\n",
       "      <th>cpus_per_node_sweep</th>\n",
       "      <th>fixed_values</th>\n",
       "      <th>gpu_dist</th>\n",
       "      <th>gpu_dist_sweep</th>\n",
       "      <th>gpu_sizes</th>\n",
       "      <th>gpu_sizes_sweep</th>\n",
       "      <th>idx</th>\n",
       "      <th>instance_type</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_duration_sweep</th>\n",
       "      <th>memory_dict</th>\n",
       "      <th>memory_dict_sweep</th>\n",
       "      <th>memory_sizes</th>\n",
       "      <th>memory_sizes_sweep</th>\n",
       "      <th>node</th>\n",
       "      <th>node_index</th>\n",
       "      <th>num_gpus</th>\n",
       "      <th>random_seed</th>\n",
       "      <th>random_seed_sweep</th>\n",
       "      <th>runtime</th>\n",
       "      <th>start</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>time_constrained</th>\n",
       "      <th>time_constrained_sweep</th>\n",
       "      <th>time_out</th>\n",
       "      <th>time_out_sweep</th>\n",
       "      <th>total_jobs</th>\n",
       "      <th>total_jobs_sweep</th>\n",
       "      <th>uniform_arrival</th>\n",
       "      <th>uniform_arrival_sweep</th>\n",
       "      <th>uniform_submission</th>\n",
       "      <th>uniform_submission_sweep</th>\n",
       "      <th>varying_values</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>wait_time_sweep</th>\n",
       "      <th>wait_times</th>\n",
       "      <th>waiting_policy</th>\n",
       "      <th>waiting_policy_sweep</th>\n",
       "      <th>gpus_per_node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{1: []}, {0: []}, {3: []}, {0: []}, {1: []}, ...</td>\n",
       "      <td>[7.240361928939819, 7.240361928939819, 14.2403...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.6, 0.25, 0.15]</td>\n",
       "      <td>[0.6, 0.25, 0.15]</td>\n",
       "      <td>[1, 2, 4]</td>\n",
       "      <td>[1, 2, 4]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 1, 1, 1, 4, 4, 4, 2, 2, 2, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>(batch_time, mean_duration, waiting_policy, cp...</td>\n",
       "      <td>[0, 0.2, 0.2, 0.2, 0.2, 0.2]</td>\n",
       "      <td>[0, 0.2, 0.2, 0.2, 0.2, 0.2]</td>\n",
       "      <td>[1, 2, 4, 8, 16, 32]</td>\n",
       "      <td>[1, 2, 4, 8, 16, 32]</td>\n",
       "      <td>[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, ...</td>\n",
       "      <td>[e2-standard-8, e2-standard-8, e2-standard-8, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.25, 0.25, 0.25, 0.25]</td>\n",
       "      <td>[0.25, 0.25, 0.25, 0.25]</td>\n",
       "      <td>[100, 500, 1000, 50000]</td>\n",
       "      <td>[100, 500, 1000, 50000]</td>\n",
       "      <td>[gke-starburst-cpu-workloads-04fa1bcf-b5bt, gk...</td>\n",
       "      <td>[1, 0, 3, 0, 1, 3, 0, 1, 3, 2, 0, 2, 0, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[7, 7, 8, 6, 6, 6, 20, 20, 20, 8, 8, 8, 3, 4, ...</td>\n",
       "      <td>[7.240361928939819, 7.240361928939819, 14.2403...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 10.176762580871582, 10.1767625...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>(cpu_dist, wait_time, arrival_rate)</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[7.240361928939819, 7.240361928939819, 14.2403...</td>\n",
       "      <td>fifo_wait</td>\n",
       "      <td>fifo_wait</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      allocated_gpus   \n",
       "1  [{1: []}, {0: []}, {3: []}, {0: []}, {1: []}, ...  \\\n",
       "\n",
       "                                             arrival arrival_rate   \n",
       "1  [7.240361928939819, 7.240361928939819, 14.2403...            1  \\\n",
       "\n",
       "  arrival_rate_sweep batch_time batch_time_sweep cloud_cluster_nodes   \n",
       "1                  1        180              180                   4  \\\n",
       "\n",
       "  cloud_cluster_nodes_sweep cloud_cpu_per_node cloud_cpu_per_node_sweep   \n",
       "1                         4                  8                        8  \\\n",
       "\n",
       "  cluster_size cluster_size_sweep           cpu_dist     cpu_dist_sweep   \n",
       "1            4                  4  [0.6, 0.25, 0.15]  [0.6, 0.25, 0.15]  \\\n",
       "\n",
       "   cpu_sizes cpu_sizes_sweep   \n",
       "1  [1, 2, 4]       [1, 2, 4]  \\\n",
       "\n",
       "                                                cpus cpus_per_node   \n",
       "1  [2, 2, 2, 2, 2, 2, 1, 1, 1, 4, 4, 4, 2, 2, 2, ...             8  \\\n",
       "\n",
       "  cpus_per_node_sweep                                       fixed_values   \n",
       "1                   8  (batch_time, mean_duration, waiting_policy, cp...  \\\n",
       "\n",
       "                       gpu_dist                gpu_dist_sweep   \n",
       "1  [0, 0.2, 0.2, 0.2, 0.2, 0.2]  [0, 0.2, 0.2, 0.2, 0.2, 0.2]  \\\n",
       "\n",
       "              gpu_sizes       gpu_sizes_sweep   \n",
       "1  [1, 2, 4, 8, 16, 32]  [1, 2, 4, 8, 16, 32]  \\\n",
       "\n",
       "                                                 idx   \n",
       "1  [0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, ...  \\\n",
       "\n",
       "                                       instance_type mean_duration   \n",
       "1  [e2-standard-8, e2-standard-8, e2-standard-8, ...             5  \\\n",
       "\n",
       "  mean_duration_sweep               memory_dict         memory_dict_sweep   \n",
       "1                   5  [0.25, 0.25, 0.25, 0.25]  [0.25, 0.25, 0.25, 0.25]  \\\n",
       "\n",
       "              memory_sizes       memory_sizes_sweep   \n",
       "1  [100, 500, 1000, 50000]  [100, 500, 1000, 50000]  \\\n",
       "\n",
       "                                                node   \n",
       "1  [gke-starburst-cpu-workloads-04fa1bcf-b5bt, gk...  \\\n",
       "\n",
       "                                          node_index   \n",
       "1  [1, 0, 3, 0, 1, 3, 0, 1, 3, 2, 0, 2, 0, 1, 1, ...  \\\n",
       "\n",
       "                                            num_gpus random_seed   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...           0  \\\n",
       "\n",
       "  random_seed_sweep                                            runtime   \n",
       "1                 0  [7, 7, 8, 6, 6, 6, 20, 20, 20, 8, 8, 8, 3, 4, ...  \\\n",
       "\n",
       "                                               start   \n",
       "1  [7.240361928939819, 7.240361928939819, 14.2403...  \\\n",
       "\n",
       "                                     submission_time time_constrained   \n",
       "1  [0.0, 0.0, 0.0, 10.176762580871582, 10.1767625...             True  \\\n",
       "\n",
       "  time_constrained_sweep time_out time_out_sweep total_jobs total_jobs_sweep   \n",
       "1                   True        5              5        100              100  \\\n",
       "\n",
       "  uniform_arrival uniform_arrival_sweep uniform_submission   \n",
       "1              10                    10               True  \\\n",
       "\n",
       "  uniform_submission_sweep                       varying_values wait_time   \n",
       "1                     True  (cpu_dist, wait_time, arrival_rate)         5  \\\n",
       "\n",
       "  wait_time_sweep                                         wait_times   \n",
       "1               5  [7.240361928939819, 7.240361928939819, 14.2403...  \\\n",
       "\n",
       "  waiting_policy waiting_policy_sweep gpus_per_node  \n",
       "1      fifo_wait            fifo_wait             8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609cf673",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df['arrival_mask'] = jobs_df['start'].apply(lambda x: [0 if not i else 1 for i in x])\n",
    "jobs_df['onprem_mask'] = jobs_df['arrival_mask']\n",
    "\n",
    "# CLIP WAITS\n",
    "\n",
    "def cloud_wait_unclipped(row): \n",
    "    cloud_wait = [row['wait_times'][i] for i, n in enumerate(row['arrival_mask']) if n == 0]\n",
    "    return cloud_wait\n",
    "jobs_df['cloud_wait_unclipped'] = jobs_df.apply(cloud_wait_unclipped, axis=1)\n",
    "\n",
    "def clipped_wait(row): \n",
    "    k8s_scheduling_waiting_constant = 1 #wait_time_2\n",
    "    onprem_wait = [row['wait_times'][i] for i, n in enumerate(row['arrival_mask']) if n == 1]\n",
    "    cloud_wait = [k8s_scheduling_waiting_constant + row['wait_time'] for i, n in enumerate(row['arrival_mask']) if n == 0]\n",
    "    new_wait = onprem_wait + cloud_wait\n",
    "    return new_wait\n",
    "\n",
    "jobs_df['wait_times'] = jobs_df.apply(clipped_wait, axis=1)\n",
    "\n",
    "def cloud_wait(row): \n",
    "    k8s_scheduling_waiting_constant = 1 #wait_time_2\n",
    "    cloud_wait = [k8s_scheduling_waiting_constant + row['wait_time'] for i, n in enumerate(row['arrival_mask']) if n == 0]\n",
    "    return cloud_wait\n",
    "jobs_df['cloud_wait'] = jobs_df.apply(cloud_wait, axis=1)\n",
    "\n",
    "\n",
    "def onprem_wait(row): \n",
    "    k8s_scheduling_waiting_constant = 1 #wait_time_2\n",
    "    onprem_wait = [row['wait_times'][i] for i, n in enumerate(row['arrival_mask']) if n == 1]\n",
    "    return onprem_wait\n",
    "\n",
    "jobs_df['onprem_wait'] = jobs_df.apply(onprem_wait, axis=1)\n",
    "\n",
    "# COMPUTE METRICS\n",
    "\n",
    "jobs_df['avg_wait'] = jobs_df['wait_times'].apply(lambda x: sum(x)/len(x))\n",
    "jobs_df['avg_runtime'] = jobs_df['runtime'].apply(lambda x: sum(x)/len(x))\n",
    "\n",
    "def compute_total_time(row):\n",
    "    total_time = [row['wait_times'][i] + row['runtime'][i] for i in range(len(row['wait_times']))]\n",
    "    return total_time\n",
    "\n",
    "jobs_df['total_time'] = jobs_df.apply(compute_total_time, axis=1)\n",
    "\n",
    "def compute_completion_time(row):\n",
    "    completion_time = [row['total_time'][i] + row['submission_time'][i] for i in range(len(row['wait_times']))]\n",
    "    return completion_time\n",
    "\n",
    "jobs_df['completion_time'] = jobs_df.apply(compute_completion_time, axis=1)\n",
    "jobs_df['avg_jct'] = jobs_df['total_time'].apply(lambda x: sum(x)/len(x))\n",
    "\n",
    "def compute_cluster_utilization(row):\n",
    "    surface_area = [row['runtime'][i] * row['cpus'][i] for i in range(len(row['runtime']))]\n",
    "    utilized_surface_area = sum(surface_area)\n",
    "    total_surface_area = (max(row['completion_time']) - min(row['submission_time'])) * (row['cpus_per_node'] * row['cluster_size'])\n",
    "    cluster_utilization = utilized_surface_area/total_surface_area\n",
    "    return cluster_utilization\n",
    "\n",
    "jobs_df['cluster_utilization'] = jobs_df.apply(compute_cluster_utilization, axis=1)\n",
    "\n",
    "def compute_system_utilization(row):\n",
    "    # TODO: Compute this value correctly\n",
    "    return system_utilization\n",
    "\n",
    "#jobs_df['cluster_utilization'] = jobs_df.apply(compute_cluster_utilization, axis=1)\n",
    "\n",
    "GCP_PRICES = {\n",
    "    \"e2-medium\": 0.038795,\n",
    "    \"e2-standard-8\": 0.31036,\n",
    "    \"unknown\": 0.038795,\n",
    "}\n",
    "\n",
    "def compute_total_cost(row):\n",
    "    # TODO: Compute this value correctly\n",
    "    # Get all cloud runtimes + submit \n",
    "    total_time = [row['runtime'][i] * i * GCP_PRICES[row['instance_type']] for i in range(len(row['onprem_mask']))]\n",
    "    return system_utilization\n",
    "\n",
    "jobs_df['total_cloud_cost'] = jobs_df.apply(compute_cluster_utilization, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acf95a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c7c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobs_df.filter(['arrival_rate', 'total_cloud_cost', 'wait_time', 'avg_jct'])\n",
    "#jobs_df.filter(['waiting_policy', 'wait_time', 'wait_times', 'arrival', 'start', 'submission_time', 'arrival_rate', 'arrival_mask'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9c7931",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def wait_time_histograms(row):\n",
    "    \"\"\"Plots waiting time for onprem, cloud, and cloud clipped\"\"\"\n",
    "    #import pdb; pdb.set_trace()\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(12,3)) \n",
    "    \n",
    "    axs[0].set_title(\"ONPREM \" + \"wait \" + str(row['wait_time']) +  \" arr \" + str(row['arrival_rate']), fontsize=10)\n",
    "    axs[0].hist(row['onprem_wait'])\n",
    "    if row['onprem_wait'] != []:\n",
    "        average = sum(row['onprem_wait'])/len(row['onprem_wait'])\n",
    "        axs[0].axvline(average, color='r', linewidth=0.5)\n",
    "\n",
    "    axs[1].set_title(\"CLOUD \" + \"wait \" + str(row['wait_time']) +  \" arr \" + str(row['arrival_rate']), fontsize=10)\n",
    "    axs[1].hist(row['cloud_wait'])\n",
    "      \n",
    "    axs[2].set_title(\"CLOUD UNCLIPPED \" + \"wait \" + str(row['wait_time']) +  \" arr \" + str(row['arrival_rate']), fontsize=10)\n",
    "    axs[2].hist(row['cloud_wait_unclipped'])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "jobs_df.apply(wait_time_histograms, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ce0dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55400294",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cpu_index_mapping(jobs=None, gpus_per_node=8):\n",
    "    '''\n",
    "    Implement greedly algorithm with heap to place cpu jobs to free cpu indices\n",
    "    \n",
    "    (1) Add all jobs to queue, then greedily assign indicies \n",
    "    (2) Have priority queue for each node with \"Free indices\" sorted by index number \n",
    "    (3) Iterate over all start times \n",
    "\n",
    "    TODO: Fix 1-off CPU index error \n",
    "    TODO: Don't let any job_idx values to be -1, and ensure it starts at node 1\n",
    "    TODO: Verify allocated_nodes\n",
    "    TODO: Determine how parsing changes between http_info and default values \n",
    "    TODO: Verify arrival value is accurate\n",
    "    TODO: Create a list of times that include all arrival times and completion times in the same list in numerical order \n",
    "    '''\n",
    "    \n",
    "    GPUS_PER_NODE = gpus_per_node\n",
    "    allocated_nodes = jobs['node_index']\n",
    "    cpus = jobs['cpus']\n",
    "    nodes = set(allocated_nodes)\n",
    "    \n",
    "    node_jobs ={}\n",
    "    node_queues = {}\n",
    "    for node in nodes:\n",
    "        node_queues[node] = [i + 1 for i in range(GPUS_PER_NODE)]\n",
    "        node_jobs[node] = []\n",
    "\n",
    "    global_queue = [] # Queue sorted on end time -- earliest to latest end time\n",
    "    job_id_to_index = {} \n",
    "\n",
    "    for i in range(len(jobs['arrival'])):\n",
    "        #Remove values from queue\n",
    "        #import pdb; pdb.set_trace()\n",
    "        job_id = jobs['idx'][i]\n",
    "        job_id_to_index[job_id] = i\n",
    "        job_node = jobs['node_index'][i]\n",
    "        job_cpu_size = jobs['cpus'][i]\n",
    "        job_arrival = jobs['arrival'][i]\n",
    "        job_runtime = jobs['runtime'][i]\n",
    "        \n",
    "        while global_queue and global_queue[0][0] <= job_arrival: \n",
    "            end_time, end_job_id = heapq.heappop(global_queue)\n",
    "            released_index = job_id_to_index[end_job_id]\n",
    "            for released_node in jobs['allocated_gpus'][released_index]: \n",
    "                released_cpus = jobs['allocated_gpus'][released_index][released_node]\n",
    "                released_node_queue = node_queues[released_node]\n",
    "                try: \n",
    "                    node_jobs[released_node].remove(end_job_id)\n",
    "                except: \n",
    "                    #import pdb; pdb.set_trace()\n",
    "                    print(\"Job Id not found\")\n",
    "                    print(end_job_id)\n",
    "                    print(node_jobs[released_node])\n",
    "                    continue \n",
    "                for cpu in released_cpus: \n",
    "                    heapq.heappush(released_node_queue, cpu)\n",
    "\n",
    "        heapq.heappush(global_queue, (job_arrival + job_runtime, job_id))\n",
    "        job_allocated_cpus = []\n",
    "        node_queue = node_queues[job_node]\n",
    "        node_jobs[job_node].append(job_id)\n",
    "        \n",
    "        try: \n",
    "            for j in range(job_cpu_size): \n",
    "                cpu_index = heapq.heappop(node_queue)\n",
    "                job_allocated_cpus.append(cpu_index)\n",
    "        except:\n",
    "            print(\"not enough cpus to fit jobs\")\n",
    "            print(node_queue)\n",
    "            print(job_allocated_cpus)\n",
    "            \n",
    "        jobs['allocated_gpus'][i] = {job_node: job_allocated_cpus}\n",
    "        #import pdb; pdb.set_trace()\n",
    "        \n",
    "    return jobs\n",
    "\n",
    "def generate_gantt_chart(row, gpus_per_node, ratio, scale):\n",
    "    '''\n",
    "    Create \"threads index\" that track CPU jobs running together\n",
    "    #TODO: Modify function to plot CPU jobs --> number of jobs concurrently running may exceed cpu count\n",
    "    #TODO: Plot color based on job start time and not job index\n",
    "    #TODO: Determine why jobs dissapaear when strings labels are used for nodes\n",
    "    #TODO: Label each row of jobs with the name of the node -- not just integers \n",
    "    '''\n",
    "    #import pdb; pdb.set_trace()\n",
    "    save=False; path=None; subplt=None; plt_index=None; tag=None; plot_sweep=False\n",
    "    varying_values = row['varying_values']\n",
    "    tag = \"\"\n",
    "    \n",
    "    for value in varying_values: \n",
    "        tag += str(row[value])\n",
    "        tag += \" | \"\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    GPUS_PER_NODE = row['cpus_per_node']\n",
    "    GPUS_PER_NODE = gpus_per_node\n",
    "    row = cpu_index_mapping(row, GPUS_PER_NODE)\n",
    "    #import pdb; pdb.set_trace()\n",
    "    \n",
    "    NUM_COLORS = len(row['idx']) + 5\n",
    "    cm = plt.get_cmap('gist_rainbow')\n",
    "    colors = [cm(1. * i / NUM_COLORS) for i in range(NUM_COLORS)]\n",
    "    \n",
    "    y_lim_min = 1000\n",
    "    y_lim_max = -1000\n",
    "    num_nodes = row['cluster_size'] + row['cloud_cluster_nodes']\n",
    "    \n",
    "    total_gpus = num_nodes * GPUS_PER_NODE #GPUs equivalent to CPUs\n",
    "    segment_height_list = {}\n",
    "    gpu_indices = {}\n",
    "    node_name = \"\"\n",
    "    try: \n",
    "        for j_idx in range(len(row['idx'])):\n",
    "            allocated_gpus = row['allocated_gpus'][j_idx]\n",
    "            segment = (row['arrival'][j_idx],\n",
    "                        row['arrival'][j_idx] + row['runtime'][j_idx], j_idx)\n",
    "\n",
    "            node_name = row['node'][j_idx]\n",
    "            for node_idx in allocated_gpus.keys():\n",
    "                for node_gpu_idx in allocated_gpus[node_idx]:\n",
    "                    gpu_idx = total_gpus - (GPUS_PER_NODE * node_idx + node_gpu_idx)\n",
    "                    gpu_indices[node_name] = [gpu_idx]\n",
    "                    y_lim_min = min(y_lim_min, gpu_idx - 8)#if gpu_idx > 0 else gpu_index - 8)\n",
    "                    y_lim_max = max(y_lim_max, gpu_idx + 8)\n",
    "                    \n",
    "                    plt.barh(gpu_idx,\n",
    "                                width=row['runtime'][j_idx],\n",
    "                                edgecolor='black',\n",
    "                                height=1.0,\n",
    "                                left=segment[0],\n",
    "                                align='edge',\n",
    "                                color=colors[row['idx'][j_idx]] if row['idx'][j_idx] < len(colors) else None,\n",
    "                                alpha = 0.5)    \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "\n",
    "    for i in range(total_gpus + 1):\n",
    "        multiplier = math.ceil(num_nodes / 32)\n",
    "        if (i + 1) % GPUS_PER_NODE == 1:\n",
    "            plt.axhline(y=i + 1, linewidth=0.75 / multiplier, color='black')\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    max_arrival = max(row['arrival'])\n",
    "    completions = [row['arrival'][i] + row['runtime'][i] for i in range(len(row['arrival']))]\n",
    "    max_completion = max(completions)\n",
    "\n",
    "    x_lim_max = max_completion\n",
    "    last_job_time = max(row['completion_time'])    \n",
    "    dim=(y_lim_min, y_lim_max, 0, last_job_time)\n",
    "    bottom, top, left, right = dim\n",
    "    plt.ylim(bottom=bottom, top=top)\n",
    "    plt.xlim(left=left, right=right)\n",
    "    plt.axvline(x=max_arrival, color='brown', linewidth=0.75)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Nodes ')\n",
    "    plt.title(str(tag))\n",
    "\n",
    "    gpu_labels = sorted([(v, k) for k, v in gpu_indices.items()])\n",
    "    ticks = [label[0] for label in gpu_labels]\n",
    "    ticks = np.array(ticks)\n",
    "    ticks = ticks.flatten()\n",
    "    labels = [label[1] for label in gpu_labels]\n",
    "    labels = np.array(labels)\n",
    "    labels = labels.flatten()\n",
    "    plt.yticks(ticks)\n",
    "    ax.set_yticklabels(labels)\n",
    "    \n",
    "    if save:\n",
    "        if path: \n",
    "            plt.savefig(path)\n",
    "            plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "gpus_per_node = 8\n",
    "ratio = (1, 1)\n",
    "scale = 1\n",
    "\n",
    "jobs_df.apply(generate_gantt_chart, axis=1, args=(gpus_per_node, ratio, scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2baf853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_plotting_setting(ax):\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    ax.grid(True, which='both')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(True)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    #ax.tick_params(bottom=False, left=False)\n",
    "    ax.tick_params(bottom=True, left=False)\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "label_dict = {\n",
    "    'avg_jct': 'Avg. JCT (hr)',\n",
    "    'cost_mult': '% Cost Savings\\nover No Wait',\n",
    "    'cost_diff': 'Cost Savings\\nover No Wait',\n",
    "    'cluster_size': 'Cluster Size (# Nodes)',\n",
    "    'norm_system_utilization': 'System Utilization',\n",
    "    'system_utilization': 'System Utilization',\n",
    "    'cluster_utilization': 'Cluster Utilization',\n",
    "    'total_cloud_cost': 'Cloud Cost',\n",
    "    'arrival_rate': 'Arrival Rate',\n",
    "}\n",
    "\n",
    "legend_dict = {\n",
    "    'constant': 'Constant',\n",
    "    'linear_runtime': 'Runtime',\n",
    "    'linear_cost': 'Cost',\n",
    "    'zero': 'No Wait',\n",
    "    'linear_runtime_filter_cpu': 'Runtime-Preempt-CPU'\n",
    "}\n",
    "\n",
    "def join_baseline(df, \n",
    "                          x_axis: str,\n",
    "                          y_axis: list = ['cost_mult', 'avg_jct'],\n",
    "                          df_filter: dict = {},\n",
    "                          baseline_filter: dict={'waiting_policy': 'zero',},\n",
    "                          groupby_values=['waiting_policy', 'waiting_factor'],\n",
    "                          normalize_x_axis=False):\n",
    "    if isinstance(y_axis, str):\n",
    "        y_axis = [y_axis]\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=len(y_axis), figsize=(5*len(y_axis), 3.5))\n",
    "    \n",
    "    for k,v in df_filter.items():\n",
    "        df = df[df[k]==v]\n",
    "       \n",
    "    baseline_df = df\n",
    "    for k,v in baseline_filter.items():\n",
    "        assert not isinstance(v, list)\n",
    "        baseline_df = baseline_df[baseline_df[k]==v]\n",
    "        #df = df[df[k]!=v]\n",
    "    diff_df = pd.merge(df, baseline_df, left_on=x_axis,right_on=x_axis)\n",
    "    return diff_df\n",
    "    \n",
    "def get_default(df, \n",
    "                          x_axis: str,\n",
    "                          y_axis: list = ['cost_mult', 'avg_jct'],\n",
    "                          df_filter: dict = {},\n",
    "                          baseline_filter: dict={'waiting_policy': 'zero',},\n",
    "                          groupby_values=['waiting_policy', 'waiting_factor'],\n",
    "                          normalize_x_axis=False):\n",
    "    if isinstance(y_axis, str):\n",
    "        y_axis = [y_axis]\n",
    "        \n",
    "    fig, axs = plt.subplots(nrows=1, ncols=len(y_axis), figsize=(5*len(y_axis), 3.5))\n",
    "    \n",
    "    for k,v in df_filter.items():\n",
    "        print(k)\n",
    "        print(v)\n",
    "        print(df[k])\n",
    "        #print(df[k]==v)\n",
    "        #df[k] = df[k].apply(lambda x: [0, 0, 0] if len(x) != 3 else x)\n",
    "        #print(df[k].eq(v))\n",
    "        \n",
    "        \n",
    "        mask = df[k].apply(lambda x: x == v)\n",
    "        print(mask)\n",
    "        if isinstance(v, list):\n",
    "            df = df[mask]\n",
    "            #df[k].eq(v)\n",
    "            #df[k] = df[k].apply(lambda x: [0, 0, 0] if len(x) != 3 else x)\n",
    "            #df = df[df[k].eq(v)]\n",
    "            \n",
    "        #df = df[df[k]==v]\n",
    "        \n",
    "    return df\n",
    "    \n",
    "def get_baseline(df, \n",
    "                          x_axis: str,\n",
    "                          y_axis: list = ['cost_mult', 'avg_jct'],\n",
    "                          df_filter: dict = {},\n",
    "                          baseline_filter: dict={'waiting_policy': 'zero',},\n",
    "                          groupby_values=['waiting_policy', 'waiting_factor'],\n",
    "                          normalize_x_axis=False):\n",
    "    if isinstance(y_axis, str):\n",
    "        y_axis = [y_axis]\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=len(y_axis), figsize=(5*len(y_axis), 3.5))\n",
    "    \n",
    "    for k,v in df_filter.items():        \n",
    "        mask = df[k].apply(lambda x: x == v)\n",
    "        if isinstance(v, list):\n",
    "            df = df[mask]\n",
    "    \n",
    "    baseline_df = df\n",
    "    \n",
    "    for k,v in baseline_filter.items():\n",
    "        #assert not isinstance(v, list)\n",
    "        #baseline_df = baseline_df[baseline_df[k]==v]\n",
    "        mask = baseline_df[k].apply(lambda x: x == v)\n",
    "        baseline_df = baseline_df[mask]\n",
    "        baseline_df = df[mask]\n",
    "        #print(mask)\n",
    "        #if isinstance(v, list):\n",
    "            #df[k].eq(v)\n",
    "            #df[k] = df[k].apply(lambda x: [0, 0, 0] if len(x) != 3 else x)\n",
    "            #df = df[df[k].eq(v)]\n",
    "            \n",
    "        #df = df[df[k]!=v]\n",
    "    \n",
    "    diff_df = pd.merge(df, baseline_df, left_on=x_axis,right_on=x_axis)\n",
    "    \n",
    "    if normalize_x_axis:\n",
    "        if x_axis == 'cluster_size':\n",
    "            # Hardcoded in Philly trace, precomputed ahead of time\n",
    "            if df['dataset'].iloc[0] == 'philly':\n",
    "                total_job_volume = 1155998.77277777\n",
    "                job_makespan = 2559.3205555555555\n",
    "            elif df['dataset'].iloc[0] == 'helios':\n",
    "                total_job_volume = 1853756.1241666232\n",
    "                job_makespan = 4651.911388888889\n",
    "            diff_df['norm_system_utilization'] = total_job_volume/(job_makespan*diff_df['cluster_size']*df['gpus_per_node'].iloc[0])\n",
    "            x_axis = 'norm_system_utilization'\n",
    "        elif x_axis == 'arrival_rate':\n",
    "            avg_job_volume_rate = diff_df['arrival_rate'] * np.mean(df['num_gpus'].iloc[0]* df['runtime'].iloc[0])\n",
    "            #print(avg_job_volume_rate)\n",
    "            #print(df['cluster_size'].iloc[0])\n",
    "            #print(df['gpus_per_node'].iloc[0])\n",
    "            #print(df['cluster_size'].iloc[0]*df['gpus_per_node'].iloc[0])\n",
    "            diff_df['norm_system_utilization'] = avg_job_volume_rate/(df['cluster_size'].iloc[0]*df['gpus_per_node'].iloc[0])\n",
    "            x_axis = 'norm_system_utilization'\n",
    "        \n",
    "    #return baseline_df\n",
    "    return diff_df\n",
    "\n",
    "def simulator_plotting_fn(df, \n",
    "                          x_axis: str,\n",
    "                          y_axis: list = ['cost_mult', 'avg_jct'],\n",
    "                          df_filter: dict = {},\n",
    "                          baseline_filter: dict={'waiting_policy': 'zero',},\n",
    "                          groupby_values=['waiting_policy', 'waiting_factor'],\n",
    "                          normalize_x_axis=False,\n",
    "                          fig_ratio=(5, 3.5)):\n",
    "    if isinstance(y_axis, str):\n",
    "        y_axis = [y_axis]\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=len(y_axis), figsize=(fig_ratio[0]*len(y_axis), fig_ratio[1]))\n",
    "    \n",
    "    if len(y_axis) == 1: \n",
    "        if not isinstance(axs, list):\n",
    "            axs = [axs]\n",
    "    print(axs)\n",
    "    #time.sleep(1000)\n",
    "    \n",
    "    '''\n",
    "    for k,v in df_filter.items():\n",
    "        if isinstance(v, list):\n",
    "            df = df[df[k]==v]\n",
    "    '''\n",
    "\n",
    "    for k,v in df_filter.items():        \n",
    "        mask = df[k].apply(lambda x: x == v)\n",
    "        if isinstance(v, list):\n",
    "            df = df[mask]\n",
    "       \n",
    "    baseline_df = df\n",
    "    \n",
    "    for k,v in baseline_filter.items():\n",
    "        assert not isinstance(v, list)\n",
    "        baseline_df = baseline_df[baseline_df[k]==v]\n",
    "        #df = df[df[k]!=v]\n",
    "        \n",
    "    diff_df = pd.merge(df, baseline_df, left_on=x_axis,right_on=x_axis)\n",
    "    \n",
    "    if normalize_x_axis:\n",
    "        if x_axis == 'cluster_size':\n",
    "            # Hardcoded in Philly trace, precomputed ahead of time\n",
    "            if df['dataset'].iloc[0] == 'philly':\n",
    "                total_job_volume = 1155998.77277777\n",
    "                job_makespan = 2559.3205555555555\n",
    "            elif df['dataset'].iloc[0] == 'helios':\n",
    "                total_job_volume = 1853756.1241666232\n",
    "                job_makespan = 4651.911388888889\n",
    "            diff_df['norm_system_utilization'] = total_job_volume/(job_makespan*diff_df['cluster_size']*df['gpus_per_node'].iloc[0])\n",
    "            x_axis = 'norm_system_utilization'\n",
    "        elif x_axis == 'arrival_rate':\n",
    "            # Volume rate => runtime must be in either hours or seconds \n",
    "            '''\n",
    "            Verification: \n",
    "            - Arrival_Rate = VERIFIED ~ error \n",
    "            - Num_gpus = Verified\n",
    "            - Runtime = Verified \n",
    "            '''\n",
    "            avg_job_volume_rate = diff_df['arrival_rate'] * np.mean(df['num_gpus'].iloc[0]* df['runtime'].iloc[0])\n",
    "            df['z_mean_runtime'] = np.mean(df['num_gpus'].iloc[0]* df['runtime'].iloc[0])\n",
    "            df['z_cluster_nodes'] = (df['cluster_size'].iloc[0]*df['gpus_per_node'].iloc[0])\n",
    "            #print(avg_job_volume_rate)\n",
    "            #print(df['cluster_size'].iloc[0])\n",
    "            #print(df['gpus_per_node'].iloc[0])\n",
    "            #print(df['cluster_size'].iloc[0]*df['gpus_per_node'].iloc[0])\n",
    "            diff_df['norm_system_utilization'] = avg_job_volume_rate/(df['cluster_size'].iloc[0]*df['gpus_per_node'].iloc[0])\n",
    "            x_axis = 'norm_system_utilization'\n",
    "    \n",
    "    #print(df)\n",
    "    \n",
    "    def cost_multiplier(row):\n",
    "        baseline_cost = row['total_cloud_cost_y']\n",
    "        cost = row['total_cloud_cost_x']\n",
    "        if baseline_cost == 0 and cost==0:\n",
    "            return 0\n",
    "        elif baseline_cost <=10000:\n",
    "            # Small cloud cost for No wait\n",
    "            # Savings over small cloud cost is negligible for organizations.\n",
    "            return 0\n",
    "        elif baseline_cost == 0 and cost>0:\n",
    "            return 100\n",
    "        return 100* (1 - (cost/baseline_cost))\n",
    "    \n",
    "    def cost_difference(row):\n",
    "        baseline_cost = row['total_cloud_cost_y']\n",
    "        cost = row['total_cloud_cost_x']\n",
    "        return baseline_cost - cost\n",
    "    \n",
    "    diff_df['cost_mult'] = diff_df.apply(cost_multiplier, axis=1)\n",
    "    diff_df['cost_diff'] = diff_df.apply(cost_difference, axis=1)\n",
    "    groupby_values = [f'{g}_x' for g in groupby_values]\n",
    "    mod_y_axis = [f'{y}_x' if y!='cost_mult' and y!='cost_diff' else y for y in y_axis]\n",
    "    import itertools\n",
    "    markers = itertools.cycle(('v', '^','.', 'o', '*',',', '+',)) \n",
    "    for idx, (label, grp) in enumerate(diff_df.groupby(groupby_values)):\n",
    "        marker = next(markers)\n",
    "#         if 'waiting_policy' in groupby_values[0]:\n",
    "#             label = [legend_dict[label[0]]] + list(label[1:])\n",
    "#             print(label)\n",
    "        for ax_idx, ax in enumerate(axs):           \n",
    "            grp.plot(x = x_axis, y = mod_y_axis[ax_idx],ylabel=label_dict[y_axis[ax_idx]], \\\n",
    "                     xlabel=label_dict[x_axis], marker=marker, ax = ax, label = label, legend=None)\n",
    "    \n",
    "    \n",
    "    for ax in axs:\n",
    "        set_plotting_setting(ax)\n",
    "    #axs[1].set_xlim(right=36, left=20)\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(lines, labels, ncol=len(labels), \\\n",
    "               bbox_to_anchor=(0, 0.92, 1, 0.2),loc='upper center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e19a435",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aeaa69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddddb4b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: Add spec to increase plot size\n",
    "\n",
    "#dists = [[0.2, 0.4, 0.4], [0, 0.5, 0.5], [0, 0, 1]]\n",
    "dists = [[0.6, 0.25, 0.15]]#[[0, 0.5, 0.5]]\n",
    "scale = 4\n",
    "for dist in dists:\n",
    "    simulator_plotting_fn(jobs_df, x_axis='arrival_rate', \\\n",
    "                          y_axis=['avg_jct', 'cluster_utilization'],\\\n",
    "                          #['total_cloud_cost'], \n",
    "                          #['avg_jct'],\\\n",
    "                          #[avg_jct', 'total_cloud_cost'], \\\n",
    "                          df_filter={'cpu_dist': dist}, \n",
    "                          #baseline_filter= {'wait_time': 1.0}, \\\n",
    "                          #baseline_filter= {'waiting_policy': 'fifo_wait', 'wait_time': 0.0}, \\\n",
    "                          baseline_filter= {'waiting_policy': 'fifo_wait', 'wait_time': 2.5}, \\\n",
    "                          #baseline_filter= {'waiting_policy': 'fifo_wait', 'wait_time': 1.0}, \\\n",
    "                          #groupby_values=['waiting_policy', 'wait_time'], normalize_x_axis=True, \\\n",
    "                          groupby_values=['wait_time'], normalize_x_axis=True, \\\n",
    "                          fig_ratio=(5*scale, 3.5*scale))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51834ed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "default_df = get_default(jobs_df, x_axis='arrival_rate', y_axis=['avg_jct'], \\\n",
    "                           #df_filter={'cpu_dist': [0.2, 0.4, 0.4]}, \\\n",
    "                         #df_filter={'cpu_dist': [0.0, 0.5, 0.5]}, \\\n",
    "                         df_filter={'cpu_dist': [0.6, 0.25, 0.15]}, \\\n",
    "                          #df_filter={'wait_time': 1.0}, \\\n",
    "                      #baseline_filter= {'waiting_policy': 'fifo_wait', 'wait_time': 1.0}, \\\n",
    "                          #baseline_filter= {'waiting_policy': 'fifo_wait', 'wait_time': 0.0}, \\\n",
    "                         baseline_filter= {'waiting_policy': 'fifo_wait', 'wait_time': 0}, \\\n",
    "                           groupby_values=['waiting_policy'], normalize_x_axis=True)\n",
    "\n",
    "\n",
    "baseline_df = get_baseline(jobs_df, x_axis='arrival_rate', y_axis=['avg_jct'], \\\n",
    "                           #df_filter={'cpu_dist': [0.2, 0.4, 0.4]}, \\\n",
    "                           #df_filter={'cpu_dist': [0.0, 0.5, 0.5]}, \\\n",
    "                           df_filter={'cpu_dist': [0.6, 0.25, 0.15]},\n",
    "                      #baseline_filter= {'waiting_policy': 'fifo_wait', 'wait_time': 1.0}, \\\n",
    "                           baseline_filter= {'waiting_policy': 'fifo_wait', 'wait_time': 0}, \\\n",
    "                           groupby_values=['waiting_policy'], normalize_x_axis=True)\n",
    "\n",
    "\n",
    "merged_df = join_baseline(jobs_df, x_axis='arrival_rate', y_axis=['avg_jct', 'total_cloud_cost'], \\\n",
    "                          #baseline_filter= {'waiting_policy': 'fifo_wait', 'wait_time': 1.0}, \\\n",
    "                          baseline_filter= {'waiting_policy': 'fifo_wait', 'wait_time': 0}, \\\n",
    "                      groupby_values=['waiting_policy'], normalize_x_axis=True)\n",
    "default_df, baseline_df, merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823a83ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5462f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp = copy.deepcopy(sampled_jobs.DEFAULT_HYPERPARAMETERS)\n",
    "\n",
    "hyp['arrival_rate'] = 10\n",
    "hyp['batch_time'] = 600\n",
    "hyp['total_jobs'] = 5\n",
    "hyp['mean_duration'] = 60\n",
    "arrived_jobs, arrivals = sampled_jobs.generate_jobs(hyp)\n",
    "\n",
    "#print(arrived_jobs)\n",
    "#print(arrivals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af943386",
   "metadata": {},
   "outputs": [],
   "source": [
    "## HYPERPARAMETER\n",
    "'''\n",
    "Vary arrival rate\n",
    "    - CPU jobs for Philly/Helios\n",
    "        \n",
    "- Mimic GPU jobs ~ with CPU\n",
    "    - vary # jobs per minute \n",
    "    - test contant waiting for baseline\n",
    "    - 0(Baseline), 0.25, 0.5, 1 ratio of runtime for waiting policy \n",
    "        - \n",
    "    \n",
    "- Plot Cluster Utilization \n",
    "- Plot Cloud Cost \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14d548c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
