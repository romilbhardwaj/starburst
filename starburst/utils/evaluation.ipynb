{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77f2329b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/surya/starburst/starburst/utils\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "import sys\n",
    "import os\n",
    "path = os.getcwd()\n",
    "path += '/../../'\n",
    "sys.path.append(path)\n",
    "\n",
    "import starburst\n",
    "from starburst import utils\n",
    "import log_jobs\n",
    "import submit_jobs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import time \n",
    "import copy \n",
    "from collections import OrderedDict \n",
    "import math\n",
    "import heapq\n",
    "import re\n",
    "from IPython.display import display\n",
    "import itertools\n",
    "import pickle\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26235ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "VMS = {\n",
    "    \"05_01_2023\": 1682925843,\n",
    "    \"05_02_2023\": 1683099273,\n",
    "    \"05_03_2023\": 1683132152,\n",
    "    \"05_03_2023_2\": 1683173965,\n",
    "    \"05_04_2023_1\": 1683184792, \n",
    "    \"05_04_2023_2\": 1683196845,\n",
    "    \"05_04_2023_3\": 1683259533,\n",
    "    \"05_05_2023_4\": 1683343491,\n",
    "    \"05_06_2023_4\": 1683410859,\n",
    "    \"05_06_2023_5\": 1683418719,\n",
    "    \"05_06_2023_6\": 1683442154,\n",
    "    \"05_06_2023_7\": 1683452077,\n",
    "    \"05_07_2023_1\": 1683486242,\n",
    "    \"05_07_2023_2\": 1683489564,\n",
    "    \"05_07_2023_3\": 1683496107,\n",
    "    \"05_07_2023_4\": 1683497538,\n",
    "    \"1683498468\": 1683497538, \n",
    "    \"1683498857\": 1683498857,\n",
    "    \"1683499283\": 1683499283,\n",
    "    \"1683528723\": 1683528723, # Fixed JCT values\n",
    "    \"1683534589\": 1683534589, # Large sweep with greater arrival rates\n",
    "    \"1683607638\": 1683607638, # Modified arrival rate values to match simulator\n",
    "    \"1683625643\": 1683625643, # Policy waits until cluster state is updated\n",
    "    \"1683627780\": 1683627780, # Policy waits until cluster state and running pods are updated\n",
    "    \"1683680278\": 1683680278, # Sweep with uniform wait (4 sec) and constant timeout (3 sec)\n",
    "    \"1683705558\": 1683705558, # 30 second inter arrival time and 5 second job time\n",
    "    \"1683707012\": 1683707012, # 30 second inter arrival time and 5 second job time (ROUND 2)\n",
    "    \"1683757260\": 1683757260, # 30 second inter arrival time and 5 second job time (ROUND 3)\n",
    "    \"1683758384\": 1683758384, # 5 second inter arrival time and 5 second job time (ROUND 3)\n",
    "    \"1683759834\": 1683759834, # 5 second arrival 5 second job 1 second wait\n",
    "    \"1683939895\": 1683939895, \n",
    "    \"1683959890\": 1683959890, # Waiting until all jobs submitted\n",
    "    \"1683961793\": 1683961793, # Waiting until jobs submitted and relogging with poroper config second time\n",
    "    \"1683999940\": 1683999940, # Fixed unscheduled gpu pod error\n",
    "    \"1684025542\": 1684025542, # Resolved last job logging error\n",
    "    \"1684027483\": 1684027483, # Decreased interarrival times\n",
    "    \"1684034550\": 1684034550, # Replace gpu index with uuid\n",
    "    \"1684035873\": 1684035873, # Varying interarrival rate of gpu jobs\n",
    "    \"1684038713\": 1684038713, # Included GPUS per node value to sweep and fixed values [PLOTS WORK]\n",
    "    \"1684107011\": 1684107011, # Run with varying timeout values to test cost saving plots\n",
    "    \"1684127501\": 1684127501, # Higher range of arrival rates (from 3 arrival rates to 5 rates) \n",
    "    \"1684211347\": 1684211347, # Use loop_time instead of curr_time when comparing job wait_time\n",
    "    \"1684211782\": 1684211782, # Doesn't check if job on queue is less than timeout, when submitting on prem\n",
    "    \"1684214027\": 1684214027, # Dropped schedule tick from 1 to 0.1\n",
    "    \"1684219829\": 1684219829, # Fixed checking cluster state if job completed -- set to 0.5 sched tick\n",
    "    \"1684222781\": 1684222781, # Interarrival rate to 3 seconds \n",
    "    \"1684223508\": 1684223508, # Rerun 1684107011 log w/ 3 inter arrival and 10 wait\n",
    "    \"1684279856\": 1684279856, # Checks if previous job submitted has been scheduled to avoid onprem congestion\n",
    "    \"1684282049\": 1684282049, # Removes the 50 length limit from http_info +  Handles case when next job not found in the cluster yet -- moves onto next job in the meantime\n",
    "    \"1684282536\": 1684282536, # Removed 50 limit for both check cluster state and get if last job scheduled\n",
    "    \"1684283565\": 1684283565, # Handling tuple jobname and jobstatus error\n",
    "    \"1684295134\": 1684295134, # Read the logs\n",
    "    \"1684300887\": 1684300887, # Added loop time and dropped schedule tick event\n",
    "    \"1684301139\": 1684301139, # Removed Job Add Event\n",
    "    \"1684301369\": 1684301369, # Removed everything except process_queue\n",
    "    \"1684301655\": 1684301655, # No 0.5 pause within the event loop\n",
    "    \"1684307219\": 1684307219, # New VM\n",
    "    \"1684311915\": 1684311915, # Debugged new VM\n",
    "    \"1684312326\": 1684312326, # Loop time\n",
    "    \"1684312971\": 1684312971, # Process Queue and Event Queue Times\n",
    "    \"1684313238\": 1684313238, # Log time\n",
    "    \"1684313922\": 1684313922, # Queue Add Time\n",
    "    \"1684366876\": 1684366876, # Fixed interloop time to 1 second \n",
    "    \"1684368494\": 1684368494, # Fixed loop time between loops\n",
    "    \"1684369123\": 1684369123, # Rerun because jobs corrupted\n",
    "    \"1684371614\": 1684371614, # Tried to ensure all previous running jobs are deleted\n",
    "    \"1684380753\": 1684380753, # Sweep different wait time values\n",
    "    \"1684382045\": 1684382045, # Multi Node 8 GPU \n",
    "    \"1684397749\": 1684397749, # Removed regex for scheudled_node event\n",
    "    \"1684433340\": 1684433340, # Modified onprem submission conditional\n",
    "    \"1684445674\": 1684445674, # Event tracked in events.log\n",
    "    \"1684449505\": 1684449505, # Testing new gpu_index parsing code -- waiting till run finishes \n",
    "    \"1684452105\": 1684452105, # 60 jobs modified policy all onprem\n",
    "    \"1684452497\": 1684452497, # 360 jobs on prem\n",
    "    \"1684470801\": 1684470801, # New terminating conditions\n",
    "    \"1684471163\": 1684471163, # Added end variable loop\n",
    "    \"1684471393\": 1684471393, # Cloud spill new termination\n",
    "    \"1684471749\": 1684471749, # Large spillover \n",
    "    \"1684473449\": 1684473449, # Check cloud spill over policy only \n",
    "    \"1684475422\": 1684475422, # Cloud only with 4 gpus\n",
    "    \"1684477231\": 1684477231, # Cloud only with 4 gpus without setup script bug\n",
    "    \"1684478946\": 1684478946, # Spill over from cloud to onprem 4 nodes each -- constant wait 10 seconds\n",
    "    \"1684480072\": 1684480072, # Constant wait 30 seconds -- 4 onprem, 4 cloud, 60 second batch\n",
    "    \"1684480621\": 1684480621, # Constant wait 60 seconds -- 4 onprem, 4 cloud, 60 second batch \n",
    "    \"1684486650\": 1684486650, # Constant wait 5 seconds -- 4 onprem, 4 cloud, 60 second batch\n",
    "    \"1684487285\": 1684487285, # Wait 0, 1, 2 seocnds -- 4 onprem, 4 cloud, 60 second batch\n",
    "    \"1684489189\": 1684489189, # Wait 2, 3, 5, 10 seconds -- 30 second mean duration\n",
    "    \"1684532430\": 1684532430, # Sweep over different poicies \n",
    "    \"1684534781\": 1684534781, # Philly trace sweep \n",
    "    \"1684536405\": 1684536405, # Reduced uniform arrival \n",
    "    \"1684537269\": 1684537269, # 30 second average job duration\n",
    "    \"1684538298\": 1684538298, # Modified compute wait threshold\n",
    "    \"1684543740\": 1684543740, # Integrating chakra \n",
    "    \"1684545298\": 1684545298, # New node name\n",
    "    \"1684548233\": 1684548233, # Updated chakra and sweep of final jobs (starburst', 'compute_optimal', 'constant_optimal', 'constant')\n",
    "    \"1684609979\": 1684609979, # Working chakra, mnist with starburst\n",
    "    \"1684611837\": 1684611837, # Pending 4 gpu job error\n",
    "    \"1684621271\": 1684621271, # Removed cloud cluster\n",
    "    \"1684630465\": 1684630465, # Removed cloud cluster w/ modified logs\n",
    "    \"1684720040\": 2,\n",
    "    \"1684726518\": 2,\n",
    "    \"1684704725\": 1, # Real sweep of training jobs from Ryan\n",
    "    \"1684726518\": 2, \n",
    "    \"1684727264\": 2, \n",
    "    \"1684731034\": 2, # More jobs ~ 15 minutes each\n",
    "    \"1684755479\": 2, # overloaded sys util - 20 jobs/sec\n",
    "    \"1684754864\": 1, # high sys util - arrival 12 jobs/sec\n",
    "    \"1684795422\": 2, # overloaded sys util - 32 jobs/sec\n",
    "    \"1684795437\": 1, # high sys util - arrival 24 jobs/sec\n",
    "    \"1684804876\": 2, # overloaded with continous arrival time logs\n",
    "    \"1684804861\": 1, # high sys util with continous arrival time logs,\n",
    "    \"1684807867\": 2, # overloaded \n",
    "    \"1684808264\": 1, # high load\n",
    "    \"1684814611\": 2, # overloaded\n",
    "    \"1684814629\": 1, # high sys\n",
    "    \"1684825502\": 1, # high sys\n",
    "    \"1684842795\": 2, # Final experiment high sys util\n",
    "    \"1684842093\": 1, # Final experiment overloaded sys util # Poster data\n",
    "    \"1686798842\": 1, # CPU Sleep jobs \n",
    "    \"1687837800\": 1, # CPU Sleep jobs w/ simulated cloud logging\n",
    "}\n",
    "# TODO: Support both GPU and CPU (e.g. \"workload_type\")\n",
    "logs =  \"1687837800\"#\"1686798842\"#\"1684842093\"#\"1684842795\"#\"1686798842\"# \"1684842093\"#\"1686798842\" #\"1684842795\" ##\"1684842795\" #\"1684755479\" #\"1684754864\" #\"1684731034\" #LOGS[\"1684630465\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ea33d423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '../logs/archive/1687837800/events/1.json'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>job_type</th>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "      <td>sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image</th>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>setup_script</th>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform_arrival</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform_submission</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waiting_policy</th>\n",
       "      <td>fifo_wait</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy</th>\n",
       "      <td>constant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_constrained</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_size</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpus_per_node</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpus_per_node</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloud_cluster_nodes</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloud_cpu_per_node</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_seed</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_jobs</th>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_time</th>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wait_time</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_out</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_duration</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_rate</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_sizes</th>\n",
       "      <td>[1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_dist</th>\n",
       "      <td>[1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_sizes</th>\n",
       "      <td>[1, 2, 4, 8]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_dist</th>\n",
       "      <td>[0.7, 0.15, 0.1, 0.05]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>memory_sizes</th>\n",
       "      <td>[100, 500, 1000, 50000]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>memory_dict</th>\n",
       "      <td>[0.25, 0.25, 0.25, 0.25]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_names</th>\n",
       "      <td>[test]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_dist</th>\n",
       "      <td>[1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_new_cluster</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onprem_cluster</th>\n",
       "      <td>gke_sky-burst_us-central1-c_mluo-onprem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloud_cluster</th>\n",
       "      <td>gke_sky-burst_us-central1-c_mluo-cloud</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_workload</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spill_to_cloud</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onprem_only</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect_runtimes</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_real_workloads</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workload_type</th>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "      <td>cpu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sched_tick</th>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workload</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "      <td>{'gpu': 0, 'cpu': 1, 'memory': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_duration</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>31.139337</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>41.956107</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>31.925926</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submit_time</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>110</td>\n",
       "      <td>120</td>\n",
       "      <td>130</td>\n",
       "      <td>140</td>\n",
       "      <td>150</td>\n",
       "      <td>160</td>\n",
       "      <td>170</td>\n",
       "      <td>180</td>\n",
       "      <td>190</td>\n",
       "      <td>200</td>\n",
       "      <td>210</td>\n",
       "      <td>220</td>\n",
       "      <td>230</td>\n",
       "      <td>240</td>\n",
       "      <td>250</td>\n",
       "      <td>260</td>\n",
       "      <td>270</td>\n",
       "      <td>280</td>\n",
       "      <td>290</td>\n",
       "      <td>300</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scheduler_submit_time</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1687837813.950912</td>\n",
       "      <td>1687837823.947605</td>\n",
       "      <td>1687837833.950068</td>\n",
       "      <td>1687837843.947018</td>\n",
       "      <td>1687837853.952934</td>\n",
       "      <td>1687837863.949754</td>\n",
       "      <td>1687837873.942481</td>\n",
       "      <td>1687837883.945334</td>\n",
       "      <td>1687837893.944211</td>\n",
       "      <td>1687837903.949104</td>\n",
       "      <td>1687837913.949703</td>\n",
       "      <td>1687837923.950936</td>\n",
       "      <td>1687837933.946119</td>\n",
       "      <td>1687837943.947579</td>\n",
       "      <td>1687837953.946669</td>\n",
       "      <td>1687837963.945398</td>\n",
       "      <td>1687837973.94409</td>\n",
       "      <td>1687837983.945077</td>\n",
       "      <td>1687837994.012038</td>\n",
       "      <td>1687838004.03192</td>\n",
       "      <td>1687838013.984719</td>\n",
       "      <td>1687838023.94536</td>\n",
       "      <td>1687838033.948371</td>\n",
       "      <td>1687838044.12214</td>\n",
       "      <td>1687838054.121535</td>\n",
       "      <td>1687838064.186292</td>\n",
       "      <td>1687838074.165931</td>\n",
       "      <td>1687838084.243511</td>\n",
       "      <td>1687838093.94573</td>\n",
       "      <td>1687838103.939518</td>\n",
       "      <td>1687838113.941313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         hyperparameters   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                       10   \n",
       "uniform_submission                                                  True   \n",
       "waiting_policy                                                 fifo_wait   \n",
       "policy                                                          constant   \n",
       "time_constrained                                                    True   \n",
       "cluster_size                                                           2   \n",
       "cpus_per_node                                                          8   \n",
       "gpus_per_node                                                          8   \n",
       "cloud_cluster_nodes                                                    4   \n",
       "cloud_cpu_per_node                                                     8   \n",
       "random_seed                                                           13   \n",
       "total_jobs                                                           125   \n",
       "batch_time                                                           300   \n",
       "wait_time                                                             15   \n",
       "time_out                                                               5   \n",
       "mean_duration                                                         10   \n",
       "arrival_rate                                                          10   \n",
       "cpu_sizes                                                            [1]   \n",
       "cpu_dist                                                             [1]   \n",
       "gpu_sizes                                                   [1, 2, 4, 8]   \n",
       "gpu_dist                                          [0.7, 0.15, 0.1, 0.05]   \n",
       "memory_sizes                                     [100, 500, 1000, 50000]   \n",
       "memory_dict                                     [0.25, 0.25, 0.25, 0.25]   \n",
       "train_names                                                       [test]   \n",
       "train_dist                                                           [1]   \n",
       "use_new_cluster                                                     True   \n",
       "onprem_cluster                   gke_sky-burst_us-central1-c_mluo-onprem   \n",
       "cloud_cluster                     gke_sky-burst_us-central1-c_mluo-cloud   \n",
       "gpu_workload                                                       False   \n",
       "spill_to_cloud                                                     False   \n",
       "onprem_only                                                        False   \n",
       "collect_runtimes                                                   False   \n",
       "sample_real_workloads                                              False   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           0.1   \n",
       "workload                                                             NaN   \n",
       "job_duration                                                         NaN   \n",
       "submit_time                                                          NaN   \n",
       "scheduler_submit_time                                                NaN   \n",
       "\n",
       "                                                                       0   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                           10   \n",
       "scheduler_submit_time                                  1687837813.950912   \n",
       "\n",
       "                                                                       1   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                           20   \n",
       "scheduler_submit_time                                  1687837823.947605   \n",
       "\n",
       "                                                                       2   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                           30   \n",
       "scheduler_submit_time                                  1687837833.950068   \n",
       "\n",
       "                                                                       3   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                           40   \n",
       "scheduler_submit_time                                  1687837843.947018   \n",
       "\n",
       "                                                                       4   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                           50   \n",
       "scheduler_submit_time                                  1687837853.952934   \n",
       "\n",
       "                                                                       5   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                           60   \n",
       "scheduler_submit_time                                  1687837863.949754   \n",
       "\n",
       "                                                                       6   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                           70   \n",
       "scheduler_submit_time                                  1687837873.942481   \n",
       "\n",
       "                                                                       7   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                           80   \n",
       "scheduler_submit_time                                  1687837883.945334   \n",
       "\n",
       "                                                                       8   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                           90   \n",
       "scheduler_submit_time                                  1687837893.944211   \n",
       "\n",
       "                                                                       9   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                          100   \n",
       "scheduler_submit_time                                  1687837903.949104   \n",
       "\n",
       "                                                                      10   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                          110   \n",
       "scheduler_submit_time                                  1687837913.949703   \n",
       "\n",
       "                                                                      11   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                   31.139337   \n",
       "submit_time                                                          120   \n",
       "scheduler_submit_time                                  1687837923.950936   \n",
       "\n",
       "                                                                      12   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                          130   \n",
       "scheduler_submit_time                                  1687837933.946119   \n",
       "\n",
       "                                                                      13   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                          140   \n",
       "scheduler_submit_time                                  1687837943.947579   \n",
       "\n",
       "                                                                      14   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                          150   \n",
       "scheduler_submit_time                                  1687837953.946669   \n",
       "\n",
       "                                                                      15   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                          160   \n",
       "scheduler_submit_time                                  1687837963.945398   \n",
       "\n",
       "                                                                      16   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                          170   \n",
       "scheduler_submit_time                                   1687837973.94409   \n",
       "\n",
       "                                                                      17   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                          180   \n",
       "scheduler_submit_time                                  1687837983.945077   \n",
       "\n",
       "                                                                      18   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                          190   \n",
       "scheduler_submit_time                                  1687837994.012038   \n",
       "\n",
       "                                                                      19   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                          200   \n",
       "scheduler_submit_time                                   1687838004.03192   \n",
       "\n",
       "                                                                      20   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                          210   \n",
       "scheduler_submit_time                                  1687838013.984719   \n",
       "\n",
       "                                                                      21   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                          220   \n",
       "scheduler_submit_time                                   1687838023.94536   \n",
       "\n",
       "                                                                      22   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                   41.956107   \n",
       "submit_time                                                          230   \n",
       "scheduler_submit_time                                  1687838033.948371   \n",
       "\n",
       "                                                                      23   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                          240   \n",
       "scheduler_submit_time                                   1687838044.12214   \n",
       "\n",
       "                                                                      24   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                          250   \n",
       "scheduler_submit_time                                  1687838054.121535   \n",
       "\n",
       "                                                                      25   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                          260   \n",
       "scheduler_submit_time                                  1687838064.186292   \n",
       "\n",
       "                                                                      26   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                   31.925926   \n",
       "submit_time                                                          270   \n",
       "scheduler_submit_time                                  1687838074.165931   \n",
       "\n",
       "                                                                      27   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                          280   \n",
       "scheduler_submit_time                                  1687838084.243511   \n",
       "\n",
       "                                                                      28   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                          290   \n",
       "scheduler_submit_time                                   1687838093.94573   \n",
       "\n",
       "                                                                      29   \n",
       "job_type                                                           sleep  \\\n",
       "image                                   gcr.io/sky-burst/skyburst:latest   \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...   \n",
       "uniform_arrival                                                      NaN   \n",
       "uniform_submission                                                   NaN   \n",
       "waiting_policy                                                       NaN   \n",
       "policy                                                               NaN   \n",
       "time_constrained                                                     NaN   \n",
       "cluster_size                                                         NaN   \n",
       "cpus_per_node                                                        NaN   \n",
       "gpus_per_node                                                        NaN   \n",
       "cloud_cluster_nodes                                                  NaN   \n",
       "cloud_cpu_per_node                                                   NaN   \n",
       "random_seed                                                          NaN   \n",
       "total_jobs                                                           NaN   \n",
       "batch_time                                                           NaN   \n",
       "wait_time                                                            NaN   \n",
       "time_out                                                             NaN   \n",
       "mean_duration                                                        NaN   \n",
       "arrival_rate                                                         NaN   \n",
       "cpu_sizes                                                            NaN   \n",
       "cpu_dist                                                             NaN   \n",
       "gpu_sizes                                                            NaN   \n",
       "gpu_dist                                                             NaN   \n",
       "memory_sizes                                                         NaN   \n",
       "memory_dict                                                          NaN   \n",
       "train_names                                                          NaN   \n",
       "train_dist                                                           NaN   \n",
       "use_new_cluster                                                      NaN   \n",
       "onprem_cluster                                                       NaN   \n",
       "cloud_cluster                                                        NaN   \n",
       "gpu_workload                                                         NaN   \n",
       "spill_to_cloud                                                       NaN   \n",
       "onprem_only                                                          NaN   \n",
       "collect_runtimes                                                     NaN   \n",
       "sample_real_workloads                                                NaN   \n",
       "workload_type                                                        cpu   \n",
       "sched_tick                                                           NaN   \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}   \n",
       "job_duration                                                          30   \n",
       "submit_time                                                          300   \n",
       "scheduler_submit_time                                  1687838103.939518   \n",
       "\n",
       "                                                                      30  \n",
       "job_type                                                           sleep  \n",
       "image                                   gcr.io/sky-burst/skyburst:latest  \n",
       "setup_script           nvidia-smi --query-gpu=index --format=csv,nohe...  \n",
       "uniform_arrival                                                      NaN  \n",
       "uniform_submission                                                   NaN  \n",
       "waiting_policy                                                       NaN  \n",
       "policy                                                               NaN  \n",
       "time_constrained                                                     NaN  \n",
       "cluster_size                                                         NaN  \n",
       "cpus_per_node                                                        NaN  \n",
       "gpus_per_node                                                        NaN  \n",
       "cloud_cluster_nodes                                                  NaN  \n",
       "cloud_cpu_per_node                                                   NaN  \n",
       "random_seed                                                          NaN  \n",
       "total_jobs                                                           NaN  \n",
       "batch_time                                                           NaN  \n",
       "wait_time                                                            NaN  \n",
       "time_out                                                             NaN  \n",
       "mean_duration                                                        NaN  \n",
       "arrival_rate                                                         NaN  \n",
       "cpu_sizes                                                            NaN  \n",
       "cpu_dist                                                             NaN  \n",
       "gpu_sizes                                                            NaN  \n",
       "gpu_dist                                                             NaN  \n",
       "memory_sizes                                                         NaN  \n",
       "memory_dict                                                          NaN  \n",
       "train_names                                                          NaN  \n",
       "train_dist                                                           NaN  \n",
       "use_new_cluster                                                      NaN  \n",
       "onprem_cluster                                                       NaN  \n",
       "cloud_cluster                                                        NaN  \n",
       "gpu_workload                                                         NaN  \n",
       "spill_to_cloud                                                       NaN  \n",
       "onprem_only                                                          NaN  \n",
       "collect_runtimes                                                     NaN  \n",
       "sample_real_workloads                                                NaN  \n",
       "workload_type                                                        cpu  \n",
       "sched_tick                                                           NaN  \n",
       "workload                               {'gpu': 0, 'cpu': 1, 'memory': 0}  \n",
       "job_duration                                                          30  \n",
       "submit_time                                                          310  \n",
       "scheduler_submit_time                                  1687838113.941313  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31.13933657654875, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 41.95610651562337, 30, 30, 30, 31.925925751656486, 30, 30, 30, 30]\n",
      "['Scheduler spun up! ', 'Cloud Job || job id 2 | job name job-2 | estimated cloud start time 1687837849.3612251 | estimated job duration 30 | submission time 1687837834.3279767 | gpus 0 | cpus 1 ', 'Cloud Job || job id 5 | job name job-5 | estimated cloud start time 1687837879.4353619 | estimated job duration 30 | submission time 1687837864.398452 | gpus 0 | cpus 1 ', 'Cloud Job || job id 8 | job name job-8 | estimated cloud start time 1687837909.5110734 | estimated job duration 30 | submission time 1687837894.4711308 | gpus 0 | cpus 1 ', 'Cloud Job || job id 11 | job name job-11 | estimated cloud start time 1687837939.5892186 | estimated job duration 31.13933657654875 | submission time 1687837924.7337954 | gpus 0 | cpus 1 ', 'Cloud Job || job id 12 | job name job-12 | estimated cloud start time 1687837949.611588 | estimated job duration 30 | submission time 1687837934.769701 | gpus 0 | cpus 1 ', 'Cloud Job || job id 15 | job name job-15 | estimated cloud start time 1687837979.6792655 | estimated job duration 30 | submission time 1687837964.6453385 | gpus 0 | cpus 1 ', 'Cloud Job || job id 18 | job name job-18 | estimated cloud start time 1687838009.7422159 | estimated job duration 30 | submission time 1687837994.9045072 | gpus 0 | cpus 1 ', 'Cloud Job || job id 19 | job name job-19 | estimated cloud start time 1687838019.7641735 | estimated job duration 30 | submission time 1687838004.9274452 | gpus 0 | cpus 1 ', 'Cloud Job || job id 22 | job name job-22 | estimated cloud start time 1687838049.829631 | estimated job duration 41.95610651562337 | submission time 1687838034.7985463 | gpus 0 | cpus 1 ', 'Cloud Job || job id 25 | job name job-25 | estimated cloud start time 1687838079.8961434 | estimated job duration 30 | submission time 1687838064.8620303 | gpus 0 | cpus 1 ', 'Cloud Job || job id 28 | job name job-28 | estimated cloud start time 1687838108.9679663 | estimated job duration 30 | submission time 1687838094.153719 | gpus 0 | cpus 1 ', 'Cloud Job || job id 29 | job name job-29 | estimated cloud start time 1687838118.992448 | estimated job duration 30 | submission time 1687838104.1854804 | gpus 0 | cpus 1 ', '']\n",
      "matched time {'arrival': 1687837813.9509115, 'submit': 1687837815, 'pod_start': 1687837816, 'job_end': 1687837849}\n",
      "value {'arrival': 1687837813.9509115, 'submit': 1687837815, 'pod_start': 1687837816, 'job_end': 1687837849}\n",
      "matched time {'arrival': 1687837823.9476047, 'submit': 1687837825, 'pod_start': 1687837826, 'job_end': 1687837859}\n",
      "value {'arrival': 1687837823.9476047, 'submit': 1687837825, 'pod_start': 1687837826, 'job_end': 1687837859}\n",
      "matched time {'arrival': 1687837843.947018, 'submit': 1687837849, 'pod_start': 1687837850, 'job_end': 1687837883}\n",
      "value {'arrival': 1687837843.947018, 'submit': 1687837849, 'pod_start': 1687837850, 'job_end': 1687837883}\n",
      "matched time {'arrival': 1687837853.9529335, 'submit': 1687837859, 'pod_start': 1687837860, 'job_end': 1687837894}\n",
      "value {'arrival': 1687837853.9529335, 'submit': 1687837859, 'pod_start': 1687837860, 'job_end': 1687837894}\n",
      "matched time {'arrival': 1687837873.9424806, 'submit': 1687837883, 'pod_start': 1687837884, 'job_end': 1687837917}\n",
      "value {'arrival': 1687837873.9424806, 'submit': 1687837883, 'pod_start': 1687837884, 'job_end': 1687837917}\n",
      "matched time {'arrival': 1687837883.9453337, 'submit': 1687837893, 'pod_start': 1687837894, 'job_end': 1687837928}\n",
      "value {'arrival': 1687837883.9453337, 'submit': 1687837893, 'pod_start': 1687837894, 'job_end': 1687837928}\n",
      "matched time {'arrival': 1687837903.9491038, 'submit': 1687837917, 'pod_start': 1687837918, 'job_end': 1687837952}\n",
      "value {'arrival': 1687837903.9491038, 'submit': 1687837917, 'pod_start': 1687837918, 'job_end': 1687837952}\n",
      "matched time {'arrival': 1687837913.9497025, 'submit': 1687837927, 'pod_start': 1687837928, 'job_end': 1687837962}\n",
      "value {'arrival': 1687837913.9497025, 'submit': 1687837927, 'pod_start': 1687837928, 'job_end': 1687837962}\n",
      "matched time {'arrival': 1687837943.9475787, 'submit': 1687837952, 'pod_start': 1687837953, 'job_end': 1687837987}\n",
      "value {'arrival': 1687837943.9475787, 'submit': 1687837952, 'pod_start': 1687837953, 'job_end': 1687837987}\n",
      "matched time {'arrival': 1687837953.946669, 'submit': 1687837961, 'pod_start': 1687837962, 'job_end': 1687837996}\n",
      "value {'arrival': 1687837953.946669, 'submit': 1687837961, 'pod_start': 1687837962, 'job_end': 1687837996}\n",
      "matched time {'arrival': 1687837973.9440897, 'submit': 1687837986, 'pod_start': 1687837987, 'job_end': 1687838020}\n",
      "value {'arrival': 1687837973.9440897, 'submit': 1687837986, 'pod_start': 1687837987, 'job_end': 1687838020}\n",
      "matched time {'arrival': 1687837983.9450774, 'submit': 1687837995, 'pod_start': 1687837997, 'job_end': 1687838030}\n",
      "value {'arrival': 1687837983.9450774, 'submit': 1687837995, 'pod_start': 1687837997, 'job_end': 1687838030}\n",
      "matched time {'arrival': 1687838013.9847186, 'submit': 1687838019, 'pod_start': 1687838020, 'job_end': 1687838054}\n",
      "value {'arrival': 1687838013.9847186, 'submit': 1687838019, 'pod_start': 1687838020, 'job_end': 1687838054}\n",
      "matched time {'arrival': 1687838023.9453604, 'submit': 1687838030, 'pod_start': 1687838031, 'job_end': 1687838064}\n",
      "value {'arrival': 1687838023.9453604, 'submit': 1687838030, 'pod_start': 1687838031, 'job_end': 1687838064}\n",
      "matched time {'arrival': 1687838044.1221404, 'submit': 1687838054, 'pod_start': 1687838055, 'job_end': 1687838088}\n",
      "value {'arrival': 1687838044.1221404, 'submit': 1687838054, 'pod_start': 1687838055, 'job_end': 1687838088}\n",
      "matched time {'arrival': 1687838054.121535, 'submit': 1687838064, 'pod_start': 1687838065, 'job_end': 1687838098}\n",
      "value {'arrival': 1687838054.121535, 'submit': 1687838064, 'pod_start': 1687838065, 'job_end': 1687838098}\n",
      "matched time {'arrival': 1687838074.1659307, 'submit': 1687838088, 'pod_start': 1687838089, 'job_end': 1687838124}\n",
      "value {'arrival': 1687838074.1659307, 'submit': 1687838088, 'pod_start': 1687838089, 'job_end': 1687838124}\n",
      "matched time {'arrival': 1687838084.2435114, 'submit': 1687838098, 'pod_start': 1687838099, 'job_end': 1687838132}\n",
      "value {'arrival': 1687838084.2435114, 'submit': 1687838098, 'pod_start': 1687838099, 'job_end': 1687838132}\n",
      "matched time {'arrival': 1687838113.941313, 'submit': 1687838124, 'pod_start': 1687838125, 'job_end': 1687838158}\n",
      "value {'arrival': 1687838113.941313, 'submit': 1687838124, 'pod_start': 1687838125, 'job_end': 1687838158}\n",
      "Onprem Jobs 19\n",
      "interval {'job-0': {'arrival': 1687837813.9509115, 'submit': 1687837815, 'pod_start': 1687837816, 'job_end': 1687837849}, 'job-1': {'arrival': 1687837823.9476047, 'submit': 1687837825, 'pod_start': 1687837826, 'job_end': 1687837859}, 'job-3': {'arrival': 1687837843.947018, 'submit': 1687837849, 'pod_start': 1687837850, 'job_end': 1687837883}, 'job-4': {'arrival': 1687837853.9529335, 'submit': 1687837859, 'pod_start': 1687837860, 'job_end': 1687837894}, 'job-6': {'arrival': 1687837873.9424806, 'submit': 1687837883, 'pod_start': 1687837884, 'job_end': 1687837917}, 'job-7': {'arrival': 1687837883.9453337, 'submit': 1687837893, 'pod_start': 1687837894, 'job_end': 1687837928}, 'job-9': {'arrival': 1687837903.9491038, 'submit': 1687837917, 'pod_start': 1687837918, 'job_end': 1687837952}, 'job-10': {'arrival': 1687837913.9497025, 'submit': 1687837927, 'pod_start': 1687837928, 'job_end': 1687837962}, 'job-13': {'arrival': 1687837943.9475787, 'submit': 1687837952, 'pod_start': 1687837953, 'job_end': 1687837987}, 'job-14': {'arrival': 1687837953.946669, 'submit': 1687837961, 'pod_start': 1687837962, 'job_end': 1687837996}, 'job-16': {'arrival': 1687837973.9440897, 'submit': 1687837986, 'pod_start': 1687837987, 'job_end': 1687838020}, 'job-17': {'arrival': 1687837983.9450774, 'submit': 1687837995, 'pod_start': 1687837997, 'job_end': 1687838030}, 'job-20': {'arrival': 1687838013.9847186, 'submit': 1687838019, 'pod_start': 1687838020, 'job_end': 1687838054}, 'job-21': {'arrival': 1687838023.9453604, 'submit': 1687838030, 'pod_start': 1687838031, 'job_end': 1687838064}, 'job-23': {'arrival': 1687838044.1221404, 'submit': 1687838054, 'pod_start': 1687838055, 'job_end': 1687838088}, 'job-24': {'arrival': 1687838054.121535, 'submit': 1687838064, 'pod_start': 1687838065, 'job_end': 1687838098}, 'job-26': {'arrival': 1687838074.1659307, 'submit': 1687838088, 'pod_start': 1687838089, 'job_end': 1687838124}, 'job-27': {'arrival': 1687838084.2435114, 'submit': 1687838098, 'pod_start': 1687838099, 'job_end': 1687838132}, 'job-30': {'arrival': 1687838113.941313, 'submit': 1687838124, 'pod_start': 1687838125, 'job_end': 1687838158}}\n",
      "onprem value {'arrival': 1687837813.9509115, 'submit': 1687837815, 'pod_start': 1687837816, 'job_end': 1687837849}\n",
      "onprem value {'arrival': 1687837823.9476047, 'submit': 1687837825, 'pod_start': 1687837826, 'job_end': 1687837859}\n",
      "onprem value {'arrival': 1687837843.947018, 'submit': 1687837849, 'pod_start': 1687837850, 'job_end': 1687837883}\n",
      "onprem value {'arrival': 1687837853.9529335, 'submit': 1687837859, 'pod_start': 1687837860, 'job_end': 1687837894}\n",
      "onprem value {'arrival': 1687837873.9424806, 'submit': 1687837883, 'pod_start': 1687837884, 'job_end': 1687837917}\n",
      "onprem value {'arrival': 1687837883.9453337, 'submit': 1687837893, 'pod_start': 1687837894, 'job_end': 1687837928}\n",
      "onprem value {'arrival': 1687837903.9491038, 'submit': 1687837917, 'pod_start': 1687837918, 'job_end': 1687837952}\n",
      "onprem value {'arrival': 1687837913.9497025, 'submit': 1687837927, 'pod_start': 1687837928, 'job_end': 1687837962}\n",
      "onprem value {'arrival': 1687837943.9475787, 'submit': 1687837952, 'pod_start': 1687837953, 'job_end': 1687837987}\n",
      "onprem value {'arrival': 1687837953.946669, 'submit': 1687837961, 'pod_start': 1687837962, 'job_end': 1687837996}\n",
      "onprem value {'arrival': 1687837973.9440897, 'submit': 1687837986, 'pod_start': 1687837987, 'job_end': 1687838020}\n",
      "onprem value {'arrival': 1687837983.9450774, 'submit': 1687837995, 'pod_start': 1687837997, 'job_end': 1687838030}\n",
      "onprem value {'arrival': 1687838013.9847186, 'submit': 1687838019, 'pod_start': 1687838020, 'job_end': 1687838054}\n",
      "onprem value {'arrival': 1687838023.9453604, 'submit': 1687838030, 'pod_start': 1687838031, 'job_end': 1687838064}\n",
      "onprem value {'arrival': 1687838044.1221404, 'submit': 1687838054, 'pod_start': 1687838055, 'job_end': 1687838088}\n",
      "onprem value {'arrival': 1687838054.121535, 'submit': 1687838064, 'pod_start': 1687838065, 'job_end': 1687838098}\n",
      "onprem value {'arrival': 1687838074.1659307, 'submit': 1687838088, 'pod_start': 1687838089, 'job_end': 1687838124}\n",
      "onprem value {'arrival': 1687838084.2435114, 'submit': 1687838098, 'pod_start': 1687838099, 'job_end': 1687838132}\n",
      "onprem value {'arrival': 1687838113.941313, 'submit': 1687838124, 'pod_start': 1687838125, 'job_end': 1687838158}\n",
      "matched time {'arrival': 1687837834.3279767, 'submit': 1687837849.3612251, 'pod_start': 1687837851.3612251, 'job_end': 1687837881.3612251, 'gpu': 0, 'cpu': 1}\n",
      "Missing gpu 0\n",
      "value {'arrival': 1687837834.3279767, 'submit': 1687837849.3612251, 'pod_start': 1687837851.3612251, 'job_end': 1687837881.3612251, 'gpu': 0, 'cpu': 1}\n",
      "matched time {'arrival': 1687837864.398452, 'submit': 1687837879.4353619, 'pod_start': 1687837881.4353619, 'job_end': 1687837911.4353619, 'gpu': 0, 'cpu': 1}\n",
      "Missing gpu 0\n",
      "value {'arrival': 1687837864.398452, 'submit': 1687837879.4353619, 'pod_start': 1687837881.4353619, 'job_end': 1687837911.4353619, 'gpu': 0, 'cpu': 1}\n",
      "matched time {'arrival': 1687837894.4711308, 'submit': 1687837909.5110734, 'pod_start': 1687837911.5110734, 'job_end': 1687837941.5110734, 'gpu': 0, 'cpu': 1}\n",
      "Missing gpu 0\n",
      "value {'arrival': 1687837894.4711308, 'submit': 1687837909.5110734, 'pod_start': 1687837911.5110734, 'job_end': 1687837941.5110734, 'gpu': 0, 'cpu': 1}\n",
      "matched time {'arrival': 1687837924.7337954, 'submit': 1687837939.5892186, 'pod_start': 1687837941.5892186, 'job_end': 1687837972.7285552, 'gpu': 0, 'cpu': 1}\n",
      "Missing gpu 0\n",
      "value {'arrival': 1687837924.7337954, 'submit': 1687837939.5892186, 'pod_start': 1687837941.5892186, 'job_end': 1687837972.7285552, 'gpu': 0, 'cpu': 1}\n",
      "matched time {'arrival': 1687837934.769701, 'submit': 1687837949.611588, 'pod_start': 1687837951.611588, 'job_end': 1687837981.611588, 'gpu': 0, 'cpu': 1}\n",
      "Missing gpu 0\n",
      "value {'arrival': 1687837934.769701, 'submit': 1687837949.611588, 'pod_start': 1687837951.611588, 'job_end': 1687837981.611588, 'gpu': 0, 'cpu': 1}\n",
      "matched time {'arrival': 1687837964.6453385, 'submit': 1687837979.6792655, 'pod_start': 1687837981.6792655, 'job_end': 1687838011.6792655, 'gpu': 0, 'cpu': 1}\n",
      "Missing gpu 0\n",
      "value {'arrival': 1687837964.6453385, 'submit': 1687837979.6792655, 'pod_start': 1687837981.6792655, 'job_end': 1687838011.6792655, 'gpu': 0, 'cpu': 1}\n",
      "matched time {'arrival': 1687837994.9045072, 'submit': 1687838009.7422159, 'pod_start': 1687838011.7422159, 'job_end': 1687838041.7422159, 'gpu': 0, 'cpu': 1}\n",
      "Missing gpu 0\n",
      "value {'arrival': 1687837994.9045072, 'submit': 1687838009.7422159, 'pod_start': 1687838011.7422159, 'job_end': 1687838041.7422159, 'gpu': 0, 'cpu': 1}\n",
      "matched time {'arrival': 1687838004.9274452, 'submit': 1687838019.7641735, 'pod_start': 1687838021.7641735, 'job_end': 1687838051.7641735, 'gpu': 0, 'cpu': 1}\n",
      "Missing gpu 0\n",
      "value {'arrival': 1687838004.9274452, 'submit': 1687838019.7641735, 'pod_start': 1687838021.7641735, 'job_end': 1687838051.7641735, 'gpu': 0, 'cpu': 1}\n",
      "matched time {'arrival': 1687838034.7985463, 'submit': 1687838049.829631, 'pod_start': 1687838051.829631, 'job_end': 1687838093.7857375, 'gpu': 0, 'cpu': 1}\n",
      "Missing gpu 0\n",
      "value {'arrival': 1687838034.7985463, 'submit': 1687838049.829631, 'pod_start': 1687838051.829631, 'job_end': 1687838093.7857375, 'gpu': 0, 'cpu': 1}\n",
      "matched time {'arrival': 1687838064.8620303, 'submit': 1687838079.8961434, 'pod_start': 1687838081.8961434, 'job_end': 1687838111.8961434, 'gpu': 0, 'cpu': 1}\n",
      "Missing gpu 0\n",
      "value {'arrival': 1687838064.8620303, 'submit': 1687838079.8961434, 'pod_start': 1687838081.8961434, 'job_end': 1687838111.8961434, 'gpu': 0, 'cpu': 1}\n",
      "matched time {'arrival': 1687838094.153719, 'submit': 1687838108.9679663, 'pod_start': 1687838110.9679663, 'job_end': 1687838140.9679663, 'gpu': 0, 'cpu': 1}\n",
      "Missing gpu 0\n",
      "value {'arrival': 1687838094.153719, 'submit': 1687838108.9679663, 'pod_start': 1687838110.9679663, 'job_end': 1687838140.9679663, 'gpu': 0, 'cpu': 1}\n",
      "matched time {'arrival': 1687838104.1854804, 'submit': 1687838118.992448, 'pod_start': 1687838120.992448, 'job_end': 1687838150.992448, 'gpu': 0, 'cpu': 1}\n",
      "Missing gpu 0\n",
      "value {'arrival': 1687838104.1854804, 'submit': 1687838118.992448, 'pod_start': 1687838120.992448, 'job_end': 1687838150.992448, 'gpu': 0, 'cpu': 1}\n",
      "Cloud Jobs 12\n",
      "interval {2: {'arrival': 1687837834.3279767, 'submit': 1687837849.3612251, 'pod_start': 1687837851.3612251, 'job_end': 1687837881.3612251, 'gpu': 0, 'cpu': 1}, 5: {'arrival': 1687837864.398452, 'submit': 1687837879.4353619, 'pod_start': 1687837881.4353619, 'job_end': 1687837911.4353619, 'gpu': 0, 'cpu': 1}, 8: {'arrival': 1687837894.4711308, 'submit': 1687837909.5110734, 'pod_start': 1687837911.5110734, 'job_end': 1687837941.5110734, 'gpu': 0, 'cpu': 1}, 11: {'arrival': 1687837924.7337954, 'submit': 1687837939.5892186, 'pod_start': 1687837941.5892186, 'job_end': 1687837972.7285552, 'gpu': 0, 'cpu': 1}, 12: {'arrival': 1687837934.769701, 'submit': 1687837949.611588, 'pod_start': 1687837951.611588, 'job_end': 1687837981.611588, 'gpu': 0, 'cpu': 1}, 15: {'arrival': 1687837964.6453385, 'submit': 1687837979.6792655, 'pod_start': 1687837981.6792655, 'job_end': 1687838011.6792655, 'gpu': 0, 'cpu': 1}, 18: {'arrival': 1687837994.9045072, 'submit': 1687838009.7422159, 'pod_start': 1687838011.7422159, 'job_end': 1687838041.7422159, 'gpu': 0, 'cpu': 1}, 19: {'arrival': 1687838004.9274452, 'submit': 1687838019.7641735, 'pod_start': 1687838021.7641735, 'job_end': 1687838051.7641735, 'gpu': 0, 'cpu': 1}, 22: {'arrival': 1687838034.7985463, 'submit': 1687838049.829631, 'pod_start': 1687838051.829631, 'job_end': 1687838093.7857375, 'gpu': 0, 'cpu': 1}, 25: {'arrival': 1687838064.8620303, 'submit': 1687838079.8961434, 'pod_start': 1687838081.8961434, 'job_end': 1687838111.8961434, 'gpu': 0, 'cpu': 1}, 28: {'arrival': 1687838094.153719, 'submit': 1687838108.9679663, 'pod_start': 1687838110.9679663, 'job_end': 1687838140.9679663, 'gpu': 0, 'cpu': 1}, 29: {'arrival': 1687838104.1854804, 'submit': 1687838118.992448, 'pod_start': 1687838120.992448, 'job_end': 1687838150.992448, 'gpu': 0, 'cpu': 1}}\n",
      "cloud value {'arrival': 1687837834.3279767, 'submit': 1687837849.3612251, 'pod_start': 1687837851.3612251, 'job_end': 1687837881.3612251, 'gpu': 0, 'cpu': 1}\n",
      "cloud value {'arrival': 1687837864.398452, 'submit': 1687837879.4353619, 'pod_start': 1687837881.4353619, 'job_end': 1687837911.4353619, 'gpu': 0, 'cpu': 1}\n",
      "cloud value {'arrival': 1687837894.4711308, 'submit': 1687837909.5110734, 'pod_start': 1687837911.5110734, 'job_end': 1687837941.5110734, 'gpu': 0, 'cpu': 1}\n",
      "cloud value {'arrival': 1687837924.7337954, 'submit': 1687837939.5892186, 'pod_start': 1687837941.5892186, 'job_end': 1687837972.7285552, 'gpu': 0, 'cpu': 1}\n",
      "cloud value {'arrival': 1687837934.769701, 'submit': 1687837949.611588, 'pod_start': 1687837951.611588, 'job_end': 1687837981.611588, 'gpu': 0, 'cpu': 1}\n",
      "cloud value {'arrival': 1687837964.6453385, 'submit': 1687837979.6792655, 'pod_start': 1687837981.6792655, 'job_end': 1687838011.6792655, 'gpu': 0, 'cpu': 1}\n",
      "cloud value {'arrival': 1687837994.9045072, 'submit': 1687838009.7422159, 'pod_start': 1687838011.7422159, 'job_end': 1687838041.7422159, 'gpu': 0, 'cpu': 1}\n",
      "cloud value {'arrival': 1687838004.9274452, 'submit': 1687838019.7641735, 'pod_start': 1687838021.7641735, 'job_end': 1687838051.7641735, 'gpu': 0, 'cpu': 1}\n",
      "cloud value {'arrival': 1687838034.7985463, 'submit': 1687838049.829631, 'pod_start': 1687838051.829631, 'job_end': 1687838093.7857375, 'gpu': 0, 'cpu': 1}\n",
      "cloud value {'arrival': 1687838064.8620303, 'submit': 1687838079.8961434, 'pod_start': 1687838081.8961434, 'job_end': 1687838111.8961434, 'gpu': 0, 'cpu': 1}\n",
      "cloud value {'arrival': 1687838094.153719, 'submit': 1687838108.9679663, 'pod_start': 1687838110.9679663, 'job_end': 1687838140.9679663, 'gpu': 0, 'cpu': 1}\n",
      "cloud value {'arrival': 1687838104.1854804, 'submit': 1687838118.992448, 'pod_start': 1687838120.992448, 'job_end': 1687838150.992448, 'gpu': 0, 'cpu': 1}\n",
      "{'idx': [0, 1, 3, 4, 6, 7, 9, 10, 13, 14, 16, 17, 20, 21, 23, 24, 26, 27, 30, 2, 5, 8, 11, 12, 15, 18, 19, 22, 25, 28, 29], 'runtime': [33, 33, 33, 34, 33, 34, 34, 34, 34, 34, 33, 33, 34, 33, 33, 33, 35, 33, 33, 30.0, 30.0, 30.0, 31.139336585998535, 30.0, 30.0, 30.0, 30.0, 41.956106424331665, 30.0, 30.0, 30.0], 'arrival': [1687837813.9509115, 1687837823.9476047, 1687837843.947018, 1687837853.9529335, 1687837873.9424806, 1687837883.9453337, 1687837903.9491038, 1687837913.9497025, 1687837943.9475787, 1687837953.946669, 1687837973.9440897, 1687837983.9450774, 1687838013.9847186, 1687838023.9453604, 1687838044.1221404, 1687838054.121535, 1687838074.1659307, 1687838084.2435114, 1687838113.941313, 1687837834.3279767, 1687837864.398452, 1687837894.4711308, 1687837924.7337954, 1687837934.769701, 1687837964.6453385, 1687837994.9045072, 1687838004.9274452, 1687838034.7985463, 1687838064.8620303, 1687838094.153719, 1687838104.1854804], 'num_gpus': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'allocated_gpus': [{1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}], 'allocated_gpus_real': [{1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}], 'start': [1687837816, 1687837826, 1687837850, 1687837860, 1687837884, 1687837894, 1687837918, 1687837928, 1687837953, 1687837962, 1687837987, 1687837997, 1687838020, 1687838031, 1687838055, 1687838065, 1687838089, 1687838099, 1687838125, 1687837851.3612251, 1687837881.4353619, 1687837911.5110734, 1687837941.5892186, 1687837951.611588, 1687837981.6792655, 1687838011.7422159, 1687838021.7641735, 1687838051.829631, 1687838081.8961434, 1687838110.9679663, 1687838120.992448], 'instance_type': ['n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown'], 'node_index': [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], 'node': ['gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu', 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu', 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu', 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu', 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu', 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu', 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu', 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu', 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu', 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w', 'cloud', 'cloud', 'cloud', 'cloud', 'cloud', 'cloud', 'cloud', 'cloud', 'cloud', 'cloud', 'cloud', 'cloud'], 'cpus': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'submission_time': [1687837815, 1687837825, 1687837849, 1687837859, 1687837883, 1687837893, 1687837917, 1687837927, 1687837952, 1687837961, 1687837986, 1687837995, 1687838019, 1687838030, 1687838054, 1687838064, 1687838088, 1687838098, 1687838124, 1687837849.3612251, 1687837879.4353619, 1687837909.5110734, 1687837939.5892186, 1687837949.611588, 1687837979.6792655, 1687838009.7422159, 1687838019.7641735, 1687838049.829631, 1687838079.8961434, 1687838108.9679663, 1687838118.992448], 'wait_times': [2.049088478088379, 2.0523953437805176, 6.0529820919036865, 6.0470664501190186, 10.057519435882568, 10.05466628074646, 14.050896167755127, 14.050297498703003, 9.05242133140564, 8.053330898284912, 13.055910348892212, 13.054922580718994, 6.015281438827515, 7.054639577865601, 10.877859592437744, 10.878464937210083, 14.83406925201416, 14.756488561630249, 11.058686971664429, 17.03324842453003, 17.036909818649292, 17.039942502975464, 16.85542321205139, 16.8418869972229, 17.033926963806152, 16.837708711624146, 16.83672833442688, 17.031084775924683, 17.03411316871643, 16.814247369766235, 16.806967735290527], 'is_local': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>runtime</th>\n",
       "      <th>arrival</th>\n",
       "      <th>num_gpus</th>\n",
       "      <th>allocated_gpus</th>\n",
       "      <th>allocated_gpus_real</th>\n",
       "      <th>start</th>\n",
       "      <th>instance_type</th>\n",
       "      <th>node_index</th>\n",
       "      <th>node</th>\n",
       "      <th>cpus</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>wait_times</th>\n",
       "      <th>is_local</th>\n",
       "      <th>job_type</th>\n",
       "      <th>image</th>\n",
       "      <th>setup_script</th>\n",
       "      <th>uniform_arrival</th>\n",
       "      <th>uniform_submission</th>\n",
       "      <th>waiting_policy</th>\n",
       "      <th>policy</th>\n",
       "      <th>time_constrained</th>\n",
       "      <th>cluster_size</th>\n",
       "      <th>cpus_per_node</th>\n",
       "      <th>gpus_per_node</th>\n",
       "      <th>cloud_cluster_nodes</th>\n",
       "      <th>cloud_cpu_per_node</th>\n",
       "      <th>random_seed</th>\n",
       "      <th>total_jobs</th>\n",
       "      <th>batch_time</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>time_out</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>arrival_rate</th>\n",
       "      <th>cpu_sizes</th>\n",
       "      <th>cpu_dist</th>\n",
       "      <th>gpu_sizes</th>\n",
       "      <th>gpu_dist</th>\n",
       "      <th>memory_sizes</th>\n",
       "      <th>memory_dict</th>\n",
       "      <th>train_names</th>\n",
       "      <th>train_dist</th>\n",
       "      <th>use_new_cluster</th>\n",
       "      <th>onprem_cluster</th>\n",
       "      <th>cloud_cluster</th>\n",
       "      <th>gpu_workload</th>\n",
       "      <th>spill_to_cloud</th>\n",
       "      <th>onprem_only</th>\n",
       "      <th>collect_runtimes</th>\n",
       "      <th>sample_real_workloads</th>\n",
       "      <th>workload_type</th>\n",
       "      <th>sched_tick</th>\n",
       "      <th>workload</th>\n",
       "      <th>job_duration</th>\n",
       "      <th>submit_time</th>\n",
       "      <th>scheduler_submit_time</th>\n",
       "      <th>varying_values</th>\n",
       "      <th>fixed_values</th>\n",
       "      <th>workload_type_sweep</th>\n",
       "      <th>batch_time_sweep</th>\n",
       "      <th>mean_duration_sweep</th>\n",
       "      <th>waiting_policy_sweep</th>\n",
       "      <th>cpu_dist_sweep</th>\n",
       "      <th>cpu_sizes_sweep</th>\n",
       "      <th>gpu_dist_sweep</th>\n",
       "      <th>gpu_sizes_sweep</th>\n",
       "      <th>uniform_submission_sweep</th>\n",
       "      <th>uniform_arrival_sweep</th>\n",
       "      <th>onprem_cluster_sweep</th>\n",
       "      <th>cloud_cluster_sweep</th>\n",
       "      <th>cluster_size_sweep</th>\n",
       "      <th>gpus_per_node_sweep</th>\n",
       "      <th>sched_tick_sweep</th>\n",
       "      <th>wait_time_sweep</th>\n",
       "      <th>spill_to_cloud_sweep</th>\n",
       "      <th>sample_real_workloads_sweep</th>\n",
       "      <th>job_type_sweep</th>\n",
       "      <th>image_sweep</th>\n",
       "      <th>policy_sweep</th>\n",
       "      <th>arrival_rate_sweep</th>\n",
       "      <th>setup_script_sweep</th>\n",
       "      <th>time_constrained_sweep</th>\n",
       "      <th>cpus_per_node_sweep</th>\n",
       "      <th>cloud_cluster_nodes_sweep</th>\n",
       "      <th>cloud_cpu_per_node_sweep</th>\n",
       "      <th>random_seed_sweep</th>\n",
       "      <th>total_jobs_sweep</th>\n",
       "      <th>time_out_sweep</th>\n",
       "      <th>memory_sizes_sweep</th>\n",
       "      <th>memory_dict_sweep</th>\n",
       "      <th>train_names_sweep</th>\n",
       "      <th>train_dist_sweep</th>\n",
       "      <th>use_new_cluster_sweep</th>\n",
       "      <th>gpu_workload_sweep</th>\n",
       "      <th>onprem_only_sweep</th>\n",
       "      <th>collect_runtimes_sweep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 1, 3, 4, 6, 7, 9, 10, 13, 14, 16, 17, 20, ...</td>\n",
       "      <td>[33, 33, 33, 34, 33, 34, 34, 34, 34, 34, 33, 3...</td>\n",
       "      <td>[-1.049088478088379, 8.947604656219482, 28.947...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[{1: []}, {0: []}, {1: []}, {0: []}, {1: []}, ...</td>\n",
       "      <td>[{1: []}, {0: []}, {1: []}, {0: []}, {1: []}, ...</td>\n",
       "      <td>[1, 11, 35, 45, 69, 79, 103, 113, 138, 147, 17...</td>\n",
       "      <td>[n2-standard-2, n2-standard-2, n2-standard-2, ...</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, ...</td>\n",
       "      <td>[gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w, gk...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 10, 34, 44, 68, 78, 102, 112, 137, 146, 17...</td>\n",
       "      <td>[2.049088478088379, 2.0523953437805176, 6.0529...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>sleep</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>fifo_wait</td>\n",
       "      <td>constant</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>125</td>\n",
       "      <td>300</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1, 2, 4, 8]</td>\n",
       "      <td>[0.7, 0.15, 0.1, 0.05]</td>\n",
       "      <td>[100, 500, 1000, 50000]</td>\n",
       "      <td>[0.25, 0.25, 0.25, 0.25]</td>\n",
       "      <td>[test]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>True</td>\n",
       "      <td>gke_sky-burst_us-central1-c_mluo-onprem</td>\n",
       "      <td>gke_sky-burst_us-central1-c_mluo-cloud</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>cpu</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Index(['workload_type', 'batch_time', 'mean_du...</td>\n",
       "      <td>Index(['workload_type', 'batch_time', 'mean_du...</td>\n",
       "      <td>cpu</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>fifo_wait</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.7, 0.15, 0.1, 0.05]</td>\n",
       "      <td>[1, 2, 4, 8]</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>gke_sky-burst_us-central1-c_mluo-onprem</td>\n",
       "      <td>gke_sky-burst_us-central1-c_mluo-cloud</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>sleep</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>constant</td>\n",
       "      <td>10</td>\n",
       "      <td>nvidia-smi --query-gpu=index --format=csv,nohe...</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>125</td>\n",
       "      <td>5</td>\n",
       "      <td>[100, 500, 1000, 50000]</td>\n",
       "      <td>[0.25, 0.25, 0.25, 0.25]</td>\n",
       "      <td>[test]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 idx   \n",
       "0  [0, 1, 3, 4, 6, 7, 9, 10, 13, 14, 16, 17, 20, ...  \\\n",
       "\n",
       "                                             runtime   \n",
       "0  [33, 33, 33, 34, 33, 34, 34, 34, 34, 34, 33, 3...  \\\n",
       "\n",
       "                                             arrival   \n",
       "0  [-1.049088478088379, 8.947604656219482, 28.947...  \\\n",
       "\n",
       "                                            num_gpus   \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \\\n",
       "\n",
       "                                      allocated_gpus   \n",
       "0  [{1: []}, {0: []}, {1: []}, {0: []}, {1: []}, ...  \\\n",
       "\n",
       "                                 allocated_gpus_real   \n",
       "0  [{1: []}, {0: []}, {1: []}, {0: []}, {1: []}, ...  \\\n",
       "\n",
       "                                               start   \n",
       "0  [1, 11, 35, 45, 69, 79, 103, 113, 138, 147, 17...  \\\n",
       "\n",
       "                                       instance_type   \n",
       "0  [n2-standard-2, n2-standard-2, n2-standard-2, ...  \\\n",
       "\n",
       "                                          node_index   \n",
       "0  [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, ...  \\\n",
       "\n",
       "                                                node   \n",
       "0  [gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w, gk...  \\\n",
       "\n",
       "                                                cpus   \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \\\n",
       "\n",
       "                                     submission_time   \n",
       "0  [0, 10, 34, 44, 68, 78, 102, 112, 137, 146, 17...  \\\n",
       "\n",
       "                                          wait_times   \n",
       "0  [2.049088478088379, 2.0523953437805176, 6.0529...  \\\n",
       "\n",
       "                                            is_local job_type   \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...    sleep  \\\n",
       "\n",
       "                              image   \n",
       "0  gcr.io/sky-burst/skyburst:latest  \\\n",
       "\n",
       "                                        setup_script uniform_arrival   \n",
       "0  nvidia-smi --query-gpu=index --format=csv,nohe...              10  \\\n",
       "\n",
       "  uniform_submission waiting_policy    policy time_constrained cluster_size   \n",
       "0               True      fifo_wait  constant             True            2  \\\n",
       "\n",
       "  cpus_per_node gpus_per_node cloud_cluster_nodes cloud_cpu_per_node   \n",
       "0             8             8                   4                  8  \\\n",
       "\n",
       "  random_seed total_jobs batch_time wait_time time_out mean_duration   \n",
       "0          13        125        300        15        5            10  \\\n",
       "\n",
       "  arrival_rate cpu_sizes cpu_dist     gpu_sizes                gpu_dist   \n",
       "0           10       [1]      [1]  [1, 2, 4, 8]  [0.7, 0.15, 0.1, 0.05]  \\\n",
       "\n",
       "              memory_sizes               memory_dict train_names train_dist   \n",
       "0  [100, 500, 1000, 50000]  [0.25, 0.25, 0.25, 0.25]      [test]        [1]  \\\n",
       "\n",
       "  use_new_cluster                           onprem_cluster   \n",
       "0            True  gke_sky-burst_us-central1-c_mluo-onprem  \\\n",
       "\n",
       "                            cloud_cluster gpu_workload spill_to_cloud   \n",
       "0  gke_sky-burst_us-central1-c_mluo-cloud        False          False  \\\n",
       "\n",
       "  onprem_only collect_runtimes sample_real_workloads workload_type sched_tick   \n",
       "0       False            False                 False           cpu        0.1  \\\n",
       "\n",
       "  workload job_duration submit_time scheduler_submit_time   \n",
       "0      NaN          NaN         NaN                   NaN  \\\n",
       "\n",
       "                                      varying_values   \n",
       "0  Index(['workload_type', 'batch_time', 'mean_du...  \\\n",
       "\n",
       "                                        fixed_values workload_type_sweep   \n",
       "0  Index(['workload_type', 'batch_time', 'mean_du...                 cpu  \\\n",
       "\n",
       "  batch_time_sweep mean_duration_sweep waiting_policy_sweep cpu_dist_sweep   \n",
       "0              300                  10            fifo_wait            [1]  \\\n",
       "\n",
       "  cpu_sizes_sweep          gpu_dist_sweep gpu_sizes_sweep   \n",
       "0             [1]  [0.7, 0.15, 0.1, 0.05]    [1, 2, 4, 8]  \\\n",
       "\n",
       "  uniform_submission_sweep uniform_arrival_sweep   \n",
       "0                     True                    10  \\\n",
       "\n",
       "                      onprem_cluster_sweep   \n",
       "0  gke_sky-burst_us-central1-c_mluo-onprem  \\\n",
       "\n",
       "                      cloud_cluster_sweep cluster_size_sweep   \n",
       "0  gke_sky-burst_us-central1-c_mluo-cloud                  2  \\\n",
       "\n",
       "  gpus_per_node_sweep sched_tick_sweep wait_time_sweep spill_to_cloud_sweep   \n",
       "0                   8              0.1              15                False  \\\n",
       "\n",
       "  sample_real_workloads_sweep job_type_sweep   \n",
       "0                       False          sleep  \\\n",
       "\n",
       "                        image_sweep policy_sweep arrival_rate_sweep   \n",
       "0  gcr.io/sky-burst/skyburst:latest     constant                 10  \\\n",
       "\n",
       "                                  setup_script_sweep time_constrained_sweep   \n",
       "0  nvidia-smi --query-gpu=index --format=csv,nohe...                   True  \\\n",
       "\n",
       "  cpus_per_node_sweep cloud_cluster_nodes_sweep cloud_cpu_per_node_sweep   \n",
       "0                   8                         4                        8  \\\n",
       "\n",
       "  random_seed_sweep total_jobs_sweep time_out_sweep       memory_sizes_sweep   \n",
       "0                13              125              5  [100, 500, 1000, 50000]  \\\n",
       "\n",
       "          memory_dict_sweep train_names_sweep train_dist_sweep   \n",
       "0  [0.25, 0.25, 0.25, 0.25]            [test]              [1]  \\\n",
       "\n",
       "  use_new_cluster_sweep gpu_workload_sweep onprem_only_sweep   \n",
       "0                  True              False             False  \\\n",
       "\n",
       "  collect_runtimes_sweep  \n",
       "0                  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Check for ground truth  -- Compare the datapoints from parse_job_df to ensure there are no missing jobs \n",
    "\n",
    "def parse_job_df(cluster_event_df=None, submission_df=None, sweep_df=None, avoid_congestion=True, columns=None, run_id=None, cloud_log_list=None):\n",
    "    '''\n",
    "    Parse onprem jobs first\n",
    "    '''\n",
    "    hyperparameters = None\n",
    "    if 'hyperparameters' in submission_df: \n",
    "        hyperparameters = submission_df['hyperparameters']\n",
    "    \n",
    "    onprem_event_df = cluster_event_df['onprem']\n",
    "    cloud_event_df = cluster_event_df['cloud']\n",
    "    \n",
    "    job_names = {}\n",
    "    jobs = {}\n",
    "    for col in columns: \n",
    "        jobs[col] = []\n",
    "\n",
    "    all_nodes = set()\n",
    "    nodes = {}\n",
    "    node_counter = 0\n",
    "    types = ['onprem', 'cloud']\n",
    "    nodes_indices = {}\n",
    "    \n",
    "    #import pdb; pdb.set_trace()\n",
    "    print(cloud_log_list)\n",
    "    \n",
    "    for cluster_type in types: \n",
    "        event_df = cluster_event_df[cluster_type]\n",
    "        try:\n",
    "            job_times = {}\n",
    "            pod_times = {}\n",
    "            if cluster_type == 'cloud':\n",
    "                for job in cloud_log_list[1:-1]:\n",
    "                    match = re.search(r\"Cloud Job \\|\\| job id (\\S+) \\| job name (\\S+) \\| estimated cloud start time (\\S+) \\| estimated job duration (\\S+) \\| submission time (\\S+) \\| gpus (\\S+) \\| cpus (\\S+)\", job)\n",
    "                    match = match.groups()\n",
    "                    if match:\n",
    "                        job_id = int(match[0])\n",
    "                        job_name = str(match[1])\n",
    "                        submit = float(match[2])\n",
    "                        duration = float(match[3])\n",
    "                        arrival = float(match[4])\n",
    "                        gpu = int(match[5])\n",
    "                        cpu = int(match[6])\n",
    "                        end = submit + 2 + duration \n",
    "                        \n",
    "                        times = {\"arrival\": arrival,\"submit\": submit,\"pod_start\": submit + 2, \"job_end\": end, \"gpu\": gpu, \"cpu\":cpu}\n",
    "                        print(f'matched time {times}')\n",
    "\n",
    "                        missing = False\n",
    "                        for v, k in times.items(): \n",
    "                            if not k: \n",
    "                                print(f'Missing {v} {k}')\n",
    "                                missing = True\n",
    "                        print(f'value {times}')\n",
    "                    \n",
    "                        pod_times[job_id] = times\n",
    "                intervals = pod_times\n",
    "                nodes[\"cloud\"] = node_counter\n",
    "                #print(pod_times)\n",
    "                print(f'Cloud Jobs {len(intervals)}')       \n",
    "            else:   \n",
    "                cluster = event_df\n",
    "                start_times = cluster['container_start_times']\n",
    "                creation_times = cluster['job_creation_times']\n",
    "                completion_times = cluster['job_completion_times']\n",
    "                # TODO: Verify node names works as intended\n",
    "                pod_nodes = cluster['node_name']\n",
    "                job_pods = cluster['job_pods']\n",
    "                pod_jobs = {value: key for key, value in job_pods.items()}\n",
    "                node_instances = cluster['node_instances']\n",
    "\n",
    "                job_start_times = {}\n",
    "                job_end_times = {}\n",
    "                pod_start_times = {}\n",
    "\n",
    "                for pod in start_times:\n",
    "                    pod_name = pod\n",
    "                    pod_start_time = start_times[pod]\n",
    "                    pod_start_times[pod_name] = pod_start_time   \n",
    "\n",
    "                for job in creation_times:\n",
    "                    job_name = job\n",
    "                    job_start_time = creation_times[job]\n",
    "                    job_start_times[job_name] = job_start_time\n",
    "\n",
    "                for job in completion_times:\n",
    "                    job_name = job\n",
    "                    job_end_time = completion_times[job]\n",
    "                    job_end_times[job_name] = job_end_time\n",
    "                       \n",
    "                for pod in pod_nodes: \n",
    "                    all_nodes.add(pod_nodes[pod])\n",
    "\n",
    "                for job in job_start_times:\n",
    "                    if job in job_end_times:\n",
    "                        job_times[job] = [job_start_times[job], job_end_times[job]]\n",
    "                    \n",
    "                    job_name = job\n",
    "                    if job_name in {'job-87', 'job-85'}: \n",
    "                            if job_name in job_start_times and job_name not in job_end_times: \n",
    "                                #1684842795\n",
    "                                missing_times = {\n",
    "                                    'job-87': 7897,\n",
    "                                    'job-85': 8999\n",
    "\n",
    "                                }\n",
    "                                job_end_times[job_name] = job_start_times[job_name] + missing_times[job_name]\n",
    "\n",
    "                for pod in pod_start_times:\n",
    "                    if pod in pod_jobs:\n",
    "                        job = pod_jobs[pod]\n",
    "                        if job not in job_end_times:\n",
    "                            print(\"MISSING JOB \" + str(job))\n",
    "                        job_id = re.findall(r'\\d+', job)[0]\n",
    "                            \n",
    "                        sub_time = submission_df[job_id]['scheduler_submit_time']\n",
    "                        if job not in job_end_times: \n",
    "                            job_end_times[job] = sub_time + 100000\n",
    "                            print(\"MISSING JOB \" + str(job))\n",
    "                            \n",
    "                        pod_times[job] = [sub_time, job_end_times[job]]\n",
    "                        #import pdb; pdb.set_trace()\n",
    "\n",
    "                        times = {\"arrival\": submission_df[job_id]['scheduler_submit_time'], \\\n",
    "                                 # Submit is also job start time\n",
    "                                 \"submit\": job_start_times[job], \\\n",
    "                                 \"pod_start\": pod_start_times[pod], \\\n",
    "                                 \"job_end\": job_end_times[job], \\\n",
    "                                }\n",
    "                        print(f'matched time {times}')\n",
    "                        missing = False\n",
    "                        for v, k in times.items(): \n",
    "                            if not k: \n",
    "                                print(f'Missing {v} {k}')\n",
    "                                missing = True\n",
    "                                #continue\n",
    "                        #if not missing:\n",
    "                        print(f'value {times}')\n",
    "                        if not times['job_end']:\n",
    "                            times['job_end'] = times['submit'] + 1000000\n",
    "                            \n",
    "                        if job_id in {'87', '85'}: \n",
    "                            missing_runtime = times['job_end'] - times['pod_start']\n",
    "                            print(f'MISSING RUNTIME {job_id} {missing_runtime}')\n",
    "                        pod_times[job] = times\n",
    "                        #else: \n",
    "                            #print(\"MISSING JOB \" + str(job))\n",
    "\n",
    "                # TODO: Possible cause of error \n",
    "                for n in all_nodes:\n",
    "                    nodes[n] = node_counter\n",
    "                    node_counter += 1\n",
    "\n",
    "                intervals = pod_times\n",
    "                print(f'Onprem Jobs {len(intervals)}')\n",
    "                \n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            print(f'matched time {times}')\n",
    "            trace = traceback.format_exc()\n",
    "            print(trace)\n",
    "\n",
    "        gpu_indices = {}\n",
    "        gpu_num = 0\n",
    "        gpu_nums = {}\n",
    "        gpu_node = {} #mapping from gpu_uuid to node_name\n",
    "        node_gpus = {} #mapping from node_name to gpu_uuid to int [0, 7]\n",
    "        print(f'interval {intervals}')\n",
    "        for i, (key, value) in enumerate(intervals.items()):\n",
    "            try:\n",
    "                print(f'{cluster_type} value {value}')\n",
    "                if cluster_type == 'cloud':\n",
    "                    #print(key)\n",
    "                    job_id = str(key)\n",
    "                else:\n",
    "                    job_id = re.findall(r'\\d+', key)[0] #e.g. \"sleep-26-100444\"\n",
    "                job_names[i] = key\n",
    "                jobs['idx'].append(int(job_id))\n",
    "                jobs['runtime'].append(value['job_end']-value['pod_start'])\n",
    "                jobs['start'].append(value['pod_start'])\n",
    "                jobs['arrival'].append(value['arrival'])\n",
    "                jobs['submission_time'].append(value['submit'])\n",
    "                #print(f'{cluster_type} value {value}')\n",
    "                \n",
    "                if cluster_type == 'cloud':\n",
    "                    #print(value)\n",
    "                    jobs['num_gpus'].append(value['gpu'])\n",
    "                    #TODO: Verify cpu value for cloud jobs\n",
    "                    jobs['cpus'].append(value['cpu'])\n",
    "                else:\n",
    "                    jobs['num_gpus'].append(submission_df[job_id]['workload']['gpu'])\n",
    "                    jobs['cpus'].append(submission_df[job_id]['workload']['cpu'])\n",
    "\n",
    "                # TODO: Cleanup\n",
    "                if avoid_congestion:\n",
    "                    submit_time = cluster['job_creation_times'][key] #Job start time\n",
    "                else:\n",
    "                    submit_time = submission_df[job_id]['scheduler_submit_time'] #Job submission time\n",
    "                \n",
    "                if not submit_time:\n",
    "                    jobs['wait_times'].append(0)\n",
    "                else:\n",
    "                    jobs['wait_times'].append(value['pod_start']-value['arrival'])\n",
    "\n",
    "                if cluster_type == \"cloud\":\n",
    "                    jobs['is_local'].append(0)\n",
    "                else:\n",
    "                    jobs['is_local'].append(1)\n",
    "                \n",
    "                #if cluster_type == 'cloud':\n",
    "                \n",
    "                if cluster_type == 'cloud':\n",
    "                    jobs['instance_type'].append(\"unknown\")\n",
    "                    jobs['node'].append(\"cloud\")\n",
    "                    jobs['allocated_gpus'].append({})\n",
    "                    jobs['node_index'].append(len(all_nodes) + 1)\n",
    "                    jobs['allocated_gpus_real'].append({len(all_nodes): [i for i in range(value['gpu'])]})\n",
    "                    #break\n",
    "                    continue\n",
    "                \n",
    "                if job_pods[key] not in pod_nodes:\n",
    "                    jobs['instance_type'].append(\"unknown\")\n",
    "                    jobs['allocated_gpus'].append({})\n",
    "                    jobs['node_index'].append(None)\n",
    "                    jobs['allocated_gpus_real'].append({1: []})\n",
    "                    break\n",
    "                \n",
    "                if job_pods[key] in pod_nodes:\n",
    "                    jobs['instance_type'].append(node_instances[pod_nodes[job_pods[key]]])\n",
    "                else:\n",
    "                    jobs['instance_type'].append(\"unknown\")\n",
    "\n",
    "                if job_pods[key] in pod_nodes:\n",
    "                    jobs['allocated_gpus'].append({nodes[pod_nodes[job_pods[key]]]: []})\n",
    "                    jobs['node_index'].append(nodes[pod_nodes[job_pods[key]]])\n",
    "                else:\n",
    "                    jobs['allocated_gpus'].append({})\n",
    "                    jobs['node_index'].append(None)\n",
    "                \n",
    "                if job_pods[key] in pod_nodes:\n",
    "                    jobs['node'].append(pod_nodes[job_pods[key]])\n",
    "                else:\n",
    "                    jobs['node'].append(\"unknown\")\n",
    "            \n",
    "                if 'gpu_index' in cluster:\n",
    "                    gpu_index = cluster['gpu_index'][job_pods[key]]\n",
    "                    gpu_pod = job_pods[key]\n",
    "                    gpu_index = gpu_index.partition(\"||\")[0]\n",
    "                    gpu_index = gpu_index.split(\"\\n\")\n",
    "                    \n",
    "                    for index in gpu_index:\n",
    "                        if index != \"\":\n",
    "                            gpu_node[index] = pod_nodes[gpu_pod]\n",
    "                            if pod_nodes[gpu_pod] not in node_gpus:\n",
    "                                node_gpus[pod_nodes[gpu_pod]] = {}\n",
    "                            if index not in node_gpus[pod_nodes[gpu_pod]]:\n",
    "                                node_gpus[pod_nodes[gpu_pod]][index] = len(node_gpus[pod_nodes[gpu_pod]])\n",
    "\n",
    "                        if index != \"\" and index not in gpu_indices:\n",
    "                            # TODO: Clean up later\n",
    "                            gpu_indices[index] = gpu_num\n",
    "                            gpu_num += 1\n",
    "                    gpu_index = [node_gpus[pod_nodes[gpu_pod]][index] for index in gpu_index if index]\n",
    "                    jobs['allocated_gpus_real'].append({nodes[pod_nodes[job_pods[key]]]: gpu_index})\n",
    "                else:\n",
    "                    jobs['allocated_gpus_real'].append({nodes[pod_nodes[job_pods[key]]]: []})\n",
    "            except Exception as e:\n",
    "                import traceback\n",
    "                trace = traceback.format_exc()\n",
    "                print(trace)\n",
    "                if cluster_type == \"cloud\":\n",
    "                    print('cloud')\n",
    "                else:\n",
    "                    print('onprem')\n",
    "                \n",
    "    if not jobs['arrival']:\n",
    "        print(\"No job arrival times logged!\")\n",
    "    \n",
    "    #print(f'nodes {nodes}')\n",
    "    print(jobs)\n",
    "    modified_arrival = [a for a in jobs['arrival'] if a]\n",
    "    #min_arrival = min(modified_arrival)\n",
    "    min_arrival = min(jobs['arrival'])\n",
    "    #print(f'minarrival {min_arrival}')\n",
    "    modified_submission = [s for s in jobs['submission_time'] if s]\n",
    "    #min_submission = min(modified_submission)\n",
    "    min_submission = min(jobs['submission_time'])\n",
    "    #print(f'minsubmission {min_submission}')\n",
    "    min_arrival = min_submission\n",
    "    #min_arrival = min(jobs['submission_time'])\n",
    "    jobs['arrival'] = [i - min_arrival for i in jobs['arrival']]\n",
    "    jobs['submission_time'] = [i - min_arrival for i in jobs['submission_time']]\n",
    "    jobs['start'] = [i - min_arrival for i in jobs['start']]\n",
    "    #jobs['arrival'] = np.array(jobs['arrival'])\n",
    "    jobs['num_gpus'] =  np.array(jobs['num_gpus'])\n",
    "    \n",
    "    hyperparameters = submission_df['hyperparameters']\n",
    "\n",
    "    for k, v in hyperparameters.items():\n",
    "        jobs[k] = v\n",
    "\n",
    "    sweep_metrics = sweep_df[str(run_id)]\n",
    "    jobs[\"varying_values\"] = sweep_df[\"varying_values\"].keys()\n",
    "    jobs[\"fixed_values\"] = sweep_df[\"fixed_values\"].keys()\n",
    "\n",
    "    for k, v in sweep_metrics.items():\n",
    "        jobs[k + \"_sweep\"] = v\n",
    "    \n",
    "    with open(\"wait\" + str(submission_df['hyperparameters']['wait_time']) + \"uni\" + str(submission_df['hyperparameters']['uniform_arrival']) + \".pkl\", 'wb') as file:\n",
    "        pickle.dump(jobs, file)\n",
    "\n",
    "    return jobs, len(all_nodes), hyperparameters\n",
    "\n",
    "def parse_jobs_df(event_number=logs, avoid_congestion=False):\n",
    "    #test = log_jobs.retrieve_events_df(event_number=logs, avoid_congestion=False, only_dict=False)\n",
    "    #print(test)\n",
    "    #print(len(test))\n",
    "    #TODO: Move log_jobs from local to remote repo\n",
    "    events_dfs, sweep_df = log_jobs.retrieve_events_df(event_number=logs, avoid_congestion=False, only_dict=False)\n",
    "    #cluster_event_data_df, submission_data_df, sweep_data_df\n",
    "    columns=['idx', 'runtime', 'arrival', 'num_gpus', 'allocated_gpus', 'allocated_gpus_real', 'start', 'instance_type', 'node_index', 'node', 'cpus', 'submission_time', 'wait_times', 'is_local']\n",
    "    runs = {}\n",
    "    runs_list = []\n",
    "    for run_id, events_df in events_dfs.items():\n",
    "        cluster_event_df, submission_df, cloud_log_list = events_df\n",
    "        display(submission_df)\n",
    "        estimated_runtimes = []\n",
    "        for job in submission_df:\n",
    "            if job == 'hyperparameters':\n",
    "                continue\n",
    "            #estimated_runtimes.append((job, submission_df[job][\"job_duration\"]))\n",
    "            estimated_runtimes.append(submission_df[job][\"job_duration\"])\n",
    "            #print(job)\n",
    "            #print(submission_df[job][\"job_duration\"])\n",
    "        print(estimated_runtimes)\n",
    "        onprem_df, cloud_df = cluster_event_df\n",
    "        try:\n",
    "            run, _, _ = parse_job_df(cluster_event_df=cluster_event_df, submission_df=submission_df, sweep_df=sweep_df, avoid_congestion=False, columns=columns, run_id=run_id, cloud_log_list=cloud_log_list)\n",
    "            runs[run_id] = pd.Series(run)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            trace = traceback.format_exc()\n",
    "            print(trace)\n",
    "    runs_df = pd.DataFrame.from_dict(runs)\n",
    "    runs_df = runs_df.transpose()\n",
    "    return runs_df\n",
    "\n",
    "jobs_df = parse_jobs_df(event_number=logs, avoid_congestion=False)\n",
    "#jobs_df = jobs_df[0:2]\n",
    "display(jobs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9682cb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "31\n",
      "31\n",
      "19\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "[30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 31.139336585998535, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 34, 35, 41.956106424331665]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[-1.049088478088379, 8.947604656219482, 28.947017908096313, 38.95293354988098, 58.94248056411743, 68.94533371925354, 88.94910383224487, 98.949702501297, 128.94757866859436, 138.9466691017151, 158.9440896511078, 168.945077419281, 198.98471856117249, 208.9453604221344, 229.12214040756226, 239.12153506278992, 259.16593074798584, 269.24351143836975, 298.94131302833557, 19.3279767036438, 49.398452043533325, 79.47113084793091, 109.7337954044342, 119.76970100402832, 149.64533853530884, 179.90450716018677, 189.92744517326355, 219.7985463142395, 249.86203026771545, 279.15371894836426, 289.18548035621643]\n",
      "[1, 11, 35, 45, 69, 79, 103, 113, 138, 147, 172, 182, 205, 216, 240, 250, 274, 284, 310, 36.36122512817383, 66.43536186218262, 96.51107335090637, 126.5892186164856, 136.61158800125122, 166.679265499115, 196.7422158718109, 206.76417350769043, 236.82963109016418, 266.8961434364319, 295.9679663181305, 305.99244809150696]\n",
      "0    [0, 10, 34, 44, 68, 78, 102, 112, 137, 146, 17...\n",
      "Name: submission_time, dtype: object\n",
      "0    [33, 33, 33, 34, 33, 34, 34, 34, 34, 34, 33, 3...\n",
      "Name: runtime, dtype: object\n",
      "0    [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, ...\n",
      "Name: node_index, dtype: object\n",
      "['gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu', 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu', 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu', 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu', 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu', 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu', 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu', 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu', 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu', 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w', 'cloud', 'cloud', 'cloud', 'cloud', 'cloud', 'cloud', 'cloud', 'cloud', 'cloud', 'cloud', 'cloud', 'cloud']\n",
      "['n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown']\n",
      "[{1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]\n",
      "[{1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}]\n"
     ]
    }
   ],
   "source": [
    "if 'workload_type' in jobs_df: \n",
    "    print(jobs_df['workload_type'][0])\n",
    "print(len(jobs_df['runtime'][0]))\n",
    "print(len(jobs_df['is_local'][0]))\n",
    "print(sum(jobs_df['is_local'][0]))\n",
    "print(len(jobs_df['arrival'][0]))\n",
    "print(len(jobs_df['start'][0]))\n",
    "print(len(jobs_df['submission_time'][0]))\n",
    "print(len(jobs_df['runtime'][0]))\n",
    "print(len(jobs_df['node'][0]))\n",
    "print(len(jobs_df['node_index'][0]))\n",
    "print(len(jobs_df['instance_type'][0]))\n",
    "print(len(jobs_df['allocated_gpus'][0]))\n",
    "print(len(jobs_df['allocated_gpus_real'][0]))\n",
    "\n",
    "print(sorted(jobs_df['runtime'][0]))\n",
    "print(jobs_df['is_local'][0])\n",
    "print(jobs_df['arrival'][0])\n",
    "print(jobs_df['start'][0])\n",
    "print(jobs_df['submission_time'])\n",
    "print(jobs_df['runtime'])\n",
    "print(jobs_df['node_index'])\n",
    "print(jobs_df['node'][0])\n",
    "print(jobs_df['instance_type'][0])\n",
    "print(jobs_df['allocated_gpus'][0])\n",
    "print(jobs_df['allocated_gpus_real'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "609cf673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobs_df['arrival_mask'] = jobs_df['start'].apply(lambda x: [0 if not i else 1 for i in x])\n",
    "jobs_df['arrival_mask'] = jobs_df['is_local']#.apply(lambda x: [0 if not i else 1 for i in x])\n",
    "jobs_df['onprem_mask'] = jobs_df['arrival_mask']\n",
    "\n",
    "# CLIP WAITS\n",
    "\n",
    "def cloud_wait_unclipped(row): \n",
    "    cloud_wait = [row['wait_times'][i] for i, n in enumerate(row['arrival_mask']) if n == 0]\n",
    "    return cloud_wait\n",
    "jobs_df['cloud_wait_unclipped'] = jobs_df.apply(cloud_wait_unclipped, axis=1)\n",
    "\n",
    "def clipped_wait(row): \n",
    "    k8s_scheduling_waiting_constant = 1 #wait_time_2\n",
    "    onprem_wait = [row['wait_times'][i] for i, n in enumerate(row['arrival_mask']) if n == 1]\n",
    "    cloud_wait = [k8s_scheduling_waiting_constant + row['wait_time'] for i, n in enumerate(row['arrival_mask']) if n == 0]\n",
    "    new_wait = onprem_wait + cloud_wait\n",
    "    return new_wait\n",
    "\n",
    "jobs_df['wait_times'] = jobs_df.apply(clipped_wait, axis=1)\n",
    "\n",
    "def cloud_wait(row): \n",
    "    k8s_scheduling_waiting_constant = 1 #wait_time_2\n",
    "    cloud_wait = [k8s_scheduling_waiting_constant + row['wait_time'] for i, n in enumerate(row['arrival_mask']) if n == 0]\n",
    "    return cloud_wait\n",
    "jobs_df['cloud_wait'] = jobs_df.apply(cloud_wait, axis=1)\n",
    "\n",
    "\n",
    "def onprem_wait(row): \n",
    "    k8s_scheduling_waiting_constant = 1 #wait_time_2\n",
    "    onprem_wait = [row['wait_times'][i] for i, n in enumerate(row['arrival_mask']) if n == 1]\n",
    "    return onprem_wait\n",
    "\n",
    "jobs_df['onprem_wait'] = jobs_df.apply(onprem_wait, axis=1)\n",
    "\n",
    "# COMPUTE METRICS\n",
    "\n",
    "jobs_df['avg_wait'] = jobs_df['wait_times'].apply(lambda x: sum(x)/len(x))\n",
    "jobs_df['avg_runtime'] = jobs_df['runtime'].apply(lambda x: sum(x)/len(x))\n",
    "\n",
    "def compute_total_time(row):\n",
    "    total_time = [row['wait_times'][i] + row['runtime'][i] for i in range(len(row['wait_times']))]\n",
    "    return total_time\n",
    "\n",
    "\n",
    "jobs_df['total_time'] = jobs_df.apply(compute_total_time, axis=1)\n",
    "\n",
    "def compute_completion_time(row):\n",
    "    # TODO: Submission time is time submitted to starburst \n",
    "    #completion_time = [row['total_time'][i] + row['submission_time'][i] for i in range(len(row['wait_times']))]\n",
    "    completion_time = [row['total_time'][i] + row['arrival'][i] for i in range(len(row['wait_times']))]\n",
    "    return completion_time\n",
    "\n",
    "jobs_df['completion_time'] = jobs_df.apply(compute_completion_time, axis=1)\n",
    "#jobs_df['avg_jct'] = jobs_df['total_time'].apply(lambda x: sum(x)/len(x))\n",
    "\n",
    "def compute_avg_jct(row):\n",
    "    arrival_times = row['arrival']\n",
    "    run_time = row['runtime']\n",
    "    wait_time = row['wait_times']\n",
    "    resources = row['num_gpus']\n",
    "    starts = row['start']\n",
    "    idxes = row['idx']\n",
    "    is_locals = row['is_local']\n",
    "    sort_zip = sorted(zip(idxes, arrival_times, run_time, starts, resources, wait_time))\n",
    "    \n",
    "    #start = sort_zip[10][1]\n",
    "    #end = sort_zip[-10][1]\n",
    "    \n",
    "    total_used_space = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for l in sort_zip:\n",
    "        #job_idx = l[0]\n",
    "        #job_arrival = l[1]\n",
    "        job_runtime = l[2]\n",
    "        job_wait_time = l[1]\n",
    "        #job_start = l[3]\n",
    "        job_gpus = l[4]\n",
    "        wait_time = l[5]\n",
    "        #inter_start = max(job_start, start)\n",
    "        #inter_end = min(job_start + job_runtime, end)\n",
    "        #if inter_end >= inter_start:\n",
    "        #    total_used_space+= job_gpus * (inter_end - inter_start)\n",
    "        total_time += job_runtime\n",
    "        total_time += wait_time\n",
    "        \n",
    "    jct = total_time/len(sort_zip)#total_used_space/(row['cluster_size']*4*row['gpus_per_node']*(end-start))\n",
    "    jct = jct/3600\n",
    "    return jct\n",
    "jobs_df['avg_jct'] = jobs_df.apply(compute_avg_jct, axis=1)\n",
    "\n",
    "def compute_cluster_utilization(row):\n",
    "    arrival_times = row['arrival']\n",
    "    run_time = row['runtime']\n",
    "    resources = row['num_gpus']\n",
    "    starts = row['start']\n",
    "    idxes = row['idx']\n",
    "    is_locals = row['is_local']\n",
    "    sort_zip = sorted(zip(idxes, arrival_times, run_time, starts, resources, is_locals))\n",
    "    \n",
    "    start = sort_zip[0][1]\n",
    "    end = sort_zip[-1][1]\n",
    "    \n",
    "    total_used_space = 0\n",
    "    for l in sort_zip:\n",
    "        job_idx = l[0]\n",
    "        job_arrival = l[1]\n",
    "        job_runtime = l[2]\n",
    "        job_start = l[3]\n",
    "        job_gpus = l[4]\n",
    "        is_local = l[5]\n",
    "        if is_local==1:\n",
    "            inter_start = max(job_start, start)\n",
    "            inter_end = min(job_start + job_runtime, end)\n",
    "            #import pdb; pdb.set_trace()\n",
    "            if inter_end >= inter_start:\n",
    "                total_used_space+= job_gpus * (inter_end - inter_start)\n",
    "    cluster_utilization = total_used_space/(row['cluster_size']*4*row['gpus_per_node']*(end-start))\n",
    "    #import pdb; pdb.set_trace()\n",
    "    return cluster_utilization\n",
    "        \n",
    "#     # TODO: Remove previous arrival and \n",
    "#     print(row['arrival'])\n",
    "#     surface_area = [row['runtime'][i] * row['num_gpus'][i] for i in range(len(row['runtime']))]\n",
    "#     utilized_surface_area = sum(surface_area)\n",
    "#     total_surface_area = (max(row['completion_time']) - min(row['submission_time'])) * (row['gpus_per_node'] * 1) #row['cluster_size'])\n",
    "#     cluster_utilization = utilized_surface_area/total_surface_area\n",
    "#     return cluster_utilization\n",
    "\n",
    "jobs_df['cluster_utilization'] = jobs_df.apply(compute_cluster_utilization, axis=1)\n",
    "\n",
    "def compute_system_utilization(row):\n",
    "    arrival_times = row['arrival']\n",
    "    run_time = row['runtime']\n",
    "    resources = row['num_gpus']\n",
    "    starts = row['start']\n",
    "    idxes = row['idx']\n",
    "    is_locals = row['is_local']\n",
    "    sort_zip = sorted(zip(idxes, arrival_times, run_time, starts, resources, is_locals))\n",
    "    \n",
    "    start = sort_zip[0][1]\n",
    "    end = sort_zip[-1][1]\n",
    "    \n",
    "    total_used_space = 0\n",
    "    for l in sort_zip:\n",
    "        job_idx = l[0]\n",
    "        job_arrival = l[1]\n",
    "        job_runtime = l[2]\n",
    "        job_start = l[3]\n",
    "        job_gpus = l[4]\n",
    "        is_local = l[5]\n",
    "        inter_start = max(job_start, start)\n",
    "        inter_end = min(job_start + job_runtime, end)\n",
    "        if inter_end >= inter_start:\n",
    "            total_used_space += job_gpus * (inter_end - inter_start)\n",
    "    system_utilization = total_used_space/(row['cluster_size']*4*row['gpus_per_node']*(end-start))\n",
    "    \n",
    "    return system_utilization\n",
    "\n",
    "jobs_df['system_utilization'] = jobs_df.apply(compute_system_utilization, axis=1)\n",
    "\n",
    "        \n",
    "#     # TODO: Remove previous arrival and \n",
    "#     print(row['arrival'])\n",
    "#     surface_area = [row['runtime'][i] * row['num_gpus'][i] for i in range(len(row['runtime']))]\n",
    "#     utilized_surface_area = sum(surface_area)\n",
    "#     total_surface_area = (max(row['completion_time']) - min(row['submission_time'])) * (row['gpus_per_node'] * 1) #row['cluster_size'])\n",
    "#     cluster_utilization = utilized_surface_area/total_surface_area\n",
    "#     return cluster_utilization\n",
    "\n",
    "\n",
    "#def compute_system_utilization(row):\n",
    "    # TODO: Compute this value correctly\n",
    "    #return system_utilization\n",
    "\n",
    "#jobs_df['cluster_utilization'] = jobs_df.apply(compute_cluster_utilization, axis=1)\n",
    "GCP_PRICES = {\n",
    "    \"e2-medium\": 0.038795,\n",
    "    \"e2-standard-8\": 0.31036,\n",
    "    \"unknown\": 0.038795,\n",
    "    \"n1-standard-96\": 4.56 \n",
    "}\n",
    "\n",
    "\n",
    "def compute_total_cost(row):\n",
    "    run_time = row['runtime']\n",
    "    resources = row['num_gpus']\n",
    "    idxes = row['idx']\n",
    "    is_locals = row['is_local']\n",
    "    sort_zip = sorted(zip(idxes, run_time, resources, is_locals))\n",
    "\n",
    "    \n",
    "    total_cloud_cost = 0\n",
    "    for l in sort_zip:\n",
    "        job_idx = l[0]\n",
    "        job_runtime = l[1]\n",
    "        job_gpus = l[2]\n",
    "        is_local = l[3]\n",
    "        if is_local==0:\n",
    "            total_cloud_cost += job_runtime * job_gpus\n",
    "\n",
    "    return total_cloud_cost/3600\n",
    "    # TODO: Compute this value correctly\n",
    "    # Get all cloud runtimes + submit \n",
    "#     total_time = [row['runtime'][i] * row['num_gpus'][i] * (1 - row['arrival_mask'][i]) * GCP_PRICES[row['instance_type'][i]] for i in range(len(row['arrival_mask']))]\n",
    "#     return sum(total_time)\n",
    "\n",
    "jobs_df['total_cloud_cost'] = jobs_df.apply(compute_total_cost, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5be22e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-9rfu',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-2k2w',\n",
       " 'cloud',\n",
       " 'cloud',\n",
       " 'cloud',\n",
       " 'cloud',\n",
       " 'cloud',\n",
       " 'cloud',\n",
       " 'cloud',\n",
       " 'cloud',\n",
       " 'cloud',\n",
       " 'cloud',\n",
       " 'cloud',\n",
       " 'cloud']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df\n",
    "jobs_df['node'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "55400294",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 11), (2, 35), (3, 45), (4, 69), (5, 79), (6, 103), (7, 113), (8, 138), (9, 147), (10, 172), (11, 182), (12, 205), (13, 216), (14, 240), (15, 250), (16, 274), (17, 284), (18, 310), (19, 19.3279767036438), (20, 49.398452043533325), (21, 79.47113084793091), (22, 109.7337954044342), (23, 119.76970100402832), (24, 149.64533853530884), (25, 179.90450716018677), (26, 189.92744517326355), (27, 219.7985463142395), (28, 249.86203026771545), (29, 279.15371894836426), (30, 289.18548035621643)]\n",
      "start times\n",
      "[1, 11, 35, 45, 69, 79, 103, 113, 138, 147, 172, 182, 205, 216, 240, 250, 274, 284, 310, 36.36122512817383, 66.43536186218262, 96.51107335090637, 126.5892186164856, 136.61158800125122, 166.679265499115, 196.7422158718109, 206.76417350769043, 236.82963109016418, 266.8961434364319, 295.9679663181305, 305.99244809150696]\n",
      "[0, 10, 34, 44, 68, 78, 102, 112, 137, 146, 171, 180, 204, 215, 239, 249, 273, 283, 309, 34.36122512817383, 64.43536186218262, 94.51107335090637, 124.5892186164856, 134.61158800125122, 164.679265499115, 194.7422158718109, 204.76417350769043, 234.82963109016418, 264.8961434364319, 293.9679663181305, 303.99244809150696]\n",
      "pod scheduling time (seconds)\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "run locally (1=local, 0=cloud)\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "allocated_gpus_real\n",
      "[{1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}, {2: []}]\n",
      "allocated_gpus\n",
      "[{1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {1: []}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]\n",
      "[-1.049088478088379, 8.947604656219482, 28.947017908096313, 38.95293354988098, 58.94248056411743, 68.94533371925354, 88.94910383224487, 98.949702501297, 128.94757866859436, 138.9466691017151, 158.9440896511078, 168.945077419281, 198.98471856117249, 208.9453604221344, 229.12214040756226, 239.12153506278992, 259.16593074798584, 269.24351143836975, 298.94131302833557, 19.3279767036438, 49.398452043533325, 79.47113084793091, 109.7337954044342, 119.76970100402832, 149.64533853530884, 179.90450716018677, 189.92744517326355, 219.7985463142395, 249.86203026771545, 279.15371894836426, 289.18548035621643]\n",
      "IDs\n",
      "[0, 1, 3, 4, 6, 7, 9, 10, 13, 14, 16, 17, 20, 21, 23, 24, 26, 27, 30, 2, 5, 8, 11, 12, 15, 18, 19, 22, 25, 28, 29]\n",
      "RUNTIME\n",
      "[33, 33, 33, 34, 33, 34, 34, 34, 34, 34, 33, 33, 34, 33, 33, 33, 35, 33, 33, 30.0, 30.0, 30.0, 31.139336585998535, 30.0, 30.0, 30.0, 30.0, 41.956106424331665, 30.0, 30.0, 30.0]\n",
      "VERIFYING\n",
      "[-1.049088478088379, 8.947604656219482, 19.3279767036438, 28.947017908096313, 38.95293354988098, 49.398452043533325, 58.94248056411743, 68.94533371925354, 79.47113084793091, 88.94910383224487, 98.949702501297, 109.7337954044342, 119.76970100402832, 128.94757866859436, 138.9466691017151, 149.64533853530884, 158.9440896511078, 168.945077419281, 179.90450716018677, 189.92744517326355, 198.98471856117249, 208.9453604221344, 219.7985463142395, 229.12214040756226, 239.12153506278992, 249.86203026771545, 259.16593074798584, 269.24351143836975, 279.15371894836426, 289.18548035621643, 298.94131302833557]\n",
      "cloud runtimes (seconds)\n",
      "[30.0, 30.0, 30.0, 31.139336585998535, 30.0, 30.0, 30.0, 30.0, 41.956106424331665, 30.0, 30.0, 30.0]\n",
      "onprem runtimes (seconds)\n",
      "[33, 33, 33, 34, 33, 34, 34, 34, 34, 34, 33, 33, 34, 33, 33, 33, 35, 33, 33]\n",
      "0 31 31 31\n",
      "workload type\n",
      "cpu\n",
      "gpus\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "cpus list\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "allocated_gpus\n",
      "[{1: [1]}, {0: [1]}, {1: [1]}, {0: [1]}, {1: [1]}, {0: [1]}, {1: [1]}, {0: [1]}, {1: [1]}, {0: [1]}, {1: [1]}, {0: [1]}, {1: [1]}, {0: [1]}, {1: [1]}, {0: [1]}, {1: [1]}, {0: [1]}, {1: [1]}, {3: [1]}, {3: [1]}, {3: [1]}, {3: [1]}, {3: [2]}, {3: [1]}, {3: [1]}, {3: [2]}, {3: [1]}, {3: [2]}, {3: [1]}, {3: [2]}]\n",
      "j_idx 19\n",
      "gpu_idx 1\n",
      "j_idx 20\n",
      "gpu_idx 1\n",
      "j_idx 21\n",
      "gpu_idx 1\n",
      "j_idx 22\n",
      "gpu_idx 1\n",
      "j_idx 23\n",
      "gpu_idx 2\n",
      "j_idx 24\n",
      "gpu_idx 1\n",
      "j_idx 25\n",
      "gpu_idx 1\n",
      "j_idx 26\n",
      "gpu_idx 2\n",
      "j_idx 27\n",
      "gpu_idx 1\n",
      "j_idx 28\n",
      "gpu_idx 2\n",
      "j_idx 29\n",
      "gpu_idx 1\n",
      "j_idx 30\n",
      "gpu_idx 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workload type\n",
      "cpu\n",
      "gpus\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "cpus list\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "allocated_gpus\n",
      "[{1: [1]}, {0: [1]}, {1: [1]}, {0: [1]}, {1: [1]}, {0: [1]}, {1: [1]}, {0: [1]}, {1: [1]}, {0: [1]}, {1: [1]}, {0: [1]}, {1: [1]}, {0: [1]}, {1: [1]}, {0: [1]}, {1: [1]}, {0: [1]}, {1: [1]}, {3: [1]}, {3: [1]}, {3: [1]}, {3: [1]}, {3: [2]}, {3: [1]}, {3: [1]}, {3: [2]}, {3: [1]}, {3: [2]}, {3: [1]}, {3: [2]}]\n",
      "j_idx 0\n",
      "gpu_idx 39\n",
      "j_idx 1\n",
      "gpu_idx 47\n",
      "j_idx 2\n",
      "gpu_idx 39\n",
      "j_idx 3\n",
      "gpu_idx 47\n",
      "j_idx 4\n",
      "gpu_idx 39\n",
      "j_idx 5\n",
      "gpu_idx 47\n",
      "j_idx 6\n",
      "gpu_idx 39\n",
      "j_idx 7\n",
      "gpu_idx 47\n",
      "j_idx 8\n",
      "gpu_idx 39\n",
      "j_idx 9\n",
      "gpu_idx 47\n",
      "j_idx 10\n",
      "gpu_idx 39\n",
      "j_idx 11\n",
      "gpu_idx 47\n",
      "j_idx 12\n",
      "gpu_idx 39\n",
      "j_idx 13\n",
      "gpu_idx 47\n",
      "j_idx 14\n",
      "gpu_idx 39\n",
      "j_idx 15\n",
      "gpu_idx 47\n",
      "j_idx 16\n",
      "gpu_idx 39\n",
      "j_idx 17\n",
      "gpu_idx 47\n",
      "j_idx 18\n",
      "gpu_idx 39\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAHvCAYAAABKceUIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6MElEQVR4nO3deXhV1b3/8U/meYAEhBAIY64KiCKJKFIGB6wWcULbokAZRJR6lerV0muhtdZre+21FB4nMKDWoe1FxPmhzBAqoMwzyIwMYQghExnW7w9u9u+cTGdIwjkL3q/nyeMOZ+3vWvusmP3J3vvsHWKMMQIAALBIaKAHAAAA4CsCDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgnfBADwAAEHghISHOMjdohw04AoMG27dvn6ZOnaof/vCHyszMVFJSkmJiYtS+fXv16dNHv/71r7V69epADxOwQkhIiPO1ePHiQA8HCFohPAsJ/srLy9OUKVP0+uuvq7y83GP7QYMG6b//+7/VrVu3CzA6wE6uR0IWLVqk/v37X/B+2S3ABpxCgl+2bNmi2267TQcOHHD+LTw8XL1791ZGRoaioqJ0+PBh5ebm6syZM5Kkr776SosXL9Zf//pX3XvvvYEaOgDgIkCAgc+2bNmiG2+8UadOnZIkRURE6KmnntIvfvELpaSkuLUtLS3Vhx9+qKeeekrHjx9XaWmp7r//fr399tsaNmxYIIYPALgIcAoJPikpKVFWVpY2bdokSYqNjdXnn3+ufv361bve999/r379+mnnzp2SpLi4OH377bfKzMxs8jEDNuEUEuAdLuKFT37/+9874UWS3nnnHY/hRZJat26t+fPnKyEhQZJUWFiosWPHNtk4AQAXNwIMvFZUVKTp06c7399111265557vF4/IyNDv/nNb5zvly5dqlWrVtXatn///jU+iXHy5Em99NJLysrKUmpqqmJiYtSxY0eNHj3aLVTVZeTIkU7NWbNmSZJOnDihl156SdnZ2WrRooViYmLUqVMnPfzww1q7dq3HmrNmzXJqjhw5UpJUUVGhDz74QEOGDFHHjh0VExOjkJAQzZ07t9Yaq1ev1pNPPqmrr75aLVq0UGRkpFq1aqV+/frppZdeck7V1ad9+/bOOPbu3StJ2rVrl55++ml169bN+WRYjx499Pvf/15FRUU1amzfvl0TJkxQ9+7dlZiYqOTkZPXu3VvTp09XRUWFxzH464svvtC4cePUrVs3paSkKCIiQsnJyerZs6fGjRunefPm1XqR+OLFi51trjpKYYzRnDlzdOeddyojI0PR0dFq1aqVbr31Vr399tuqrKysdyx79+51arZv396r8df23l9IZ8+e1dSpUzVo0CClp6crOjpazZo1U7du3TRhwgR9/fXXftdevXq1xowZo8zMTMXFxal58+bKzs7Wiy++6Fzb5s34XnvtNd1xxx1q166dYmNjFRERoaSkJF1++eUaPHhwjT+MAK8YwEuzZs0ykpyvpUuX+lyjoKDAxMfHOzVGjhxZa7t+/fo5bRYtWmSWL19u2rRp49a/61dYWJh544036u17xIgRTvucnByTm5tr0tLS6q05efLkemvm5OQ47UeMGGEOHTpkbrzxxlrrffTRR27rnjx50tx777119l/1lZycbP7+97/XO46MjAyn/Z49e8w777xjYmNj66x5zTXXmJMnTzrrP//88yY0NLTO9v379zeFhYX1jsFXmzZtMr169fK4/ZLMAw88UGP9RYsWOa/369fPnDlzxgwZMqTeOtdff705evRonWPas2eP0zYjI8Or7aj+3jeU63gXLVpUb9tPPvnEtGrVyuP799Of/tTj/Lm2N8aYyZMn1/sz0aZNG5Obm1tvzdzc3Hr/v63+VVZW5tN7hUsbF/HCa4sWLXKW27Ztq759+/pcIz4+XkOGDNFf//pXSfLqPhebNm3SL3/5S509e1YtW7ZU3759lZKSokOHDmnhwoUqLi5WRUWFHnnkEXXv3l29e/f2WHPfvn2aOHGiTp06pfj4eA0cOFCXXXaZDh8+rEWLFqmoqEgVFRX6zW9+o8rKSv32t7/1WLO0tFR33nmnvvnmG4WHh+uGG25Qp06dVFpaqm+//dat7ZEjRzRw4EBt3brV+beuXbuqR48eio+P17Fjx7Rs2TKdOHFCp0+f1v3336933nnHqwufv/jiC02YMEGVlZXq0qWLsrOzFR0drQ0bNjj341m7dq1+/OMf66uvvtKLL76o5557TpJ01VVXqUePHgoPD9eqVau0efNmSefnaeLEiXrttdc89u+NxYsX684771RBQYHzb+3atVN2draaN2+uwsJCbd++XevXr1dZWZlKSko81hw5cqQ+/vhjhYSEKDs7W1deeaVKS0uVm5vrHBlZuXKlbrrpJq1YsUKJiYmNsi2B8uGHH2rYsGHO0bGwsDDdeOON6ty5s86ePatly5bp8OHDkqT33ntPe/bs0cKFCxUdHe2x9tSpU52jpZ07d9Z1112nyMhIbdy4UWvWrJEkHTp0SLfddpuWLFmiq6++ukaNAwcOaNCgQc4cR0REKCsrS507d1ZsbKwKCwu1d+9erV+/3uujOYCbQCco2KNTp07OX0r33Xef33WmTp3q9lfXwYMHa7RxPQITFRVlwsLCzMsvv1zjL7T9+/ebbt26OW0HDBhQZ7+uR2AiIyONJDNs2DCTn5/v1u7kyZPmnnvucdqGhoaaFStW1FrT9QhMeHi4czSgtr/ES0pKjDHGVFRUmAEDBjjrZWdnm2+//bZG++LiYjNlyhQTEhJiJJm4uDjz3Xff1ToO16MAUVFRJiEhodajNh988IEJCwtz2v7P//yPCQsLM2lpaWbx4sU12r/88stu70NjHGHYv3+/SU1Ndep26NDBfPHFF7W2PXnypHnttdfMU089VeM11yMwVfPZoUMHs3r16hpt33zzTRMREeG0f/jhh2vtz5YjMLt27XI7kpmdnW127tzp1qaiosK8/PLLbkdRfv7zn3vVb2RkpImOjjbvvvtujXbVj4Z2797dnDt3rka7J554wmnTt29fc+jQoVr7LSsrM4sXLzbDhg0z5eXl9bwzgDsCDLxWtYOWZKZMmeJ3nYULF7r9sly+fHmNNq4BRpJ5/fXX66y3ceNGZycfEhJiDh8+XGs71wAjydx+++2moqKi1rZlZWWmf//+br+Aa+MaYKp+mRcVFdW7/W+//bbTvnfv3h7bT5482Wn/yCOP1NrGdScaEhJi5s+fX2e9MWPGuI05JibGbNmypc72N998s9P2pZdeqnes3hg2bJhbSDhy5IhfdVwDTFXA27VrV53tZ8yY4fYe1dbWlgAzfPhwp03nzp3N6dOn66z3pz/9yS2E1hWCXfuVZD744IM6a27atMlERUU5bWfOnFmjzbXXXuu8Xj1cAY2BAAOv5Ofnu/1y+/Of/+x3rbVr17rVmjdvXo02rgGme/fuHmtmZ2fXW88Y9wBT1w7M1YYNG9zGuW3bthptqgeYzz//3ONYr776aqf9unXrPLYvLi42ycnJRpJJSkqqNXS57kSHDBlSb70FCxa4jfmJJ56ot/3MmTOdtvfee6/H8dbn4MGDbkG4riMv3qgeYJ577jmP67juVJ999tkar9sQYE6dOuUWHubMmVNvvYqKCtO1a9d6t7t6v3UFdlcTJ050C+LVdenSxXm9voAF+ItPIcErrtcqSOfv4+Kv+Ph4t+89nf8eOnSox5rXXHONs+zNJ0Gqrk+pT/fu3d3qul4DVJtmzZrp1ltvrbfN999/r3Xr1kmSrrzySvXo0cPjWKOjo3X99ddLkvLz8z1+WuO+++6r9/Xu3bv71N710Q979uypt60n//znP51PFHXp0kW33XZbg+q5Gj58uE9tPM1nsMrNzVVpaakkKTU1VYMHD663fWhoqEaNGuV87812e/NejhgxwllevXq1CgsL3V5v27ats9xY104BrriIF16pun9Lleq/rHxx9uxZt+89XUxZfYdbG9c7AHtzQWBVIPCmXdXHqT19rPrqq69WWFhYvW1WrlzpLBcXF2vChAlejWP37t3O8oEDB3TVVVfV2dbTs6aaNWvm9n3Xrl3rbd+8eXNnuaEXW/7rX/9ylhvzBm2pqanq3Lmzx3au875u3ToZY9xu4GYD15/D7OxshYd7/jXep08ft/U9bbc3/390795d8fHxOnv2rCoqKrRhwwa39e6//34tXLhQkvTss89q/vz5GjZsmG655Ralp6d7rA94QoCBVxITExUeHu789Xzy5Em/a1W/r4nrDrI2SUlJHmtGREQ4y2VlZR7bt2vXzmOb6u2OHz9eb9sWLVp4rFf1qRDp/NEM1/vqeMvTfWE8vV/Vd3i+tPfmva3P0aNHneWOHTs2qJYrf+aztLRUBQUF1n0ayfXnMCMjw6t1XO9pc+7cOY/b7c37GRISovT0dG3btq3GuCRpzJgx+vLLL537Hy1YsEALFixw6vft21cDBgzQkCFDlJqa6tV2AK44hQSvuf6ybMhNp6qv6+mGYU3xF3JsbKxX7VxPlVU/jVZdTEyMx3r5+fle9VsfT0/+9vX9upBHIFzfw+qnEhvCn/msPh5buB7B9PZUrq/b3Rj/f4SFhWnOnDmaMWOGrrzySrfX9u/fr7/+9a8aM2aM0tLSNGbMmAb9UYRLEwEGXnM9DN2Qu3u6rtu+fXu1adOmQePyR213oq2N66my6qfR/OH6C//OO++UOX8hvU9fVXf8tZHre1j9VGJD+DOf1cfjL093921srsHP21O5vm53Y/3/ERISotGjR2vz5s3avn273njjDY0YMcLt6FtZWZlmzpyp7Oxsj0c5AVcEGHhtwIABzvLBgwe1dOlSn2ucPXtWH3/8ca01L6T9+/d71e7AgQPOcmMc5r7sssuc5SNHjjS4nm1ct7+hFwS7cp0nb9tFRUXV2Om6nor0dKSrSmMcVfOF66lKb3+OXS9sj4yM9BhgvKlrjNGhQ4ec7z39/5GZmamxY8dq1qxZ2r17t7Zv366JEyc6143t3r3b7VEjgCcEGHht6NChbheA/ulPf/K5xptvvun2l/cjjzzSKGPzlevFpPVxvei2Z8+eDe73uuuuc5bXrVvXoIuhbeR6l+TG/BTQ8ePH3S50rovrfF599dU1Tp+5Xhdy6tQpj09l3r9//wW/i6zrJ+NWrVrl1XOqcnNz3db3dNrQm/8/Nm3a5Jw2CgsL8+oTda4yMzP18ssvu4WWefPm+VQDlzYCDLwWFxenRx991Pn+448/1kcffeT1+vv27dOvf/1r5/sf/OAHys7ObtQxemvFihUejwBs3rzZ7REAjfGpmY4dO+qKK66QdP5iypkzZza4pk1uueUW56LgnTt36quvvmq02u+8845PbWo7+peQkOBcVF5UVKQdO3bUW+9vf/ubj6NsuBtuuEFRUVGSzge3zz77rN72lZWVysnJcb4fOHCgxz7effddj23efvttZzkrK8vvWyvceeedzrLrRd6AJwQY+GTSpEluF+Q9+OCDXp1KOnLkiG699Vbn6EtcXJzefPPNJhunJ8YY/fu//3udf2FXVFTo8ccfd76/8cYbdfnllzdK388884yz/J//+Z/auHGj1+vaftopLS1NDzzwgPP9uHHjGm2n9ac//aneUDpr1iznWVBV12bUxvUoWdVTy2tz8OBBvfjii/4NtgGSk5Pd3sOnn3663otyp02b5vyMhYaG6uGHH/bYx+LFi/WPf/yjzte3bt2qadOmOd+PGTOmRpu8vDyP/Ujup/Vatmzp1TqAJHEnXvhs48aNJikpybnLZkREhJk0aZLJy8ur0ba0tNTMnj3btGzZ0u125rU9Y8VV9adRe+J6u/26niBd27OQhg8fbs6cOePW7uTJk2bo0KFud+1dtmxZrTWrP43aG+Xl5WbgwIHOeomJiea1114zpaWltbbPz8837777runXr1+dz6Dy9W6wcrnrqif+3J22Pvv37zfNmzd3anbo0MF8+eWXtbY9deqUef31183TTz9d47XanoXUqVMn880339Ro+9ZbbzltJJkxY8bUOb533nnHre4//vGPGm1WrlxpOnbsaEJCQtzqBupZSNdff73ZvXu3W5uKigrzyiuvuD37ypdnIcXExJj33nuvRrvc3FzTtm1bp23Xrl1r/dmNiYkxDz/8sFm8eHGdj+xYvXq16dixo1Nr7Nix9bwzgDsCDPyyceNGk56e7vZLLzw83PTt29c8+OCDZtSoUeaHP/yhW9CRzj9o8G9/+5vH+k0dYCZPnuzcnj8hIcEMGTLEjB071gwePNjExcW5jXnSpEl19utPgDHGmLy8PHPNNde49ZOYmGgGDRpkRo0aZcaOHWvuu+8+0717d7db79d1K3+bAowxxvzzn/902wFX1R46dKgZN26cGTZsmMnKynIewFjb4xFcA0y/fv3M3Xff7QTO66+/3owaNcoMGzbMbQcpyVxxxRX13tq+rKzM9OjRw22dnj17mlGjRpkRI0a4zduUKVMC8iwkY2o+mDM8PNwMGDDAjBkzxvz4xz92e+Ci/u92/8XFxV71+8orrzjLXbp0MQ8++KD52c9+ZrKystzaxcfHmzVr1nisl5CQ4PxuGDdunLn33nvdHm8gybRo0aLOBz4CtSHAwG9Hjx41jzzyiNsOtr6vW2+91WzYsMGr2k0dYHJycsyKFStM69at6xxvWFiY+dWvflVvv/4GGGOMKSoq8un9i4mJMb///e9rrWVbgDHGmHXr1tUICnV9DRs2rMb61QNMfn6++dGPflRvneuuu858//33Hsf23Xff1Qg+rl8hISHmV7/6lamsrGzUAFNZWenWz9KlS+tt/8knn5jLLrvM4/v3k5/8xBQWFtZbq/rPxHPPPec8JLW2r7S0tFofxFqlekCt76tHjx5m69atvr9huKRxJ174rWXLlnr11Vf1zDPPaO7cufryyy+1a9cuHTt2TGVlZWrRooXS09M1cOBADRkyRFlZWYEespsbbrhB69ev1xtvvKGPPvpIe/fu1dmzZ5WWlqaBAwfq0UcfbZRPHtUlJibGef/effddLVy4UDt27NCJEydUWVmppKQkdezYUT169NBNN92k2267zbq7xtanR48eWrt2rebOnau5c+dq5cqVOnr0qAoLC5WYmKiOHTsqOztbgwcP1qBBgzzWS0xM1Lx58/SPf/xDs2fP1oYNG3T06FElJyfrqquu0rBhwzR8+HCFhnq+9K9Dhw7asGGD/vKXv2jOnDnasWOHSktLlZaWpr59+2r8+PFu18o0lpKSErfvPd3s70c/+pF27dqlt956S59++qk2b96svLw8xcTEKC0tTQMGDNDw4cP9Gutvf/tb3X777XrjjTe0bNkyHT58WBEREercubPuuecePfbYY/XexfnEiRNaunSplixZotWrV2vnzp06evSoSkpKFBsbq/T0dF177bW69957deedd3o1L4CrEGM8fE4QuEiMHDlSs2fPliTl5ORYfUM4nL/QtOqTRP369dPixYsDO6BGcPDgQbeHIO7Zs8fjnaqBSxWRFwCCxNatW53l2NhYr591BFyKCDAAECRc76t03XXXWfekbOBCIsAAQBD47LPP3G5s+NOf/jSAowGCHxfxAkCATJgwQcXFxdq0aZNWrVrl/PuVV16pESNGBHBkQPAjwABAgEyfPr3Gv3Xu3Fmffvqp24MlAdREgAGAAIqIiFDz5s3VrVs33XXXXRo7dqzzrCMAdQvox6grKyt1+PBhJSQkcLEaAACWMMaooKBAaWlpAbuHT0CPwBw+fNjtngcAAMAeBw4cUHp6ekD6DmiASUhIkHT+DXC9w+iRI0eUM2WKBsfEKDU2xue6eUXFeu/kSYUlSw9kN1dqku81tu3P06sLVunxZ7KV3i7V5/Ulace2PP3x9VW6/clstfazxoFteXr/9fW69sk7lNrOvye15m37XqteX63sJycotV0bP2vs0qo/fKjsO59Saqt2/tXYv02r335d1/d8Uqmp/tU4nrdNW1e9rgezn1RrL2uYynIVLbxHsQPn6EzpaW0o/kRPTPmZWrVq5dcYAOBSd+bMGbVt29bZjwdCQANM1WmjxMREtwBTWFioqMhIdWiWrNZ+vDkJBQWKKihQWKTUoXWyWqf6XqOopEwREaFql5Gkzl38Cx/FRWUKjwhVy4wktfGzRmlRmcIiwpSUkaLULq39qlFWdE6hEeFKymij1C6d/KxRrNDwCCVdlqHUtl38q1FapNCwCCUnZSg11c8aZUUKC41Qq6QMtfOyhqks0/6wMLVL7aIThXnaXhGlhISEi+q2/AAQCIG8/IP7wAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwTnigB1Cf44VFDV7v+Gn/apw4U3z+v3nFiosv8KvGyRPna5zJK9ZJP2uc+b8axXlnVRB/2q8axSfO/l+NUyqIP+pnjVPn/5ufp4IT8f7VyD8hSSoqzlNBgX81iorP18gvzlOelzVMZbkkKa/giPJLTvnVLwAguARlgImNjVVEaqrm5OVJxcX+1bjsMilGmrO+QJLvNUpKy1VpkvX5J+WKjDzh1xhKSsoVVZGs3Z+U64CfNUpLypVUkaDyT47ohJ81yktKlVwRpvJPluhEZKSfNUqUHF6p8m2f6MRuP2uUlig5qUKl5Z/o2An/apwrL1FMcoU2lX+iHV7WCKmsVC9JS0+8KRMaqvjUCMXGxvrVPwAgOIQYY0ygOj9z5oySkpKUn5+vxMREt9fy8/NVVOTf0RNJzg6qITXKysoUERHh9/rUCI4aleXlWnLbber35ZcKDQ9XbGyskpKSGjQGALiU1bf/vlCC8giMJCUlJTXKToYdFSrLyiRJrVu1UmgDwxMAIDhwES8AALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALBOeKAHIEl5eXkqLS0N9DBwkaosL5ckHc/LU2h4UPzIA4DVCgoKAj2E4AgwnTp1CvQQcBELk/T2lVeqTVqaKgI9GABAo+AUEgAAsA4BBgAAWIcAAwAArBMU18Ds3r1bCQkJgR4GLlKV5eVacPPNOnT4MBfxAkAjKCgoCPj1q0Hx2zw1NVWJiYmBHgYuUpVlZZKkFqmpCo2ICPBoAMB+UVFRgR4Cp5AAAIB9CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsE54oAcgSfn5+SosLPR7/djYWElSUVGR3zXKysoUERHh9/qNVeNi2pZgqREdGSlJ+v7IEYWG+/cjHxsbq6SkpAaNAwDQeIIiwLzxh5cVVuB/gKlIiJMiKxRWUuDX+iWl57R53w51vyZTkf+3s/O5Rsk5fbtth/7tqkxF+FlDksIqElSiUBWEnfVr/XMl57Rj8wFldr/K7205V1KqHWt3K/Pyq/2vUVqiHd9uVman7v7XOFeifVs3q2tn/2tIUlRcma6V9OavXpNC/TvoGJEaqQnPPU6IAYAgERQBpvzEKQ1NSlOL2Hif1z1edFazj+5XWFyZHuyWohaJsT7X2HLwuLbtPa3BN4erfbsUn9eXpC3bjmv1jtPqMThcbdr7V+PU8SItnn1Up8PClfJga8W28OP92HJEp7eVKnxwT6W0b+PXOI5v+U6nv/lO4VmDlZLe3r8au7fo9NJtCk8arJTL/KxxZIsKT21TRvhgtU7xr8aZouPacCxHknR3zO1qGd/K93EU5WlO3qcqKioiwABAkAiKACNJLWLj1TrBz53Dif+rkRir1s0SfF796OnzRztSm8eodSvf15eko8fO10hOjVFqa/9qnHd+Y2JbxCuhdaLPa589ev4oVExqshJat/BrBGePnh9DTHKqElq09q/GiaPna8SlKiHJzxoF52skxqSqeYJ/NVylxqaqdYLvAUaSVNzg7gEAjYiLeAEAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYJzyQnRtjJEmlZee05/QJFZSW+Fwjr7hQpWVlCjtXpj3HTquguNTnGvtP5KusvFL7DuTLKMLn9SVp/8F8lZdV6vt9+Qox/tU4lVesc6VlKgszOr3nhEoLfN+W/P2nVFlWrvx93yvC+DUM5e8/osryMuV/v08RIf4Vyf9+vyorypR/ap8iwv2scWq/KirLdCx/n0L93JiC4jydKytVUUWF9p7ep8KyYp9r5BWfVOm5UhUUFCguLs6vcQDAxeTMmTOS/v9+PBBCTAB7/+6779SpU6dAdQ8AABpg9+7d6tixY0D6DugRmObNm0uS9u/fr6SkpEAO5ZJ35swZtW3bVgcOHFBiYmKgh3PJYz6CB3MRPJiL4JGfn6927do5+/FACGiACQ09fwlOUlISP4xBIjExkbkIIsxH8GAuggdzETyq9uMB6TtgPQMAAPiJAAMAAKwT0AATFRWlyZMnKyoqKpDDgJiLYMN8BA/mIngwF8EjGOYioJ9CAgAA8AenkAAAgHUIMAAAwDoEGAAAYB0CDAAAsE6DA8y+ffv0i1/8Qpdffrni4uLUvHlzZWVl6Y9//KOKiooaY4ySpC+++EJ333230tPTFRUVpfT0dN1999364osvGq0P2zXlXFRWVmrLli2aNWuWHn30UWVlZSkqKkohISEKCQnR4sWLG2cjLhLMRXBpyvkoKirSnDlzNH78eGVlZalZs2aKiIhQSkqKrr/+ek2ZMkVHjhxppC2xH3MRPJpyLrZu3app06ZpxIgR6tmzp9LT0xUdHa24uDh17NhRDzzwgD7++OOGPUvJNMC8efNMYmKikVTrV2Zmptm5c2dDujAVFRVm9OjRdfYhyYwZM8ZUVFQ0qB/bNfVczJo1q945WLRoUeNtjOWYi+DSlPOxfv16Ex8fX+98SDKJiYnmgw8+aOQtsw9zETya+vfUsGHDPM6FJNOvXz+Tl5fnVx9+B5hvv/3WxMTEGEkmPj7evPDCCyY3N9csWLDAjB071u1NOHPmjL/dmGeffdapdc0115j333/frFq1yrz//vvmmmuucV775S9/6XcftrsQc5GTk+PUiYiIMD179jTdu3dnp1kNcxFcmno+li1b5tTo06ePefHFF838+fPNt99+a7766iszbtw4ExoaaiSZsLAw8/nnnzfBVtqBuQgeF+L31IgRI8x1111nJk6caHJycswXX3xh1qxZY+bPn2/+8pe/mG7dujn9XH/99X4dhPA7wPTt29dIMuHh4SY3N7fG63/4wx+cwU2ePNmvPrZv327Cw8ONJNOrVy9TVFTk9nphYaHp1auXM46GHu2x1YWYi6+//tpMnTrVrFy50hQXFxtjjJk8eTI7zWqYi+DS1POxYsUKc//995vNmzfX2Wbu3LkmJCTESDKdOnUylZWVPvdzMWAugseF+D1VVlZW7+vl5eXmnnvucfr5+OOPfe7DrwDz9ddfO52OGzeu1jYVFRXmiiuuMJJMcnKyOXfunM/9jB8/3uln5cqVtbZZuXKl0+bRRx/1uQ/bXai5qA07TXfMRXAJ5HxUd++99zpj+eabb5qkj2DGXASPYJoL1/33U0895fP6fl3EO3fuXGf5Zz/7Wa1tQkNDNXz4cEnS6dOntWjRIp/6MMbo448/liRdfvnl6t27d63tevfurX/7t3+TpIZfEGShCzEX8A5zEVyCaT4GDBjgLO/evbtJ+ghmzEXwCKa5SEhIcJZLSkp8Xt+vALN8+XJJUlxcnK699to62/Xr189ZXrFihU997NmzR4cPH65Rp75+Dh06pL179/rUj+0uxFzAO8xFcAmm+SgtLXWWw8LCmqSPYMZcBI9gmosPPvjAWb788st9Xj/cn063bt0qSercubPCw+su4TqgqnW8tWXLllrreNNPhw4dfOrLZhdiLuAd5iK4BNN8LFmyxFm+4oormqSPYMZcBI9Az0VeXp527typGTNmKCcnR5KUmpqqYcOG+VzL5wBTUlKivLw8SVJ6enq9bZs1a6a4uDgVFhbqwIEDPvVz8OBBZ9lTP23btnWWfe3HZhdqLuAZcxFcgmk+1q9fr88++0yS1L1790tup8lcBI9AzUX//v3dgqOr1NRUffTRR0pOTva5rs+nkAoKCpzl+Ph4j+3j4uIkSWfPnm2yfqr68Kcfm12ouYBnzEVwCZb5KC0t1ZgxY1RRUSFJeuGFFxq1vg2Yi+ARLHNR5fHHH9fWrVt14403+rW+X0dgqkRGRnpsHxUVJUkqLi5usn6q+vCnH5tdqLmAZ8xFcAmW+ZgwYYLWrFkjSRoxYoQGDx7cqPVtwFwEj0DNRU5OjgoLC2WM0enTp7VmzRq9+uqrmjZtmr777jvNmDFDl112mc91fQ4w0dHRzvK5c+c8tq+6YComJqbJ+nG9KMvXfmx2oeYCnjEXwSUY5uPFF1/UjBkzJElZWVmaPn16o9W2CXMRPAI1F9WvS+3bt6/Gjx+voUOH6tNPP1VWVpZyc3M9ntaqzudTSK4fe/LmsFJhYaEk7w5X+dtPVR/+9GOzCzUX8Iy5CC6Bno/XX39dkyZNknT+YsjPP//c7VT3pYS5CB6BngtX0dHRysnJUWxsrA4cOKD/+I//8LmGzwEmOjpaKSkpktwvtK3NqVOnnDfA9UJbb7gmMU/9uF5g5Gs/NrtQcwHPmIvgEsj5eP/99/Xoo49KkjIyMjR//nylpqY2uK6tmIvgEWy/p1JTU9WnTx9J5+/jVlZW5tP6ft0H5sorr5Qk7dq1S+Xl5XW227Ztm7Ps69XeVX1Ur9PY/djuQswFvMNcBJdAzMe8efM0fPhwVVZWqnXr1lqwYIHPh8UvRsxF8Ai231MtWrSQdP5J4lWfkPKWXwGm6orhwsJCffPNN3W2c/3YVFXK8laHDh2UlpZWo05tli5dKklq06aN2rdv71M/trsQcwHvMBfB5ULPx4IFC3T//fervLxcKSkpmj9/vjp16uR3vYsJcxE8gu331KFDh5xln09V+fP8Ap6FFDx4/k7wYC6Cy4WcjxUrVpi4uDgjySQlJZk1a9Y0ZOgXHeYieATTs5AOHDhgIiMjjSSTkZHh8/oBexr1okWLnNdHjBhRax/bt283YWFhdT6NuqioyO1p1Dt27PB3c6x2IeaiNuw0a2IugsuFmI+1a9ea5ORkI8nExcWZ5cuXN/JWXByYi+DR1HOxfft2s2DBgnrHcPr0aWccksxzzz3n83b49SgBSfrzn/+sPn36qLi4WLfeeqsmTZqkAQMGqLi4WB988IHeeOMNSVJmZqZ+8Ytf+NVHZmamnn76af3Xf/2X1qxZoz59+uiZZ55Rp06dtHv3br300ktau3atJOnpp59Wly5d/N0cq12IuZCkWbNmuX2/bt06Z/nLL790ew5V586d/b45kc2Yi+DS1POxe/duDRo0SKdPn5Yk/e53v1NSUpI2bdpU5zotW7ZUy5Yt/doemzEXwaOp5+Lw4cO66aab1KNHD91111269tpr1apVK4WHh+vIkSNasWKFZs6cqSNHjkiSunXrpmeffdb3DfE58riYN2+eSUxMdBJU9a/MzEyzc+fOWtf19i/NiooKM2rUqDr7kGRGjx5tKioqGrIp1rsQc1HfHFT/8uXowcWGuQguTTkfOTk5Ps2F6viL9lLBXASPppwL19c9fd1xxx3m2LFjfm2DXxfxVhk8eLA2bNigJ598UpmZmYqNjVVycrJ69erlHB3p3LlzQ7pQaGioZs6cqc8++0xDhgxRWlqaIiMjlZaWpiFDhujzzz/XjBkzFBraoE2x3oWYC3iHuQguzEfwYC6CR1PORZ8+ffTVV1/p6aef1oABA9SlSxclJiYqPDxczZs317XXXqvHHntMy5cv16effup8EslXIcYY49eaAAAAAXJpH7YAAABWIsAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMECQmDVrlkJCQhQSEqK9e/cGejgX3Pbt2xUZGano6GgdOnSoxutV782UKVMu/OB89Mc//lEhISHq379/oIcCXLQIMEAD7d2719m5NuTrUjdx4kSVlZVp9OjRatOmTaCH0yDjx49XSkqKlixZojlz5gR6OMBFiQADIOByc3P1+eefKzIyUs8++2ygh9Ng8fHxmjhxoiTp17/+tSorKwM8IuDiEx7oAQC2a9OmjTZu3Fjn6927d5ck9erVSzk5OXW269atm0aOHNnYw7PC7373O0nS0KFD1bZt2wCPpnE89thjev7557V582bNnTtX99xzT6CHBFxUCDBAA0VERKhbt24e28XFxXnV7lKzfft2ffnll5KkBx98MMCjaTxJSUm6/fbbNWfOHE2dOpUAAzQyTiEBCKicnBwZY9SyZUvdfPPNgR5Ooxo2bJgkacmSJdq9e3eARwNcXAgwQJDw9Cmk/v37u32yZdeuXXrkkUfUsWNHxcTEqH379ho9erT27dvntt6mTZv0s5/9TB07dlR0dLTatm2r8ePH69ixY16Na+7cuRo6dKjatWun6OhoJScnq1evXvrNb36jU6dONXSz9be//U2SNGTIEIWHe39QePXq1frJT36i9PR0RUVFqU2bNnrooYe0devWOtep/h6XlpbqlVdeUe/evZWamlrrp5wWLlyon/zkJ+rQoYNiYmIUGxurjIwM9e7dW0899ZQWLlxYZ3933HGHoqOjJUnvv/++19sGwAsGQJOSZCSZfv361dsuJyfHabtnz54ar/fr18+pM3/+fJOQkOC0d/1q2bKl2bp1qzHGmPfee89ERkbW2i4jI8McOnSozvGcPHnSDBw4sNZ1XftauXKl3+/N3r17nVozZ86st21Vu8mTJ5vp06eb8PDwWscUGxtrlixZUmsN1/d49erV5uqrr66x/uTJk532TzzxRL3bL8mkpKTUO+7evXsbSeaGG27w+f0BUDeOwACWOXz4sO6//34lJyfrL3/5i77++mstW7ZMTzzxhEJCQnTs2DGNGTNGq1ev1vDhw9WpUyfNmDFDq1at0qJFi/TQQw9Jkvbt2+d8Uqa60tJS3XzzzVq4cKHCwsL00EMP6f3339e//vUvLVu2TC+88IJSUlJ07Ngx3X777TWO+nhr2bJlznJWVpZX63z11Vf6+c9/rq5du+qtt97S6tWrtXTpUj355JMKDQ1VUVGRHnroIZ07d67eOqNHj9b69es1fPhwffbZZ/rmm2/00Ucf6brrrpMkffrpp3rllVckSVdddZVeffVVLV68WGvXrtWiRYs0bdo03XXXXYqKiqq3n+zsbEnSqlWrVFJS4tU2AvBCoBMUcLFTIx+BkWS6dOlijh07VqPNU0895bRp0aKFueGGG0xhYWGNdkOHDjWSTHh4eK11Jk2aZCSZ5ORks2bNmlrHu3fvXtO6dWsjyfz0pz+td9vqMn78eCPJREZGmvLy8nrbyuWox+23325KS0trtPnd737ntJkzZ06N113fY0lmxowZdfb30EMPOUeqCgoK6mx34sSJesc9e/Zsp79//etf9bYF4D2OwAAWmjp1qlq0aFHj3x999FFnOS8vTzNmzFBsbGyNduPHj5cklZeXa+XKlW6vnT17VtOnT5ckPf/887r22mtrHUNGRoaee+45SdLf//53FRYW+rwdBw8elCSlpKQoLCzMq3Wio6OVk5OjyMjIGq89/vjjzr+7Ht2pzcCBAzV69Og6Xz9y5IgkqWfPnoqPj6+zXfPmzevtp2XLls7yd999V29bAN4jwACWSU5O1qBBg2p9rUOHDkpISJB0/rTHFVdcUWu7Hj16OMvVd6pLlixRfn6+JOm+++6rdyw/+MEPJEllZWX65ptvvNsAF8ePH5ckNWvWzOt1brnlFrdQ4CohIUFdunSR5DksVH1CqC6tW7eWJC1durRBnyByDThVoQhAwxFgAMt06dKl3kcPJCcnS5IyMzM9tpGkgoICt9fWrFnjLLdu3brexx+43tfGn53zyZMnJfkWYC6//PJ6X68KDNW3q7qrrrqq3teHDx8uSTpx4oS6deumH//4x8rJydGuXbu8Hqvkvm3+HKUCUDsCDGCZ2k4JuQoNDfXYrqqNJFVUVLi95u3Hq6srKiryeZ2qjxgXFxd7vY632199u6rzFJpuuukmTZs2TTExMSopKdGHH36oUaNGqUuXLkpPT9cjjzyi9evXexyv67ZFRER4bA/AO9yJF4Ab1x3/t99+6/VONz093ee+qq7jqToScyF5c83NY489pqFDh+q9997T/PnztWLFCuXn5+vQoUN6/fXX9cYbb2jSpEnOoxBq47ptrke+ADQMAQaAm5SUFGe5RYsWfgUTb1UFmMa4IV5TadmypZ544gk98cQTqqys1Lp16/TRRx9p2rRpOn36tF544QVlZWVpyJAhta7vum3t2rW7UMMGLnqcQgLg5pprrnGWV6xY0aR9VT3oMj8/3+9TVxdSaGioevbsqeeff14LFixw/r3qbsK12bFjh7PctWvXJh0fcCkhwABwc/PNNzvXmUydOlXGmCbrq2/fvs7y6tWrm6yfptCzZ0/nOpq8vLw621VtV+vWrTkCAzQiAgwAN8nJyZowYYIkKTc3V08++aQqKyvrbH/06FHNmDHDr76ys7OdO9muWrXKrxpN5cMPP6z34uI1a9Y4p4c6dOhQZ7uq7brlllsad4DAJY4AA6CG3/72t84t9f/85z+rZ8+emj59ulasWKF169a53Uq/Xbt2eu211/zqJyoqyrmnjespmWDwzDPPKC0tTSNHjtRbb72l5cuXa+3atfrnP/+pKVOmOOMOCwvTmDFjaq2xc+dOHThwQJJ09913X7CxA5cCLuIFUENUVJTmz5+vkSNHas6cOVq/fr1zVKY2iYmJfvc1duxYzZs3T7m5udq3b58yMjL8rtXYTp8+rdmzZ2v27Nm1vh4VFaXXXntNvXr1qvX19957T9L5e9PcfvvtTTZO4FJEgAFQq4SEBP3v//6vli9frtmzZ2vZsmU6fPiwiouLlZiYqE6dOik7O1t33HGHbr31Vr/7+eEPf6j09HQdPHhQ77//vp599tlG3Ar/LVq0SJ988omWLl2qHTt26MiRIzp16pRiY2PVqVMn3XTTTRo/frw6duxYZ42qADN69OhaH30AwH8hpimv0AMAL/zhD3/QM888o8zMTG3dutXtRnu2Wr58ufr27avIyEjt3LmTC3iBRmb/bwkA1vv5z3+uNm3aaMeOHfV+JNkmzz//vCRp1KhRhBegCXAEBkBQmDlzpsaMGaOuXbtq48aN9T7vKdh9/fXX6t27txISErRjxw61atUq0EMCLjpcAwMgKIwcOVJHjx7VuXPn9P333ystLS3QQ/LbiRMnNHnyZPXs2ZPwAjQRjsAAAADrcA0MAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFjn/wHqOE3dHeryTQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def index_mapping(jobs=None, gpus_per_node=8, resource='cpu'):#gpu_value=None):\n",
    "    '''\n",
    "    Implement greedly algorithm with heap to place jobs to free resource indicies\n",
    "    \n",
    "    Specify which resource (e.g. gpu, cpu) to use fitting jobs to indices\n",
    "    \n",
    "    (1) Add all jobs to queue, then greedily assign indicies \n",
    "    (2) Have priority queue for each node with \"Free indices\" sorted by index number \n",
    "    (3) Iterate over all start times \n",
    "\n",
    "    TODO: Fix 1-off CPU index error \n",
    "    TODO: Don't let any job_idx values to be -1, and ensure it starts at node 1\n",
    "    TODO: Verify allocated_nodes\n",
    "    TODO: Determine how parsing changes between http_info and default values \n",
    "    TODO: Verify arrival value is accurate\n",
    "    TODO: Create a list of times that include all arrival times and completion times in the same list in numerical order \n",
    "    '''\n",
    "    '''\n",
    "    if gpu_jobs: \n",
    "        gpu_value = 'allocated_gpus_index'\n",
    "    else: \n",
    "        gpu_value = 'allocated_gpus'\n",
    "    '''\n",
    "    workload = 'gpu'\n",
    "    if 'workload_type' in jobs: \n",
    "        print('workload type')\n",
    "        print(jobs['workload_type'])\n",
    "        workload = jobs['workload_type']\n",
    "    print('gpus')\n",
    "    print(jobs['num_gpus'])\n",
    "    print('cpus list')\n",
    "    print(jobs['cpus'])\n",
    "    #import pdb; pdb.set_trace()\n",
    "    GPUS_PER_NODE = gpus_per_node\n",
    "    allocated_nodes = jobs['node_index']\n",
    "    \n",
    "    \n",
    "    #if resource == 'gpu':\n",
    "    if workload == 'gpu':\n",
    "        cpus = jobs['num_gpus']\n",
    "    else: \n",
    "        cpus = jobs['cpus']\n",
    "    #gpus = jobs['gpus']\n",
    "    nodes = set(allocated_nodes)\n",
    "    \n",
    "    node_jobs ={}\n",
    "    node_queues = {}\n",
    "    for node in nodes:\n",
    "        node_queues[node] = [i + 1 for i in range(GPUS_PER_NODE)]\n",
    "        node_jobs[node] = []\n",
    "\n",
    "    global_queue = [] # Queue sorted on end time -- earliest to latest end time\n",
    "    job_id_to_index = {} \n",
    "\n",
    "    for i in range(len(jobs['arrival'])):\n",
    "        #Remove values from queue\n",
    "        #import pdb; pdb.set_trace()\n",
    "        job_id = jobs['idx'][i]\n",
    "        job_id_to_index[job_id] = i\n",
    "        job_node = jobs['node_index'][i]\n",
    "        #if resource == 'gpu':\n",
    "        if workload == 'gpu':\n",
    "            job_cpu_size = jobs['num_gpus'][i]\n",
    "        else: \n",
    "            job_cpu_size = jobs['cpus'][i]\n",
    "        job_arrival = jobs['arrival_plot'][i]\n",
    "        job_runtime = jobs['runtime'][i]\n",
    "        \n",
    "        while global_queue and global_queue[0][0] <= job_arrival: \n",
    "            end_time, end_job_id = heapq.heappop(global_queue)\n",
    "            released_index = job_id_to_index[end_job_id]\n",
    "            for released_node in jobs['allocated_gpus'][released_index]: \n",
    "                released_cpus = jobs['allocated_gpus'][released_index][released_node]\n",
    "                released_node_queue = node_queues[released_node]\n",
    "                try:\n",
    "                    node_jobs[released_node].remove(end_job_id)\n",
    "                except:\n",
    "                    #import pdb; pdb.set_trace()\n",
    "                    print(\"Job Id not found\")\n",
    "                    print(end_job_id)\n",
    "                    print(node_jobs[released_node])\n",
    "                    continue\n",
    "                for cpu in released_cpus:\n",
    "                    heapq.heappush(released_node_queue, cpu)\n",
    "\n",
    "        heapq.heappush(global_queue, (job_arrival + job_runtime, job_id))\n",
    "        job_allocated_cpus = []\n",
    "        node_queue = node_queues[job_node]\n",
    "        node_jobs[job_node].append(job_id)\n",
    "    \n",
    "        print(f'job_cpu_size {job_cpu_size}')\n",
    "        try:\n",
    "            for j in range(job_cpu_size):\n",
    "                cpu_index = heapq.heappop(node_queue)\n",
    "                job_allocated_cpus.append(cpu_index)\n",
    "        except:\n",
    "            print(\"not enough cpus to fit jobs\")\n",
    "            print(node_queue)\n",
    "            print(job_allocated_cpus)\n",
    "        \n",
    "        print(f'allocated resources -- cpus or gpus: {job_allocated_cpus}')\n",
    "\n",
    "        jobs['allocated_gpus'][i] = {job_node: job_allocated_cpus}\n",
    "        #print(jobs['allocated_gpus'][i])\n",
    "        #import pdb; pdb.set_trace()\n",
    "\n",
    "    return jobs\n",
    "\n",
    "def generate_gantt_chart(row=None, gpus_per_node=None, ratio=None, scale=None, gpu_jobs=None):\n",
    "    '''\n",
    "    Create \"threads index\" that track CPU jobs running together\n",
    "    #TODO: Modify function to plot CPU jobs --> number of jobs concurrently running may exceed cpu count\n",
    "    #TODO: Plot color based on job start time and not job index\n",
    "    #TODO: Determine why jobs dissapaear when strings labels are used for nodes\n",
    "    #TODO: Label each row of jobs with the name of the node -- not just integers \n",
    "    #TODO: Plot cloud values in a separate plot\n",
    "    '''\n",
    "    workload = \"gpu\"\n",
    "    if 'workload_type' in row: \n",
    "        workload = row['workload_type']\n",
    "        \n",
    "    #if 'workload_type' in row and row['workload_type'] == 'cpu': \n",
    "    if workload == 'cpu':\n",
    "        gpus_per_nodes = 2\n",
    "        \n",
    "    graphs = ['cloud', 'onprem']\n",
    "    for graph in graphs:\n",
    "        #import pdb; pdb.set_trace()\n",
    "        save=False; path=None; subplt=None; plt_index=None; tag=None; plot_sweep=False\n",
    "        varying_values = row['varying_values']\n",
    "        tag = \"\"\n",
    "\n",
    "        count = 0 \n",
    "        for value in varying_values: \n",
    "            tag += str(value)\n",
    "            tag += \":\"\n",
    "            if isinstance(row[value], str) and len(row[value]) < 50: \n",
    "                tag += str(row[value])\n",
    "            tag += \" | \"\n",
    "            count += 1\n",
    "            if count % 5 == 0: \n",
    "                tag += '\\n'\n",
    "                \n",
    "        gpu_value = 'allocated_gpus'#_real'\n",
    "        \n",
    "        '''\n",
    "        if 'workload_type' in row and row['workload_type'] == 'cpu': \n",
    "            gpu_value = 'allocated_gpus'\n",
    "        elif gpu_jobs: \n",
    "            gpu_value = 'allocated_gpus_real'\n",
    "        else: \n",
    "            gpu_value = 'allocated_gpus'\n",
    "        '''\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        #GPUS_PER_NODE = row['cpus_per_node']\n",
    "        GPUS_PER_NODE = gpus_per_node\n",
    "        \n",
    "        '''\n",
    "        if 'workload_type' in row: \n",
    "            print('workload type')\n",
    "            print(row['workload_type'])\n",
    "            row = index_mapping(row, GPUS_PER_NODE, row['workload_type'])\n",
    "        else: \n",
    "            row = index_mapping(row, GPUS_PER_NODE, 'gpu')\n",
    "        '''\n",
    "        \n",
    "        row = index_mapping(row, GPUS_PER_NODE, 'gpu')\n",
    "        \n",
    "        '''\n",
    "        if 'workload_type' in row and row['workload_type'] == 'cpu':\n",
    "            print(\"mapped indices\")\n",
    "            row = index_mapping(row, GPUS_PER_NODE, 'cpu')\n",
    "        #if not gpu_jobs: \n",
    "        elif graph == 'cloud':\n",
    "            GPUS_PER_NODE = 32\n",
    "            #print(row['allocated_gpus'])\n",
    "            row = index_mapping(row, GPUS_PER_NODE, 'gpu')\n",
    "            #print(row['allocated_gpus'])\n",
    "        #import pdb; pdb.set_trace()\n",
    "        #if row['workload_type'] == 'cpu':\n",
    "        '''\n",
    "\n",
    "        \n",
    "        #print(\"allocated_gpus_real\")\n",
    "        #print(row['allocated_gpus_real'])\n",
    "        print(\"allocated_gpus\")\n",
    "        print(row['allocated_gpus'])\n",
    "        \n",
    "        NUM_COLORS = len(row['idx'])\n",
    "        cm = plt.get_cmap('gist_rainbow')\n",
    "        colors = [cm(1. * i / NUM_COLORS) for i in range(NUM_COLORS)]\n",
    "\n",
    "        y_lim_min = 1000\n",
    "        y_lim_max = -1000\n",
    "        num_nodes = row['cluster_size'] + row['cloud_cluster_nodes']\n",
    "\n",
    "        total_gpus = num_nodes * GPUS_PER_NODE #GPUs equivalent to CPUs -- if no GPU's then GPUS_PER_NODE reflects cpus\n",
    "        segment_height_list = {}\n",
    "        gpu_indices = {}\n",
    "        gpu_rows = set()\n",
    "        node_name = \"\"\n",
    "\n",
    "        # TODO: Plot infinite cloud spillover \n",
    "        try: \n",
    "            #import pdb; pdb.set_trace()\n",
    "            for j_idx in range(len(row['idx'])):\n",
    "                allocated_gpus = row[gpu_value][j_idx]\n",
    "                \n",
    "                #if graph == 'cloud':\n",
    "                #    allocated_gpus = row['allocated_gpus'][j_idx]\n",
    "                \n",
    "                #print(allocated_gpus)\n",
    "                #print(allocated_gpus)\n",
    "                #segment = (row['arrival'][j_idx],\n",
    "                #            row['arrival'][j_idx] + row['runtime'][j_idx], j_idx)\n",
    "                #segment = (row['submission_time'][j_idx],\n",
    "                #            row['submission_time'][j_idx] + row['runtime'][j_idx], j_idx)\n",
    "                segment = (row['arrival_plot'][j_idx],\n",
    "                            row['arrival_plot'][j_idx] + row['runtime'][j_idx], j_idx)\n",
    "\n",
    "                node_name = row['node'][j_idx]\n",
    "                if graph == 'onprem' and node_name == 'cloud': \n",
    "                    continue\n",
    "                elif graph == 'cloud' and node_name != 'cloud':\n",
    "                    continue\n",
    "                \n",
    "                print(f'j_idx {j_idx}')\n",
    "                \n",
    "                #if graph == 'cloud' and node_name == 'cloud':\n",
    "                #    print(allocated_gpus)\n",
    "                \n",
    "                for node_idx in allocated_gpus.keys():\n",
    "                    for node_gpu_idx in allocated_gpus[node_idx]:\n",
    "                        if graph == 'cloud': \n",
    "                            gpu_idx = node_gpu_idx\n",
    "                            #print(gpu_idx)\n",
    "                        else: \n",
    "                            gpu_idx = total_gpus - (GPUS_PER_NODE * node_idx + node_gpu_idx)\n",
    "                        print(f'gpu_idx {gpu_idx}')\n",
    "                        \n",
    "                        gpu_rows.add(gpu_idx)\n",
    "                        #print(node_gpu_idx)\n",
    "                        #print(gpu_rows)\n",
    "                        gpu_indices[node_name] = [gpu_idx]\n",
    "                        y_lim_min = min(y_lim_min, gpu_idx) #- 8)#if gpu_idx > 0 else gpu_index - 8)\n",
    "                        \n",
    "                        y_lim_max = max(y_lim_max, gpu_idx + 1) #+ 8)\n",
    "                        if graph == 'cloud':\n",
    "                            y_lim_max = GPUS_PER_NODE\n",
    "\n",
    "                        plt.barh(gpu_idx,\n",
    "                                    width=row['runtime'][j_idx],\n",
    "                                    edgecolor='black',\n",
    "                                    height=1.0,\n",
    "                                    left=segment[0],\n",
    "                                    align='edge',\n",
    "                                    color=colors[row['idx'][j_idx]] if row['idx'][j_idx] < len(colors) else None,\n",
    "                                    alpha = 0.5)    \n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            t = traceback.format_exc()\n",
    "            print(t)\n",
    "            print(e)\n",
    "\n",
    "        for i in range(total_gpus + 1):\n",
    "            multiplier = math.ceil(num_nodes / 32)\n",
    "            if (i + 1) % GPUS_PER_NODE == 1:\n",
    "                plt.axhline(y=i + 1, linewidth=3 / multiplier, color='black')\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        max_arrival = max(row['arrival_plot'])\n",
    "        completions = [row['arrival_plot'][i] + row['runtime'][i] for i in range(len(row['arrival_plot']))]\n",
    "        max_completion = max(completions)\n",
    "\n",
    "        x_lim_max = max_completion\n",
    "        last_job_time = max(row['completion_time'])\n",
    "        #print(last_job_time)\n",
    "        #26913.0\n",
    "        #18405.78506708145\n",
    "        last_job_time= 1000#18405.78506708145#26913\n",
    "        dim=(y_lim_min, y_lim_max, 0, last_job_time)\n",
    "        bottom, top, left, right = dim\n",
    "        plt.ylim(bottom=bottom, top=top)\n",
    "        plt.xlim(left=left, right=right)\n",
    "        plt.axvline(x=max_arrival, color='brown', linewidth=0.75)\n",
    "        plt.xlabel('Time (hrs)')\n",
    "        plt.ylabel('Nodes ')\n",
    "        #if graph == 'cloud'\n",
    "        plt.title(str(tag))\n",
    "        if graph == 'cloud':\n",
    "            plt.title(f'Cloud {workload} Jobs')\n",
    "        elif graph == 'onprem':\n",
    "            plt.title(f'Onprem {workload} Jobs')\n",
    "        #plt.title(graph)\n",
    "\n",
    "        gpu_labels = sorted([(v, k) for k, v in gpu_indices.items()])\n",
    "        ticks = [label[0] for label in gpu_labels]\n",
    "        ticks = np.array(ticks)\n",
    "        ticks = ticks.flatten()\n",
    "        labels = [label[1] for label in gpu_labels]\n",
    "        labels = np.array(labels)\n",
    "        labels = labels.flatten()\n",
    "        plt.yticks(ticks)\n",
    "        labels = [i for i in range(len(labels))]\n",
    "        ax.set_yticklabels(labels)\n",
    "        new_labels = {}\n",
    "        node_count = 0\n",
    "        #for k, v in labels.items():\n",
    "            #new_labels[node_count] = k #node_count\n",
    "            #node_count += 1\n",
    "            #new_labels.append(node_count)\n",
    "        #labels = {1.0: 'High', 0.0: 'Medium', -1.0: 'Low'}\n",
    "        #ax.set_yticks(list(labels.keys()))\n",
    "        #ax.set_yticks(list(new_labels.keys()))\n",
    "        plt.rcParams.update({'font.size': 20})\n",
    "        plt.tick_params(axis='y', which='both', bottom=False, top=False, labelbottom=False, right=False, left=False, labelleft=False)\n",
    "        ax.set_ylabel('')\n",
    "        \n",
    "        def divide(x, pos):\n",
    "            return '{}'.format(round(x / 3600, 1))\n",
    "\n",
    "        # Set the formatter\n",
    "        import matplotlib.ticker as ticker\n",
    "        formatter = ticker.FuncFormatter(divide)\n",
    "        ax.xaxis.set_major_formatter(formatter)\n",
    "        \n",
    "        if save:\n",
    "            if path: \n",
    "                plt.savefig(path)\n",
    "                plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "        \n",
    "def remap_cloud_arrival(row):\n",
    "    new_arrival = [row['start'][i] if row['is_local'][i] == 1 else row['arrival'][i] for i in range(len(row['arrival']))]\n",
    "    #new_arrival = [1 if row['is_local'] == 1 else 0 for i in range(len(row['arrival']))]\n",
    "    return new_arrival\n",
    "\n",
    "jobs_df['arrival_plot'] = jobs_df.apply(remap_cloud_arrival, axis=1)\n",
    "print(list(enumerate(jobs_df['arrival_plot'][0])))\n",
    "#print(jobs_df['is_local'][0])\n",
    "print('start times')\n",
    "print(jobs_df['start'][0])\n",
    "print(jobs_df['submission_time'][0])\n",
    "schedule_time = [jobs_df['start'][0][i] - jobs_df['submission_time'][0][i] for i in range(len(jobs_df['start'][0]))]\n",
    "print(\"pod scheduling time (seconds)\")\n",
    "print(schedule_time)\n",
    "print(\"run locally (1=local, 0=cloud)\")\n",
    "print(jobs_df['is_local'][0])\n",
    "print(\"allocated_gpus_real\")\n",
    "print(jobs_df['allocated_gpus_real'][0])\n",
    "print(\"allocated_gpus\")\n",
    "print(jobs_df['allocated_gpus'][0])\n",
    "print(jobs_df['arrival'][0])\n",
    "print(\"IDs\")\n",
    "print(jobs_df['idx'][0])\n",
    "print(\"RUNTIME\")\n",
    "print(jobs_df['runtime'][0])\n",
    "print(\"VERIFYING\")\n",
    "print(sorted(jobs_df['arrival'][0]))\n",
    "\n",
    "for j in range(len(jobs_df)):\n",
    "    cloud_time = [jobs_df['runtime'][j][i] for i in range(len(jobs_df['runtime'][j])) if jobs_df['is_local'][j][i] == 0  ]\n",
    "    print(\"cloud runtimes (seconds)\")\n",
    "    print(cloud_time)\n",
    "    onprem_time = [jobs_df['runtime'][j][i] for i in range(len(jobs_df['runtime'][j])) if jobs_df['is_local'][j][i] == 1  ]\n",
    "    print(\"onprem runtimes (seconds)\")\n",
    "    print(onprem_time)\n",
    "\n",
    "for j in range(len(jobs_df)):\n",
    "    total_job_arrival = len(jobs_df['arrival'][j])\n",
    "    total_job_submission = len(jobs_df['start'][j])\n",
    "    total_job_completion = len(jobs_df['completion_time'][j])\n",
    "    print(f'{j} {total_job_arrival} {total_job_submission} {total_job_completion}')\n",
    "gpus_per_node = 8 #TODO: Parse this value from the job\n",
    "ratio = (1, 1)\n",
    "scale = 1\n",
    "\n",
    "jobs_df.apply(generate_gantt_chart, axis=1, args=(gpus_per_node, ratio, scale, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c6ceeda0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'log_jobs' has no attribute 'retrieve_log'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m     log \u001b[38;5;241m=\u001b[39m log_jobs\u001b[38;5;241m.\u001b[39mretrieve_log(event_number\u001b[38;5;241m=\u001b[39mlogs)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log \n\u001b[0;32m----> 5\u001b[0m log_df \u001b[38;5;241m=\u001b[39m \u001b[43mparse_starburst_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m log_df\n\u001b[1;32m      8\u001b[0m loop_times \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[57], line 2\u001b[0m, in \u001b[0;36mparse_starburst_log\u001b[0;34m(event_number)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_starburst_log\u001b[39m(event_number\u001b[38;5;241m=\u001b[39mlogs):\n\u001b[0;32m----> 2\u001b[0m     log \u001b[38;5;241m=\u001b[39m \u001b[43mlog_jobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve_log\u001b[49m(event_number\u001b[38;5;241m=\u001b[39mlogs)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'log_jobs' has no attribute 'retrieve_log'"
     ]
    }
   ],
   "source": [
    "def parse_starburst_log(event_number=logs):\n",
    "    log = log_jobs.retrieve_log(event_number=logs)\n",
    "    return log \n",
    "\n",
    "log_df = parse_starburst_log(event_number=logs)\n",
    "log_df\n",
    "\n",
    "loop_times = []\n",
    "interloop_times = []\n",
    "process_queue_times = []\n",
    "process_event_times = []\n",
    "queue_add_times = []\n",
    "await_times = []\n",
    "times = []\n",
    "events = []\n",
    "\n",
    "for i in range(len(log_df)):\n",
    "    log = log_df[0][i]\n",
    "    parts = log.split('||')\n",
    "    if len(parts) > 1:\n",
    "        log = parts[1]\n",
    "        \n",
    "    if log.find(\"TICK TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        if len(parts) > 8: \n",
    "            time = parts[4]\n",
    "            times.append(float(time))\n",
    "            eventtype = parts[6] + parts[7]\n",
    "            events.append(eventtype)\n",
    "            \n",
    "    if log.find(\"LOOP TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        time = parts[4]\n",
    "        loop_times.append(float(time))\n",
    "        \n",
    "    if log.find(\"INTERLOOP TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        time = parts[4]\n",
    "        interloop_times.append(float(time))\n",
    "        \n",
    "    if log.find(\"PROCESSQUEUE TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        time = parts[4]\n",
    "        process_queue_times.append(float(time))\n",
    "        \n",
    "    if log.find(\"PROCESSEVENT TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        time = parts[4]\n",
    "        process_event_times.append(float(time))\n",
    "    \n",
    "    if log.find(\"QUEUEADD TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        time = parts[4]\n",
    "        queue_add_times.append(float(time))\n",
    "        \n",
    "    if log.find(\"AWAIT TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        time = parts[4]\n",
    "        await_times.append(float(time))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=9,figsize=(12,3)) \n",
    "\n",
    "#loop_times = [loop_times[i + 1] - loop_times[i] for i in range(len(loop_times) - 1)]\n",
    "\n",
    "overflows = []\n",
    "addtimes = []\n",
    "ticktimes = []\n",
    "for i in range(len(times)):\n",
    "    time = times[i]\n",
    "    event = events[i]\n",
    "    if event == 'JobAddEvent:Job,':\n",
    "        addtimes.append(time)\n",
    "    if event == 'SchedTick,':\n",
    "        ticktimes.append(time)\n",
    "    if time > 0.6: \n",
    "        overflows.append((time, event))\n",
    "\n",
    "axs[0].set_title('All Event Times', fontsize =10)\n",
    "axs[0].hist(times)\n",
    "axs[0].set_xlabel('Time (sec)')\n",
    "axs[0].set_ylabel('Frequency')\n",
    "\n",
    "axs[1].set_title('Job Add Event Times', fontsize =10)\n",
    "axs[1].hist(addtimes)\n",
    "axs[1].set_xlabel('Time (sec)')\n",
    "axs[1].set_ylabel('Frequency')\n",
    "\n",
    "axs[2].set_title('Sched Tick Event Times', fontsize =10)\n",
    "axs[2].hist(ticktimes)\n",
    "axs[2].set_xlabel('Time (sec)')\n",
    "axs[2].set_ylabel('Frequency')\n",
    "\n",
    "axs[3].set_title('Loop Times', fontsize =10)\n",
    "axs[3].hist(loop_times)\n",
    "axs[3].set_xlabel('Time (sec)')\n",
    "axs[3].set_ylabel('Frequency')\n",
    "\n",
    "axs[4].set_title('Inter Loop Times', fontsize =10)\n",
    "axs[4].hist(interloop_times)\n",
    "axs[4].set_xlabel('Time (sec)')\n",
    "axs[4].set_ylabel('Frequency')\n",
    "\n",
    "axs[5].set_title('Process Queue Times', fontsize =10)\n",
    "axs[5].hist(process_queue_times)\n",
    "axs[5].set_xlabel('Time (sec)')\n",
    "axs[5].set_ylabel('Frequency')\n",
    "\n",
    "axs[6].set_title('Process Event Times', fontsize =10)\n",
    "axs[6].hist(process_event_times)\n",
    "axs[6].set_xlabel('Time (sec)')\n",
    "axs[6].set_ylabel('Frequency')\n",
    "\n",
    "axs[7].set_title('Queue Add Times', fontsize =10)\n",
    "axs[7].hist(queue_add_times)\n",
    "axs[7].set_xlabel('Time (sec)')\n",
    "axs[7].set_ylabel('Frequency')\n",
    "\n",
    "axs[8].set_title('Await Times', fontsize =10)\n",
    "axs[8].hist(queue_add_times)\n",
    "axs[8].set_xlabel('Time (sec)')\n",
    "axs[8].set_ylabel('Frequency')\n",
    "\n",
    "print(process_event_times)\n",
    "print(process_queue_times)\n",
    "print(loop_times)\n",
    "print(interloop_times)\n",
    "print(queue_add_times)\n",
    "print(sum(loop_times)/len(loop_times))\n",
    "\n",
    "add_count = 0 \n",
    "sched_count = 0\n",
    "for t, e in overflows: \n",
    "    if e == 'JobAddEvent:Job,':\n",
    "        add_count += 1\n",
    "    if e == 'SchedTick,':\n",
    "        sched_count += 1\n",
    "\n",
    "#print(add_count)\n",
    "#print(sched_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1933e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(jobs_df)):\n",
    "    print(i)\n",
    "    print(len(jobs_df['is_local'][i]))\n",
    "    print(sum(jobs_df['is_local'][i]))\n",
    "    print(len(jobs_df['arrival'][i]))\n",
    "    print(len(jobs_df['start'][i]))\n",
    "    print(len(jobs_df['submission_time'][i]))\n",
    "    print(len(jobs_df['runtime'][i]))\n",
    "    print(len(jobs_df['allocated_gpus_real'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310e3c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df\n",
    "#print(len(jobs_df['idx'][0]))\n",
    "'''\n",
    "print(jobs_df['is_local'][0][:-18])\n",
    "print(jobs_df['arrival'][0][:-18])\n",
    "print(jobs_df['start'][0][:-18])\n",
    "print(jobs_df['submission_time'][0][:-18])\n",
    "print(jobs_df['runtime'][0][:-18])\n",
    "print(jobs_df['allocated_gpus_real'][0][:-18])\n",
    "'''\n",
    "print(len(jobs_df['is_local'][0]))\n",
    "print(len(jobs_df['arrival'][0]))\n",
    "print(len(jobs_df['start'][0]))\n",
    "print(len(jobs_df['submission_time'][0]))\n",
    "print(len(jobs_df['runtime'][0]))\n",
    "print(len(jobs_df['allocated_gpus_real'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bbd5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jobs_df['total_cloud_cost'])\n",
    "print(jobs_df['avg_jct'])\n",
    "print(jobs_df['cluster_utilization'])\n",
    "\n",
    "jobs_df['completion_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9317035",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in jobs_df['runtime']:\n",
    "    print(i)\n",
    "    print(len(i))\n",
    "\n",
    "for i in jobs_df['arrival_mask']:\n",
    "    print(i)\n",
    "    print(len(i))\n",
    "    \n",
    "for i in jobs_df['onprem_mask']:\n",
    "    print(i)\n",
    "    print(len(i))\n",
    "    \n",
    "for i in jobs_df['num_gpus']:\n",
    "    print(i)\n",
    "    print(len(i))\n",
    "    \n",
    "for i in jobs_df['start']:\n",
    "    print(i)\n",
    "    print(len(i))\n",
    "    \n",
    "for i in jobs_df['instance_type']:\n",
    "    print(i)\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9c7931",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def wait_time_histograms(row):\n",
    "    \"\"\"Plots waiting time for onprem, cloud, and cloud clipped\"\"\"\n",
    "    #import pdb; pdb.set_trace()\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(12,3)) \n",
    "    \n",
    "    axs[0].set_title(\"ONPREM \" + \"wait \" + str(row['wait_time']) +  \" arr \" + str(row['arrival_rate']), fontsize=10)\n",
    "    axs[0].hist(row['onprem_wait'])\n",
    "    if row['onprem_wait'] != []:\n",
    "        average = sum(row['onprem_wait'])/len(row['onprem_wait'])\n",
    "        axs[0].axvline(average, color='r', linewidth=0.5)\n",
    "\n",
    "    axs[1].set_title(\"CLOUD \" + \"wait \" + str(row['wait_time']) +  \" arr \" + str(row['arrival_rate']), fontsize=10)\n",
    "    axs[1].hist(row['cloud_wait'])\n",
    "      \n",
    "    axs[2].set_title(\"CLOUD UNCLIPPED \" + \"wait \" + str(row['wait_time']) +  \" arr \" + str(row['arrival_rate']), fontsize=10)\n",
    "    axs[2].hist(row['cloud_wait_unclipped'])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "jobs_df.apply(wait_time_histograms, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a0496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df\n",
    "jobs_df['allocated_gpus_real'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad96d33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_uuid = list(jobs_df['idx'])[0]\n",
    "job_runtimes = list(jobs_df['runtime'])[0]\n",
    "job_gpus = list(jobs_df['num_gpus'])[0]\n",
    "job_gpus = [int(i) for i in job_gpus]\n",
    "print(job_uuid)\n",
    "print(job_runtimes)\n",
    "print(job_gpus)\n",
    "print(sum(job_runtimes)/len(job_runtimes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2baf853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def set_plotting_setting(ax):\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    ax.grid(True, which='both')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(True)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    #ax.tick_params(bottom=False, left=False)\n",
    "    ax.tick_params(bottom=True, left=False)\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "label_dict = {\n",
    "    'avg_jct': 'Avg. JCT (sec)',\n",
    "    'cost_mult': '% Cost Savings\\nover No Wait',\n",
    "    'cost_diff': 'Cost Savings\\nover No Wait',\n",
    "    'cluster_size': 'Cluster Size (# Nodes)',\n",
    "    'norm_system_utilization': 'System Utilization',\n",
    "    'system_utilization': 'System Utilization',\n",
    "    'cluster_utilization': 'Cluster Utilization',\n",
    "    'total_cloud_cost': 'Cloud Cost',\n",
    "    'arrival_rate': 'Arrival Rate',\n",
    "    'uniform_arrival': 'Uniform Inter Arrival Time',\n",
    "}\n",
    "\n",
    "legend_dict = {\n",
    "    'constant': 'Constant',\n",
    "    'linear_runtime': 'Runtime',\n",
    "    'linear_cost': 'Cost',\n",
    "    'zero': 'No Wait',\n",
    "    'linear_runtime_filter_cpu': 'Runtime-Preempt-CPU'\n",
    "}\n",
    "\n",
    "def simulator_plotting_fn(df, \n",
    "                          x_axis: str,\n",
    "                          y_axis: list = ['cost_mult', 'avg_jct'],\n",
    "                          df_filter: dict = {},\n",
    "                          baseline_filter: dict={'waiting_policy': 'zero',},\n",
    "                          groupby_values=['waiting_policy', 'waiting_factor'],\n",
    "                          normalize_x_axis=False,\n",
    "                          fig_ratio=(5, 3.5),\n",
    "                          intermediate_df={\"baseline_df\": False, \"merged_df\": False, \"metrics_df\": False, \"groups_df\": False},\n",
    "                          return_df=False):\n",
    "    \"\"\"\n",
    "    Takes a baseline filter to plot metrics of different policies against\n",
    "    \n",
    "    Creates a product of the baseline filter against each existing run\n",
    "        - Values ending with _y are values from the baseline\n",
    "    \n",
    "    Takes a groupby value to compress to set of useful pairs\n",
    "    \"\"\"\n",
    "    \n",
    "    def cost_multiplier(row):\n",
    "        baseline_cost = row['total_cloud_cost_y']\n",
    "        cost = row['total_cloud_cost_x']\n",
    "        if baseline_cost == 0 and cost==0:\n",
    "            return 0\n",
    "        #elif baseline_cost <=10000:\n",
    "            # Small cloud cost for No wait\n",
    "            # Savings over small cloud cost is negligible for organizations.\n",
    "        #    return 0\n",
    "        elif baseline_cost == 0 and cost>0:\n",
    "            return 100\n",
    "        return 100* (1 - (cost/baseline_cost))\n",
    "    \n",
    "    def cost_difference(row):\n",
    "        baseline_cost = row['total_cloud_cost_y']\n",
    "        cost = row['total_cloud_cost_x']\n",
    "        return baseline_cost - cost\n",
    "    \n",
    "    \n",
    "    if isinstance(y_axis, str):\n",
    "        y_axis = [y_axis]\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=len(y_axis), figsize=(fig_ratio[0]*len(y_axis), fig_ratio[1]))\n",
    "    \n",
    "    if len(y_axis) == 1: \n",
    "        if not isinstance(axs, list):\n",
    "            axs = [axs]\n",
    "    #print(axs)\n",
    "    '''\n",
    "    for k,v in df_filter.items():\n",
    "        if isinstance(v, list):\n",
    "            df = df[df[k]==v]\n",
    "    '''\n",
    "\n",
    "    for k,v in df_filter.items():        \n",
    "        mask = df[k].apply(lambda x: x == v)\n",
    "        if isinstance(v, list):\n",
    "            df = df[mask]\n",
    "            \n",
    "    #TODO: get_default = df after mask \n",
    "    baseline_df = df\n",
    "    if intermediate_df['baseline_df']:\n",
    "        print(\"baseline\")\n",
    "        display(baseline_df)\n",
    "    \n",
    "    for k,v in baseline_filter.items():\n",
    "        assert not isinstance(v, list)\n",
    "        baseline_df = baseline_df[baseline_df[k]==v]\n",
    "        #df = df[df[k]!=v]\n",
    "         \n",
    "    # Merge to check for baseline\n",
    "    diff_df = pd.merge(df, baseline_df, left_on=x_axis,right_on=x_axis)\n",
    "    \n",
    "    #TODO: join_baseline = diff_df after merge\n",
    "    if intermediate_df['merged_df']:\n",
    "        print(\"merged\")\n",
    "        display(diff_df)\n",
    "    \n",
    "    if normalize_x_axis:\n",
    "        if x_axis == 'cluster_size':\n",
    "            # Hardcoded in Philly trace, precomputed ahead of time\n",
    "            if df['dataset'].iloc[0] == 'philly':\n",
    "                total_job_volume = 1155998.77277777\n",
    "                job_makespan = 2559.3205555555555\n",
    "            elif df['dataset'].iloc[0] == 'helios':\n",
    "                total_job_volume = 1853756.1241666232\n",
    "                job_makespan = 4651.911388888889\n",
    "            diff_df['norm_system_utilization'] = total_job_volume/(job_makespan*diff_df['cluster_size']*df['gpus_per_node'].iloc[0])\n",
    "            x_axis = 'norm_system_utilization'\n",
    "        elif x_axis == 'arrival_rate' or x_axis == 'uniform_arrival':\n",
    "            # Volume rate => runtime must be in either hours or seconds \n",
    "            '''\n",
    "            Verification: \n",
    "            - Arrival_Rate = VERIFIED ~ error \n",
    "            - Num_gpus = Verified\n",
    "            - Runtime = Verified \n",
    "            '''\n",
    "            #arrival_rate = diff_df['arrival_rate'] # Jobs per second \n",
    "            arrival_rate = 1/df['uniform_arrival'] # uniform_arrival => time between jobs in seconds \n",
    "            #avg_job_volume_rate = arrival_rate * np.mean(df['num_gpus'].iloc[0]* df['runtime'].iloc[0])\n",
    "            df['volume'] = df['num_gpus'] * df['runtime']\n",
    "            #df['avg_job_volume_rate'] = sum(df['volume'])/len(df['volume']) * arrival_rate\n",
    "            df['avg_volume'] = df['volume'].apply(lambda arr: np.mean(arr))\n",
    "            df['avg_job_volume_rate'] = df['avg_volume'] * arrival_rate\n",
    "            #import pdb; pdb.set_trace()\n",
    "            #avg_job_volume_rate = arrival_rate * ([df['num_gpus'] * df['runtime'][i] for i in range(len(df['runtime']))])/len(df['runtime'])\n",
    "            #df['avg_job_volume_rate'] = avg_job_volume_rate\n",
    "            df['verify_mean_runtime'] = np.mean(df['num_gpus'].iloc[0]* df['runtime'].iloc[0])\n",
    "            df['verify_cluster_nodes'] = (df['cluster_size'].iloc[0]*df['gpus_per_node'].iloc[0])\n",
    "            #print(avg_job_volume_rate)\n",
    "            #print(df['cluster_size'].iloc[0])\n",
    "            #print(df['gpus_per_node'].iloc[0])\n",
    "            #print(df['cluster_size'].iloc[0]*df['gpus_per_node'].iloc[0])\n",
    "            #diff_df['norm_system_utilization'] = avg_job_volume_rate/(df['cluster_size'].iloc[0]*df['gpus_per_node'].iloc[0])\n",
    "            #df['cluster_size'] = 1 #TODO: Remove this value\n",
    "            diff_df['norm_system_utilization'] = df['avg_job_volume_rate']/(df['cluster_size']*df['gpus_per_node'])\n",
    "            diff_df['norm_system_utilization'] = pd.to_numeric(diff_df['norm_system_utilization'], errors='coerce')\n",
    "            diff_df['norm_system_utilization'] = diff_df['norm_system_utilization'].round(4)\n",
    "            x_axis = 'norm_system_utilization'\n",
    "            diff_df = diff_df.sort_values('norm_system_utilization')\n",
    "    \n",
    "    \n",
    "    diff_df['cost_mult'] = diff_df.apply(cost_multiplier, axis=1)\n",
    "    diff_df['cost_diff'] = diff_df.apply(cost_difference, axis=1)\n",
    "    \n",
    "    if intermediate_df['metrics_df']:\n",
    "        print(\"merged metrics\")\n",
    "        display(diff_df)\n",
    "        \n",
    "    #TODO: get_baseline = df after normalizing axis\n",
    "    if groupby_values: \n",
    "        groupby_values = [f'{g}_x' for g in groupby_values]\n",
    "    mod_y_axis = [f'{y}_x' if y!='cost_mult' and y!='cost_diff' else y for y in y_axis]\n",
    "    \n",
    "    markers = itertools.cycle(('v', '^','.', 'o', '*',',', '+',)) \n",
    "    groups = diff_df.groupby(groupby_values)\n",
    "    \n",
    "    if intermediate_df['groups_df']:\n",
    "        for name, group in groups:\n",
    "            print(f\"Group: {name}\")\n",
    "            #'cost_mult', 'cost_diff', 'wait_time_x', 'wait_time_y' , 'wait_time_x', 'wait_time_y'\n",
    "            group = group[['cost_mult', 'cost_diff', 'wait_time_x', 'wait_time_y', 'uniform_arrival_sweep_x', 'uniform_arrival_sweep_y', 'total_cloud_cost_x', 'total_cloud_cost_y']]\n",
    "            \n",
    "            display(group)\n",
    "        \n",
    "    for idx, (label, grp) in enumerate(groups):\n",
    "        marker = next(markers)\n",
    "#         if 'waiting_policy' in groupby_values[0]:\n",
    "#             label = [legend_dict[label[0]]] + list(label[1:])\n",
    "#             print(label)\n",
    "        for ax_idx, ax in enumerate(axs):           \n",
    "            grp.plot(x = x_axis, y = mod_y_axis[ax_idx],ylabel=label_dict[y_axis[ax_idx]], \\\n",
    "                     xlabel=label_dict[x_axis], marker=marker, ax = ax, label = label, legend=None)\n",
    "    \n",
    "    if return_df: \n",
    "        return diff_df \n",
    "    for ax in axs:\n",
    "        set_plotting_setting(ax)\n",
    "    #axs[1].set_xlim(right=36, left=20)\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(lines, labels, ncol=len(labels), \\\n",
    "               bbox_to_anchor=(0, 0.92, 1, 0.2),loc='upper center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "'''\n",
    "# TODO: Add spec to increase plot size\n",
    "# TODO: pull the first distribution value\n",
    "# TODO: retrieve sweep value based on the log value \n",
    "# TODO: Clean up ipynb to avoid overwriting jobs_df values\n",
    "'''\n",
    "def generate_system_util_plots(event_number=None, scale=4):\n",
    "    events_dict, sweep_dict = log_jobs.retrieve_events_df(event_number=logs, avoid_congestion=False, only_dict=True)\n",
    "    sweep_dict = OrderedDict(sweep_dict['varying_values'])\n",
    "    \n",
    "    # Make sure baseline filter is one row in dataframe\n",
    "    # Make sure the baseline filter subtracts each corresponding arrival_rate\n",
    "    for sweep_dim in sweep_dict: \n",
    "        for sweep_value in sweep_dict[sweep_dim]:\n",
    "            print(sweep_dim + \"_sweep\")\n",
    "            print(sweep_value)\n",
    "            df = simulator_plotting_fn(jobs_df, \\\n",
    "                                       #x_axis='arrival_rate', \\\n",
    "                                       x_axis='uniform_arrival', \\\n",
    "                                       y_axis=['avg_jct', 'cluster_utilization', 'total_cloud_cost', 'cost_mult', 'cost_diff'], \\\n",
    "                                       baseline_filter= {'wait_time': 2}, \\\n",
    "                                       groupby_values=['wait_time'], \\\n",
    "                                       #'uniform_submission_sweep', \n",
    "                                       #'arrival_rate': 'Arrival Rate',\n",
    "                                       #'uniform_arrival_sweep',\n",
    "                                       normalize_x_axis=True, \\\n",
    "                                       intermediate_df={\"baseline_df\": False, \"merged_df\": True, \"metrics_df\": False, \"groups_df\": True}, \\\n",
    "                                       fig_ratio=(5*scale, 3.5*scale), \\\n",
    "                                       return_df=False)\n",
    "            display(df)\n",
    "            break \n",
    "        break\n",
    "        \n",
    "generate_system_util_plots(event_number=logs, scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd606030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b41794c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00db7fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
