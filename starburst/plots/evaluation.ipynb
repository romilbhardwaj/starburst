{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77f2329b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/surya/starburst/starburst/plots\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "import sys\n",
    "import os\n",
    "path = os.getcwd()\n",
    "path += '/../../'\n",
    "sys.path.append(path)\n",
    "\n",
    "import starburst\n",
    "from starburst import utils\n",
    "from starburst import sweep\n",
    "\n",
    "import log_jobs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import time \n",
    "import copy \n",
    "from collections import OrderedDict \n",
    "import math\n",
    "import heapq\n",
    "import re\n",
    "from IPython.display import display\n",
    "import itertools\n",
    "import pickle\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26235ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTANCE_GPUS = {\n",
    "    \"n2-standard-2\": 0\n",
    "}\n",
    "\n",
    "INSTANCE_CPUS = {\n",
    "    \"n2-standard-2\": 2\n",
    "}\n",
    "\n",
    "VMS = {\n",
    "    \"1688429055.455189\": 1, # CPU Sleep jobs refactored\n",
    "    \"1688761486.0967073\": 1, # Formatting\n",
    "    \"1689102570.9465764\": 1, # Cluster size log\n",
    "    \"1689102776.9346955\": 1, # listnode error \n",
    "}\n",
    "\n",
    "logs =  \"1689102776.9346955\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b8d2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '../sweep_logs/1689102776.9346955/events/1.yaml'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>image</th>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_duration</th>\n",
       "      <td>2.712068</td>\n",
       "      <td>33.740453</td>\n",
       "      <td>6.041281</td>\n",
       "      <td>14.939977</td>\n",
       "      <td>12.801997</td>\n",
       "      <td>3.544624</td>\n",
       "      <td>19.453369</td>\n",
       "      <td>11.389592</td>\n",
       "      <td>4.270686</td>\n",
       "      <td>4.43687</td>\n",
       "      <td>2.457714</td>\n",
       "      <td>24.982641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_id</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kube_yaml</th>\n",
       "      <td>{'apiVersion': 'batch/v1', 'kind': 'Job', 'met...</td>\n",
       "      <td>{'apiVersion': 'batch/v1', 'kind': 'Job', 'met...</td>\n",
       "      <td>{'apiVersion': 'batch/v1', 'kind': 'Job', 'met...</td>\n",
       "      <td>{'apiVersion': 'batch/v1', 'kind': 'Job', 'met...</td>\n",
       "      <td>{'apiVersion': 'batch/v1', 'kind': 'Job', 'met...</td>\n",
       "      <td>{'apiVersion': 'batch/v1', 'kind': 'Job', 'met...</td>\n",
       "      <td>{'apiVersion': 'batch/v1', 'kind': 'Job', 'met...</td>\n",
       "      <td>{'apiVersion': 'batch/v1', 'kind': 'Job', 'met...</td>\n",
       "      <td>{'apiVersion': 'batch/v1', 'kind': 'Job', 'met...</td>\n",
       "      <td>{'apiVersion': 'batch/v1', 'kind': 'Job', 'met...</td>\n",
       "      <td>{'apiVersion': 'batch/v1', 'kind': 'Job', 'met...</td>\n",
       "      <td>{'apiVersion': 'batch/v1', 'kind': 'Job', 'met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resources</th>\n",
       "      <td>{'cpu': 1, 'gpu': 0}</td>\n",
       "      <td>{'cpu': 1, 'gpu': 0}</td>\n",
       "      <td>{'cpu': 1, 'gpu': 0}</td>\n",
       "      <td>{'cpu': 1, 'gpu': 0}</td>\n",
       "      <td>{'cpu': 1, 'gpu': 0}</td>\n",
       "      <td>{'cpu': 1, 'gpu': 0}</td>\n",
       "      <td>{'cpu': 1, 'gpu': 0}</td>\n",
       "      <td>{'cpu': 1, 'gpu': 0}</td>\n",
       "      <td>{'cpu': 1, 'gpu': 0}</td>\n",
       "      <td>{'cpu': 1, 'gpu': 0}</td>\n",
       "      <td>{'cpu': 1, 'gpu': 0}</td>\n",
       "      <td>{'cpu': 1, 'gpu': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scheduler_submit_time</th>\n",
       "      <td>1689102784.871662</td>\n",
       "      <td>1689102789.871757</td>\n",
       "      <td>1689102794.851678</td>\n",
       "      <td>1689102799.904291</td>\n",
       "      <td>1689102804.877728</td>\n",
       "      <td>1689102809.860941</td>\n",
       "      <td>1689102814.892436</td>\n",
       "      <td>1689102819.87739</td>\n",
       "      <td>1689102824.860771</td>\n",
       "      <td>1689102829.892119</td>\n",
       "      <td>1689102834.882229</td>\n",
       "      <td>1689102839.871469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spill_to_cloud</th>\n",
       "      <td>log</td>\n",
       "      <td>log</td>\n",
       "      <td>log</td>\n",
       "      <td>log</td>\n",
       "      <td>log</td>\n",
       "      <td>log</td>\n",
       "      <td>log</td>\n",
       "      <td>log</td>\n",
       "      <td>log</td>\n",
       "      <td>log</td>\n",
       "      <td>log</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submit_time</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workload_type</th>\n",
       "      <td>cpu_sleep</td>\n",
       "      <td>cpu_sleep</td>\n",
       "      <td>cpu_sleep</td>\n",
       "      <td>cpu_sleep</td>\n",
       "      <td>cpu_sleep</td>\n",
       "      <td>cpu_sleep</td>\n",
       "      <td>cpu_sleep</td>\n",
       "      <td>cpu_sleep</td>\n",
       "      <td>cpu_sleep</td>\n",
       "      <td>cpu_sleep</td>\n",
       "      <td>cpu_sleep</td>\n",
       "      <td>cpu_sleep</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      0    \n",
       "image                                   gcr.io/sky-burst/skyburst:latest  \\\n",
       "job_duration                                                    2.712068   \n",
       "job_id                                                                 0   \n",
       "kube_yaml              {'apiVersion': 'batch/v1', 'kind': 'Job', 'met...   \n",
       "resources                                           {'cpu': 1, 'gpu': 0}   \n",
       "scheduler_submit_time                                  1689102784.871662   \n",
       "spill_to_cloud                                                       log   \n",
       "submit_time                                                            5   \n",
       "workload_type                                                  cpu_sleep   \n",
       "\n",
       "                                                                      1    \n",
       "image                                   gcr.io/sky-burst/skyburst:latest  \\\n",
       "job_duration                                                   33.740453   \n",
       "job_id                                                                 1   \n",
       "kube_yaml              {'apiVersion': 'batch/v1', 'kind': 'Job', 'met...   \n",
       "resources                                           {'cpu': 1, 'gpu': 0}   \n",
       "scheduler_submit_time                                  1689102789.871757   \n",
       "spill_to_cloud                                                       log   \n",
       "submit_time                                                           10   \n",
       "workload_type                                                  cpu_sleep   \n",
       "\n",
       "                                                                      2    \n",
       "image                                   gcr.io/sky-burst/skyburst:latest  \\\n",
       "job_duration                                                    6.041281   \n",
       "job_id                                                                 2   \n",
       "kube_yaml              {'apiVersion': 'batch/v1', 'kind': 'Job', 'met...   \n",
       "resources                                           {'cpu': 1, 'gpu': 0}   \n",
       "scheduler_submit_time                                  1689102794.851678   \n",
       "spill_to_cloud                                                       log   \n",
       "submit_time                                                           15   \n",
       "workload_type                                                  cpu_sleep   \n",
       "\n",
       "                                                                      3    \n",
       "image                                   gcr.io/sky-burst/skyburst:latest  \\\n",
       "job_duration                                                   14.939977   \n",
       "job_id                                                                 3   \n",
       "kube_yaml              {'apiVersion': 'batch/v1', 'kind': 'Job', 'met...   \n",
       "resources                                           {'cpu': 1, 'gpu': 0}   \n",
       "scheduler_submit_time                                  1689102799.904291   \n",
       "spill_to_cloud                                                       log   \n",
       "submit_time                                                           20   \n",
       "workload_type                                                  cpu_sleep   \n",
       "\n",
       "                                                                      4    \n",
       "image                                   gcr.io/sky-burst/skyburst:latest  \\\n",
       "job_duration                                                   12.801997   \n",
       "job_id                                                                 4   \n",
       "kube_yaml              {'apiVersion': 'batch/v1', 'kind': 'Job', 'met...   \n",
       "resources                                           {'cpu': 1, 'gpu': 0}   \n",
       "scheduler_submit_time                                  1689102804.877728   \n",
       "spill_to_cloud                                                       log   \n",
       "submit_time                                                           25   \n",
       "workload_type                                                  cpu_sleep   \n",
       "\n",
       "                                                                      5    \n",
       "image                                   gcr.io/sky-burst/skyburst:latest  \\\n",
       "job_duration                                                    3.544624   \n",
       "job_id                                                                 5   \n",
       "kube_yaml              {'apiVersion': 'batch/v1', 'kind': 'Job', 'met...   \n",
       "resources                                           {'cpu': 1, 'gpu': 0}   \n",
       "scheduler_submit_time                                  1689102809.860941   \n",
       "spill_to_cloud                                                       log   \n",
       "submit_time                                                           30   \n",
       "workload_type                                                  cpu_sleep   \n",
       "\n",
       "                                                                      6    \n",
       "image                                   gcr.io/sky-burst/skyburst:latest  \\\n",
       "job_duration                                                   19.453369   \n",
       "job_id                                                                 6   \n",
       "kube_yaml              {'apiVersion': 'batch/v1', 'kind': 'Job', 'met...   \n",
       "resources                                           {'cpu': 1, 'gpu': 0}   \n",
       "scheduler_submit_time                                  1689102814.892436   \n",
       "spill_to_cloud                                                       log   \n",
       "submit_time                                                           35   \n",
       "workload_type                                                  cpu_sleep   \n",
       "\n",
       "                                                                      7    \n",
       "image                                   gcr.io/sky-burst/skyburst:latest  \\\n",
       "job_duration                                                   11.389592   \n",
       "job_id                                                                 7   \n",
       "kube_yaml              {'apiVersion': 'batch/v1', 'kind': 'Job', 'met...   \n",
       "resources                                           {'cpu': 1, 'gpu': 0}   \n",
       "scheduler_submit_time                                   1689102819.87739   \n",
       "spill_to_cloud                                                       log   \n",
       "submit_time                                                           40   \n",
       "workload_type                                                  cpu_sleep   \n",
       "\n",
       "                                                                      8    \n",
       "image                                   gcr.io/sky-burst/skyburst:latest  \\\n",
       "job_duration                                                    4.270686   \n",
       "job_id                                                                 8   \n",
       "kube_yaml              {'apiVersion': 'batch/v1', 'kind': 'Job', 'met...   \n",
       "resources                                           {'cpu': 1, 'gpu': 0}   \n",
       "scheduler_submit_time                                  1689102824.860771   \n",
       "spill_to_cloud                                                       log   \n",
       "submit_time                                                           45   \n",
       "workload_type                                                  cpu_sleep   \n",
       "\n",
       "                                                                      9    \n",
       "image                                   gcr.io/sky-burst/skyburst:latest  \\\n",
       "job_duration                                                     4.43687   \n",
       "job_id                                                                 9   \n",
       "kube_yaml              {'apiVersion': 'batch/v1', 'kind': 'Job', 'met...   \n",
       "resources                                           {'cpu': 1, 'gpu': 0}   \n",
       "scheduler_submit_time                                  1689102829.892119   \n",
       "spill_to_cloud                                                       log   \n",
       "submit_time                                                           50   \n",
       "workload_type                                                  cpu_sleep   \n",
       "\n",
       "                                                                      10   \n",
       "image                                   gcr.io/sky-burst/skyburst:latest  \\\n",
       "job_duration                                                    2.457714   \n",
       "job_id                                                                10   \n",
       "kube_yaml              {'apiVersion': 'batch/v1', 'kind': 'Job', 'met...   \n",
       "resources                                           {'cpu': 1, 'gpu': 0}   \n",
       "scheduler_submit_time                                  1689102834.882229   \n",
       "spill_to_cloud                                                       log   \n",
       "submit_time                                                           55   \n",
       "workload_type                                                  cpu_sleep   \n",
       "\n",
       "                                                                      11  \n",
       "image                                   gcr.io/sky-burst/skyburst:latest  \n",
       "job_duration                                                   24.982641  \n",
       "job_id                                                                11  \n",
       "kube_yaml              {'apiVersion': 'batch/v1', 'kind': 'Job', 'met...  \n",
       "resources                                           {'cpu': 1, 'gpu': 0}  \n",
       "scheduler_submit_time                                  1689102839.871469  \n",
       "spill_to_cloud                                                       log  \n",
       "submit_time                                                           60  \n",
       "workload_type                                                  cpu_sleep  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.7120683102399417, 33.74045299745098, 6.0412810727372666, 14.939976839188729, 12.80199741243524, 3.544623519398357, 19.453369114977534, 11.389592447185601, 4.270686151986858, 4.436870212480407, 2.457714024423588, 24.982640966016]\n",
      "['Scheduler spun up! ', 'Job: job-4 | Arrival: 1689102805.4420917 | Start:  1689102815.4573197 | Runtime: 12.80199741243524 | cpu: 1 | gpu: 0 | ', 'Job: job-5 | Arrival: 1689102810.449461 | Start:  1689102820.465552 | Runtime: 3.544623519398357 | cpu: 1 | gpu: 0 | ', 'Job: job-6 | Arrival: 1689102815.4572952 | Start:  1689102825.473359 | Runtime: 19.453369114977534 | cpu: 1 | gpu: 0 | ', '']\n",
      "matched time {'arrival': 1689102784.8716621, 'submit': 1689102785, 'pod_start': 1689102786, 'job_end': 1689102793}\n",
      "value {'arrival': 1689102784.8716621, 'submit': 1689102785, 'pod_start': 1689102786, 'job_end': 1689102793}\n",
      "matched time {'arrival': 1689102789.871757, 'submit': 1689102790, 'pod_start': 1689102791, 'job_end': 1689102828}\n",
      "value {'arrival': 1689102789.871757, 'submit': 1689102790, 'pod_start': 1689102791, 'job_end': 1689102828}\n",
      "matched time {'arrival': 1689102834.882229, 'submit': 1689102842, 'pod_start': 1689102843, 'job_end': 1689102849}\n",
      "value {'arrival': 1689102834.882229, 'submit': 1689102842, 'pod_start': 1689102843, 'job_end': 1689102849}\n",
      "matched time {'arrival': 1689102839.8714688, 'submit': 1689102845, 'pod_start': 1689102846, 'job_end': 1689102875}\n",
      "value {'arrival': 1689102839.8714688, 'submit': 1689102845, 'pod_start': 1689102846, 'job_end': 1689102875}\n",
      "matched time {'arrival': 1689102794.8516784, 'submit': 1689102795, 'pod_start': 1689102797, 'job_end': 1689102806}\n",
      "value {'arrival': 1689102794.8516784, 'submit': 1689102795, 'pod_start': 1689102797, 'job_end': 1689102806}\n",
      "matched time {'arrival': 1689102799.9042912, 'submit': 1689102806, 'pod_start': 1689102807, 'job_end': 1689102826}\n",
      "value {'arrival': 1689102799.9042912, 'submit': 1689102806, 'pod_start': 1689102807, 'job_end': 1689102826}\n",
      "matched time {'arrival': 1689102819.87739, 'submit': 1689102826, 'pod_start': 1689102827, 'job_end': 1689102842}\n",
      "value {'arrival': 1689102819.87739, 'submit': 1689102826, 'pod_start': 1689102827, 'job_end': 1689102842}\n",
      "matched time {'arrival': 1689102824.8607714, 'submit': 1689102828, 'pod_start': 1689102829, 'job_end': 1689102837}\n",
      "value {'arrival': 1689102824.8607714, 'submit': 1689102828, 'pod_start': 1689102829, 'job_end': 1689102837}\n",
      "matched time {'arrival': 1689102829.8921194, 'submit': 1689102836, 'pod_start': 1689102837, 'job_end': 1689102845}\n",
      "value {'arrival': 1689102829.8921194, 'submit': 1689102836, 'pod_start': 1689102837, 'job_end': 1689102845}\n",
      "Onprem Jobs 9\n",
      "interval {'job-0': {'arrival': 1689102784.8716621, 'submit': 1689102785, 'pod_start': 1689102786, 'job_end': 1689102793}, 'job-1': {'arrival': 1689102789.871757, 'submit': 1689102790, 'pod_start': 1689102791, 'job_end': 1689102828}, 'job-10': {'arrival': 1689102834.882229, 'submit': 1689102842, 'pod_start': 1689102843, 'job_end': 1689102849}, 'job-11': {'arrival': 1689102839.8714688, 'submit': 1689102845, 'pod_start': 1689102846, 'job_end': 1689102875}, 'job-2': {'arrival': 1689102794.8516784, 'submit': 1689102795, 'pod_start': 1689102797, 'job_end': 1689102806}, 'job-3': {'arrival': 1689102799.9042912, 'submit': 1689102806, 'pod_start': 1689102807, 'job_end': 1689102826}, 'job-7': {'arrival': 1689102819.87739, 'submit': 1689102826, 'pod_start': 1689102827, 'job_end': 1689102842}, 'job-8': {'arrival': 1689102824.8607714, 'submit': 1689102828, 'pod_start': 1689102829, 'job_end': 1689102837}, 'job-9': {'arrival': 1689102829.8921194, 'submit': 1689102836, 'pod_start': 1689102837, 'job_end': 1689102845}}\n",
      "onprem value {'arrival': 1689102784.8716621, 'submit': 1689102785, 'pod_start': 1689102786, 'job_end': 1689102793}\n",
      "onprem value {'arrival': 1689102789.871757, 'submit': 1689102790, 'pod_start': 1689102791, 'job_end': 1689102828}\n",
      "onprem value {'arrival': 1689102834.882229, 'submit': 1689102842, 'pod_start': 1689102843, 'job_end': 1689102849}\n",
      "onprem value {'arrival': 1689102839.8714688, 'submit': 1689102845, 'pod_start': 1689102846, 'job_end': 1689102875}\n",
      "onprem value {'arrival': 1689102794.8516784, 'submit': 1689102795, 'pod_start': 1689102797, 'job_end': 1689102806}\n",
      "onprem value {'arrival': 1689102799.9042912, 'submit': 1689102806, 'pod_start': 1689102807, 'job_end': 1689102826}\n",
      "onprem value {'arrival': 1689102819.87739, 'submit': 1689102826, 'pod_start': 1689102827, 'job_end': 1689102842}\n",
      "onprem value {'arrival': 1689102824.8607714, 'submit': 1689102828, 'pod_start': 1689102829, 'job_end': 1689102837}\n",
      "onprem value {'arrival': 1689102829.8921194, 'submit': 1689102836, 'pod_start': 1689102837, 'job_end': 1689102845}\n",
      "matched time {'arrival': 1689102815.4573197, 'submit': 1689102805.4420917, 'pod_start': 1689102807.4420917, 'job_end': 1689102820.2440891, 'gpu': 0, 'cpu': 1}\n",
      "value {'arrival': 1689102815.4573197, 'submit': 1689102805.4420917, 'pod_start': 1689102807.4420917, 'job_end': 1689102820.2440891, 'gpu': 0, 'cpu': 1}\n",
      "matched time {'arrival': 1689102820.465552, 'submit': 1689102810.449461, 'pod_start': 1689102812.449461, 'job_end': 1689102815.9940846, 'gpu': 0, 'cpu': 1}\n",
      "value {'arrival': 1689102820.465552, 'submit': 1689102810.449461, 'pod_start': 1689102812.449461, 'job_end': 1689102815.9940846, 'gpu': 0, 'cpu': 1}\n",
      "matched time {'arrival': 1689102825.473359, 'submit': 1689102815.4572952, 'pod_start': 1689102817.4572952, 'job_end': 1689102836.9106643, 'gpu': 0, 'cpu': 1}\n",
      "value {'arrival': 1689102825.473359, 'submit': 1689102815.4572952, 'pod_start': 1689102817.4572952, 'job_end': 1689102836.9106643, 'gpu': 0, 'cpu': 1}\n",
      "Cloud Jobs 3\n",
      "interval {4: {'arrival': 1689102815.4573197, 'submit': 1689102805.4420917, 'pod_start': 1689102807.4420917, 'job_end': 1689102820.2440891, 'gpu': 0, 'cpu': 1}, 5: {'arrival': 1689102820.465552, 'submit': 1689102810.449461, 'pod_start': 1689102812.449461, 'job_end': 1689102815.9940846, 'gpu': 0, 'cpu': 1}, 6: {'arrival': 1689102825.473359, 'submit': 1689102815.4572952, 'pod_start': 1689102817.4572952, 'job_end': 1689102836.9106643, 'gpu': 0, 'cpu': 1}}\n",
      "cloud value {'arrival': 1689102815.4573197, 'submit': 1689102805.4420917, 'pod_start': 1689102807.4420917, 'job_end': 1689102820.2440891, 'gpu': 0, 'cpu': 1}\n",
      "cloud value {'arrival': 1689102820.465552, 'submit': 1689102810.449461, 'pod_start': 1689102812.449461, 'job_end': 1689102815.9940846, 'gpu': 0, 'cpu': 1}\n",
      "cloud value {'arrival': 1689102825.473359, 'submit': 1689102815.4572952, 'pod_start': 1689102817.4572952, 'job_end': 1689102836.9106643, 'gpu': 0, 'cpu': 1}\n",
      "{'idx': [0, 1, 10, 11, 2, 3, 7, 8, 9, 4, 5, 6], 'runtime': [7, 37, 6, 29, 9, 19, 15, 8, 8, 12.801997423171997, 3.544623613357544, 19.453369140625], 'arrival': [1689102784.8716621, 1689102789.871757, 1689102834.882229, 1689102839.8714688, 1689102794.8516784, 1689102799.9042912, 1689102819.87739, 1689102824.8607714, 1689102829.8921194, 1689102815.4573197, 1689102820.465552, 1689102825.473359], 'num_gpus': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'allocated_gpus': [{0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {0: []}, {0: []}, {1: []}, {1: []}, {}, {}, {}], 'allocated_gpus_real': [{0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {0: []}, {0: []}, {1: []}, {1: []}, {2: []}, {2: []}, {2: []}], 'start': [1689102786, 1689102791, 1689102843, 1689102846, 1689102797, 1689102807, 1689102827, 1689102829, 1689102837, 1689102807.4420917, 1689102812.449461, 1689102817.4572952], 'instance_type': ['n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'unknown', 'unknown', 'unknown'], 'node_index': [0, 1, 0, 1, 0, 0, 0, 1, 1, 3, 3, 3], 'node': ['gke-mluo-onprem-onprem-pool-6e17a3a5-9l8l', 'gke-mluo-onprem-onprem-pool-6e17a3a5-g0nb', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9l8l', 'gke-mluo-onprem-onprem-pool-6e17a3a5-g0nb', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9l8l', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9l8l', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9l8l', 'gke-mluo-onprem-onprem-pool-6e17a3a5-g0nb', 'gke-mluo-onprem-onprem-pool-6e17a3a5-g0nb', 'cloud', 'cloud', 'cloud'], 'cpus': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'submission_time': [1689102785, 1689102790, 1689102842, 1689102845, 1689102795, 1689102806, 1689102826, 1689102828, 1689102836, 1689102805.4420917, 1689102810.449461, 1689102815.4572952], 'wait_times': [1.1283378601074219, 1.1282429695129395, 8.117770910263062, 6.128531217575073, 2.1483216285705566, 7.095708847045898, 7.122610092163086, 4.139228582382202, 7.107880592346191, -8.015228033065796, -8.016091108322144, -8.016063928604126], 'is_local': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], 'cluster_size': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>runtime</th>\n",
       "      <th>arrival</th>\n",
       "      <th>num_gpus</th>\n",
       "      <th>allocated_gpus</th>\n",
       "      <th>allocated_gpus_real</th>\n",
       "      <th>start</th>\n",
       "      <th>instance_type</th>\n",
       "      <th>node_index</th>\n",
       "      <th>node</th>\n",
       "      <th>cpus</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>wait_times</th>\n",
       "      <th>is_local</th>\n",
       "      <th>cluster_size</th>\n",
       "      <th>arrival_dist</th>\n",
       "      <th>arrival_param</th>\n",
       "      <th>cloud_cluster</th>\n",
       "      <th>cpu_dist</th>\n",
       "      <th>cpu_sizes</th>\n",
       "      <th>image</th>\n",
       "      <th>loop</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>min_arrival_time</th>\n",
       "      <th>min_duration</th>\n",
       "      <th>min_waiting_time</th>\n",
       "      <th>onprem_cluster</th>\n",
       "      <th>queue_policy</th>\n",
       "      <th>random_seed</th>\n",
       "      <th>spill_to_cloud</th>\n",
       "      <th>submit_time</th>\n",
       "      <th>waiting_budget</th>\n",
       "      <th>waiting_coeff</th>\n",
       "      <th>waiting_policy</th>\n",
       "      <th>workload_type</th>\n",
       "      <th>gpu_dist</th>\n",
       "      <th>gpu_sizes</th>\n",
       "      <th>max_duration</th>\n",
       "      <th>random_seed'</th>\n",
       "      <th>schedule_tick</th>\n",
       "      <th>config</th>\n",
       "      <th>varying_values</th>\n",
       "      <th>fixed_values</th>\n",
       "      <th>arrival_dist_sweep</th>\n",
       "      <th>arrival_param_sweep</th>\n",
       "      <th>cloud_cluster_sweep</th>\n",
       "      <th>cpu_dist_sweep</th>\n",
       "      <th>cpu_sizes_sweep</th>\n",
       "      <th>image_sweep</th>\n",
       "      <th>loop_sweep</th>\n",
       "      <th>mean_duration_sweep</th>\n",
       "      <th>min_arrival_time_sweep</th>\n",
       "      <th>min_duration_sweep</th>\n",
       "      <th>min_waiting_time_sweep</th>\n",
       "      <th>onprem_cluster_sweep</th>\n",
       "      <th>queue_policy_sweep</th>\n",
       "      <th>random_seed_sweep</th>\n",
       "      <th>spill_to_cloud_sweep</th>\n",
       "      <th>submit_time_sweep</th>\n",
       "      <th>waiting_budget_sweep</th>\n",
       "      <th>waiting_coeff_sweep</th>\n",
       "      <th>waiting_policy_sweep</th>\n",
       "      <th>workload_type_sweep</th>\n",
       "      <th>gpu_dist_sweep</th>\n",
       "      <th>gpu_sizes_sweep</th>\n",
       "      <th>max_duration_sweep</th>\n",
       "      <th>random_seed'_sweep</th>\n",
       "      <th>schedule_tick_sweep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 1, 10, 11, 2, 3, 7, 8, 9, 4, 5, 6]</td>\n",
       "      <td>[7, 37, 6, 29, 9, 19, 15, 8, 8, 12.80199742317...</td>\n",
       "      <td>[-0.12833786010742188, 4.8717570304870605, 49....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[{0: []}, {1: []}, {0: []}, {1: []}, {0: []}, ...</td>\n",
       "      <td>[{0: []}, {1: []}, {0: []}, {1: []}, {0: []}, ...</td>\n",
       "      <td>[1, 6, 58, 61, 12, 22, 42, 44, 52, 22.44209170...</td>\n",
       "      <td>[n2-standard-2, n2-standard-2, n2-standard-2, ...</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 0, 1, 1, 3, 3, 3]</td>\n",
       "      <td>[gke-mluo-onprem-onprem-pool-6e17a3a5-9l8l, gk...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[0, 5, 57, 60, 10, 21, 41, 43, 51, 20.44209170...</td>\n",
       "      <td>[1.1283378601074219, 1.1282429695129395, 8.117...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>5</td>\n",
       "      <td>gke_sky-burst_us-central1-c_mluo-cloud</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>gke_sky-burst_us-central1-c_mluo-onprem</td>\n",
       "      <td>fifo</td>\n",
       "      <td>13</td>\n",
       "      <td>log</td>\n",
       "      <td>60</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>constant</td>\n",
       "      <td>cpu_sleep</td>\n",
       "      <td>[0.7, 0.15, 0.1, 0.05]</td>\n",
       "      <td>[1, 2, 4, 8]</td>\n",
       "      <td>10000</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>{'arrival_dist': 'uniform', 'arrival_param': 5...</td>\n",
       "      <td>[cpu_dist, cpu_sizes]</td>\n",
       "      <td>[arrival_dist, arrival_param, cloud_cluster, i...</td>\n",
       "      <td>uniform</td>\n",
       "      <td>5</td>\n",
       "      <td>gke_sky-burst_us-central1-c_mluo-cloud</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>gcr.io/sky-burst/skyburst:latest</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>gke_sky-burst_us-central1-c_mluo-onprem</td>\n",
       "      <td>fifo</td>\n",
       "      <td>13</td>\n",
       "      <td>log</td>\n",
       "      <td>60</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>constant</td>\n",
       "      <td>cpu_sleep</td>\n",
       "      <td>[0.7, 0.15, 0.1, 0.05]</td>\n",
       "      <td>[1, 2, 4, 8]</td>\n",
       "      <td>10000</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      idx   \n",
       "0  [0, 1, 10, 11, 2, 3, 7, 8, 9, 4, 5, 6]  \\\n",
       "\n",
       "                                             runtime   \n",
       "0  [7, 37, 6, 29, 9, 19, 15, 8, 8, 12.80199742317...  \\\n",
       "\n",
       "                                             arrival   \n",
       "0  [-0.12833786010742188, 4.8717570304870605, 49....  \\\n",
       "\n",
       "                               num_gpus   \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \\\n",
       "\n",
       "                                      allocated_gpus   \n",
       "0  [{0: []}, {1: []}, {0: []}, {1: []}, {0: []}, ...  \\\n",
       "\n",
       "                                 allocated_gpus_real   \n",
       "0  [{0: []}, {1: []}, {0: []}, {1: []}, {0: []}, ...  \\\n",
       "\n",
       "                                               start   \n",
       "0  [1, 6, 58, 61, 12, 22, 42, 44, 52, 22.44209170...  \\\n",
       "\n",
       "                                       instance_type   \n",
       "0  [n2-standard-2, n2-standard-2, n2-standard-2, ...  \\\n",
       "\n",
       "                             node_index   \n",
       "0  [0, 1, 0, 1, 0, 0, 0, 1, 1, 3, 3, 3]  \\\n",
       "\n",
       "                                                node   \n",
       "0  [gke-mluo-onprem-onprem-pool-6e17a3a5-9l8l, gk...  \\\n",
       "\n",
       "                                   cpus   \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \\\n",
       "\n",
       "                                     submission_time   \n",
       "0  [0, 5, 57, 60, 10, 21, 41, 43, 51, 20.44209170...  \\\n",
       "\n",
       "                                          wait_times   \n",
       "0  [1.1283378601074219, 1.1282429695129395, 8.117...  \\\n",
       "\n",
       "                               is_local cluster_size arrival_dist   \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]            2      uniform  \\\n",
       "\n",
       "  arrival_param                           cloud_cluster cpu_dist cpu_sizes   \n",
       "0             5  gke_sky-burst_us-central1-c_mluo-cloud      [1]       [1]  \\\n",
       "\n",
       "                              image   loop mean_duration min_arrival_time   \n",
       "0  gcr.io/sky-burst/skyburst:latest  False            10                3  \\\n",
       "\n",
       "  min_duration min_waiting_time                           onprem_cluster   \n",
       "0            2                0  gke_sky-burst_us-central1-c_mluo-onprem  \\\n",
       "\n",
       "  queue_policy random_seed spill_to_cloud submit_time waiting_budget   \n",
       "0         fifo          13            log          60             -1  \\\n",
       "\n",
       "  waiting_coeff waiting_policy workload_type                gpu_dist   \n",
       "0            10       constant     cpu_sleep  [0.7, 0.15, 0.1, 0.05]  \\\n",
       "\n",
       "      gpu_sizes max_duration random_seed' schedule_tick   \n",
       "0  [1, 2, 4, 8]        10000           13             1  \\\n",
       "\n",
       "                                              config         varying_values   \n",
       "0  {'arrival_dist': 'uniform', 'arrival_param': 5...  [cpu_dist, cpu_sizes]  \\\n",
       "\n",
       "                                        fixed_values arrival_dist_sweep   \n",
       "0  [arrival_dist, arrival_param, cloud_cluster, i...            uniform  \\\n",
       "\n",
       "  arrival_param_sweep                     cloud_cluster_sweep cpu_dist_sweep   \n",
       "0                   5  gke_sky-burst_us-central1-c_mluo-cloud            [1]  \\\n",
       "\n",
       "  cpu_sizes_sweep                       image_sweep loop_sweep   \n",
       "0             [1]  gcr.io/sky-burst/skyburst:latest      False  \\\n",
       "\n",
       "  mean_duration_sweep min_arrival_time_sweep min_duration_sweep   \n",
       "0                  10                      3                  2  \\\n",
       "\n",
       "  min_waiting_time_sweep                     onprem_cluster_sweep   \n",
       "0                      0  gke_sky-burst_us-central1-c_mluo-onprem  \\\n",
       "\n",
       "  queue_policy_sweep random_seed_sweep spill_to_cloud_sweep submit_time_sweep   \n",
       "0               fifo                13                  log                60  \\\n",
       "\n",
       "  waiting_budget_sweep waiting_coeff_sweep waiting_policy_sweep   \n",
       "0                   -1                  10             constant  \\\n",
       "\n",
       "  workload_type_sweep          gpu_dist_sweep gpu_sizes_sweep   \n",
       "0           cpu_sleep  [0.7, 0.15, 0.1, 0.05]    [1, 2, 4, 8]  \\\n",
       "\n",
       "  max_duration_sweep random_seed'_sweep schedule_tick_sweep  \n",
       "0              10000                 13                   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO (surya): Check for ground truth  -- Compare the datapoints from parse_job_df to ensure there are no missing jobs \n",
    "# TODO (surya): Support both GPU and CPU (e.g. \"workload_type\")\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, data_dict):\n",
    "        self.__dict__.update(data_dict)\n",
    "\n",
    "def parse_job_df(cluster_event_df=None, submission_df=None, sweep_df=None, avoid_congestion=True, columns=None, run_id=None, cloud_log_list=None):\n",
    "    '''\n",
    "    Parse onprem jobs first\n",
    "    '''\n",
    "    '''\n",
    "    hyperparameters = None\n",
    "    if 'hyperparameters' in submission_df:\n",
    "        #import pdb; pdb.set_trace()\n",
    "        hyperparameters = submission_df['hyperparameters']\n",
    "    import pdb; pdb.set_trace()\n",
    "    '''\n",
    "    hyperparameters = sweep_df[0]\n",
    "    onprem_event_df = cluster_event_df['onprem']\n",
    "    cloud_event_df = cluster_event_df['cloud']\n",
    "    \n",
    "    job_names = {}\n",
    "    jobs = {}\n",
    "    for col in columns: \n",
    "        jobs[col] = []\n",
    "\n",
    "    all_nodes = set()\n",
    "    nodes = {}\n",
    "    node_counter = 0\n",
    "    types = ['onprem', 'cloud']\n",
    "    nodes_indices = {}\n",
    "    \n",
    "    #import pdb; pdb.set_trace()\n",
    "    print(cloud_log_list)\n",
    "    \n",
    "    for cluster_type in types: \n",
    "        event_df = cluster_event_df[cluster_type]\n",
    "        try:\n",
    "            job_times = {}\n",
    "            pod_times = {}\n",
    "            if cluster_type == 'cloud':\n",
    "                for job in cloud_log_list[1:-1]:\n",
    "                    match = re.search(r\"Job: (\\S+) \\| Arrival: (\\S+) \\| Start:  (\\S+) \\| Runtime: (\\S+) \\| cpu: (\\S+) \\| gpu: (\\S+) \\|\", job) \n",
    "                    #match = re.search(r\"Cloud Job \\|\\| job id (\\S+) \\| job name (\\S+) \\| estimated cloud start time (\\S+) \\| estimated job duration (\\S+) \\| submission time (\\S+) \\| gpus (\\S+) \\| cpus (\\S+)\", job)\n",
    "                    match = match.groups()\n",
    "                    if match:\n",
    "                        #job_id = int(match[0])\n",
    "                        job_name = str(match[0])\n",
    "                        job_id = int(re.findall('\\d+', job_name)[0])\n",
    "                        #import pdb; pdb.set_trace()\n",
    "                        #return int(num[0]) if num else None\n",
    "                        submit = float(match[1]) # submit == arrival\n",
    "                        duration = float(match[3]) # duration == runtime\n",
    "                        arrival = float(match[2]) # arrival == start\n",
    "                        gpu = int(match[5])\n",
    "                        cpu = int(match[4])\n",
    "                        end = submit + 2 + duration\n",
    "\n",
    "                        \n",
    "                        times = {\"arrival\": arrival,\"submit\": submit,\"pod_start\": submit + 2, \"job_end\": end, \"gpu\": gpu, \"cpu\":cpu}\n",
    "                        print(f'matched time {times}')\n",
    "\n",
    "                        missing = False\n",
    "                        for v, k in times.items(): \n",
    "                            #if not k: \n",
    "                            if k == None: \n",
    "                                print(f'Missing {v} {k}')\n",
    "                                missing = True\n",
    "                        #import pdb; pdb.set_trace()\n",
    "                        print(f'value {times}')\n",
    "                    \n",
    "                        pod_times[job_id] = times\n",
    "                intervals = pod_times\n",
    "                nodes[\"cloud\"] = node_counter\n",
    "                #print(pod_times)\n",
    "                print(f'Cloud Jobs {len(intervals)}')       \n",
    "            else:   \n",
    "                cluster_data = Data(event_df)\n",
    "                cluster = event_df\n",
    "                #import pdb; pdb.set_trace()\n",
    "                '''\n",
    "                job_pods                {'job-0': ['job-0-d7zvf'], 'job-1': ['job-1-b9...\n",
    "                node_instances          {'gke-mluo-onprem-onprem-pool-6e17a3a5-9l8l': ...\n",
    "                pod_logs                {'job-0-d7zvf': '||\n",
    "                ', 'job-1-b9pzh': '||\n",
    "                ', '...\n",
    "                pod_node                {'job-0-d7zvf': 'gke-mluo-onprem-onprem-pool-6...\n",
    "                job_completed           {'job-0': 1688429084, 'job-1': 1688429275, 'jo...\n",
    "                job_successfulcreate    {'job-0': 1688429063, 'job-1': 1688429068, 'jo...\n",
    "                pod_created             {'job-0-d7zvf': 1688429064, 'job-1-b9pzh': 168...\n",
    "                pod_pulled              {'job-0-d7zvf': 1688429064, 'job-1-b9pzh': 168...\n",
    "                pod_started             {'job-0-d7zvf': 1688429064, 'job-1-b9pzh': 168...\n",
    "                Name: onprem, dtype: object\n",
    "                '''\n",
    "                cluster_size = cluster_data.cluster_size\n",
    "                job_pods = cluster_data.job_pods\n",
    "                node_instances = cluster_data.node_instances\n",
    "                pod_logs = cluster_data.pod_logs\n",
    "                pod_node = cluster_data.pod_node\n",
    "                job_completed = cluster_data.job_completed\n",
    "                job_successfulcreate = cluster_data.job_successfulcreate\n",
    "                pod_created = cluster_data.pod_created\n",
    "                pod_pulled = cluster_data.pod_pulled\n",
    "                pod_start = cluster_data.pod_started\n",
    "\n",
    "                #cluster['job_pods']\n",
    "                #cluster['node_instances']\n",
    "                #cluster['pod_logs']\n",
    "                #cluster['pod_node']\n",
    "                #cluster['job_successfulcreate']\n",
    "                #TODO: Generalize this\n",
    "                #import pdb; pdb.set_trace()\n",
    "                jobs['cluster_size'] = cluster_size\n",
    "                #jobs['node_instances'] = node_instances\n",
    "                \n",
    "                start_times = pod_start #cluster['container_start_times']\n",
    "                creation_times = job_successfulcreate #cluster['job_creation_times']\n",
    "                completion_times = job_completed #cluster['job_completion_times']\n",
    "                # TODO: Verify node names works as intended\n",
    "                pod_nodes = pod_node #cluster['node_name']\n",
    "                job_pods = job_pods #cluster['job_pods']\n",
    "                #import pdb; pdb.set_trace()\n",
    "                pod_jobs = {}\n",
    "                for k,v in job_pods.items():\n",
    "                    for i in v: \n",
    "                        pod_jobs[i] = k\n",
    "                #pod_jobs = {value: key for key, value in job_pods.items()}\n",
    "                node_instances = cluster['node_instances']\n",
    "\n",
    "                job_start_times = {}\n",
    "                job_end_times = {}\n",
    "                pod_start_times = {}\n",
    "\n",
    "                for pod in start_times:\n",
    "                    pod_name = pod\n",
    "                    pod_start_time = start_times[pod]\n",
    "                    pod_start_times[pod_name] = pod_start_time   \n",
    "\n",
    "                for job in creation_times:\n",
    "                    job_name = job\n",
    "                    job_start_time = creation_times[job]\n",
    "                    job_start_times[job_name] = job_start_time\n",
    "\n",
    "                for job in completion_times:\n",
    "                    job_name = job\n",
    "                    job_end_time = completion_times[job]\n",
    "                    job_end_times[job_name] = job_end_time\n",
    "                       \n",
    "                for pod in pod_nodes: \n",
    "                    all_nodes.add(pod_nodes[pod])\n",
    "\n",
    "                for job in job_start_times:\n",
    "                    if job in job_end_times:\n",
    "                        job_times[job] = [job_start_times[job], job_end_times[job]]\n",
    "                    \n",
    "                    job_name = job\n",
    "                    if job_name in {'job-87', 'job-85'}: \n",
    "                            if job_name in job_start_times and job_name not in job_end_times: \n",
    "                                #1684842795\n",
    "                                missing_times = {\n",
    "                                    'job-87': 7897,\n",
    "                                    'job-85': 8999\n",
    "\n",
    "                                }\n",
    "                                job_end_times[job_name] = job_start_times[job_name] + missing_times[job_name]\n",
    "\n",
    "                #import pdb; pdb.set_trace()\n",
    "                \n",
    "                for pod in pod_start_times:\n",
    "                    if pod in pod_jobs:\n",
    "                        job = pod_jobs[pod]\n",
    "                        if job not in job_end_times:\n",
    "                            print(\"MISSING JOB \" + str(job))\n",
    "                        job_id = re.findall(r'\\d+', job)[0]\n",
    "                            \n",
    "                        sub_time = submission_df[int(job_id)]['scheduler_submit_time']\n",
    "                        if job not in job_end_times: \n",
    "                            job_end_times[job] = sub_time + 100000\n",
    "                            print(\"MISSING JOB \" + str(job))\n",
    "                            \n",
    "                        pod_times[job] = [sub_time, job_end_times[job]]\n",
    "                        #import pdb; pdb.set_trace()\n",
    "\n",
    "                        times = {\"arrival\": submission_df[int(job_id)]['scheduler_submit_time'], \\\n",
    "                                 # Submit is also job start time\n",
    "                                 \"submit\": job_start_times[job], \\\n",
    "                                 \"pod_start\": pod_start_times[pod], \\\n",
    "                                 \"job_end\": job_end_times[job], \\\n",
    "                                }\n",
    "                        print(f'matched time {times}')\n",
    "                        missing = False\n",
    "                        for v, k in times.items(): \n",
    "                            if not k: \n",
    "                                print(f'Missing {v} {k}')\n",
    "                                missing = True\n",
    "                                #continue\n",
    "                        #if not missing:\n",
    "                        print(f'value {times}')\n",
    "                        if not times['job_end']:\n",
    "                            times['job_end'] = times['submit'] + 1000000\n",
    "                            \n",
    "                        if job_id in {'87', '85'}: \n",
    "                            missing_runtime = times['job_end'] - times['pod_start']\n",
    "                            print(f'MISSING RUNTIME {job_id} {missing_runtime}')\n",
    "                        \n",
    "                        #import pdb; pdb.set_trace()\n",
    "                            \n",
    "                        pod_times[job] = times\n",
    "                        #else: \n",
    "                            #print(\"MISSING JOB \" + str(job))\n",
    "\n",
    "                # TODO: Possible cause of error \n",
    "                for n in all_nodes:\n",
    "                    nodes[n] = node_counter\n",
    "                    node_counter += 1\n",
    "                    \n",
    "                #import pdb; pdb.set_trace()\n",
    "\n",
    "                intervals = pod_times\n",
    "                print(f'Onprem Jobs {len(intervals)}')\n",
    "                \n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            #print(f'matched time -- error {times}')\n",
    "            trace = traceback.format_exc()\n",
    "            print(trace)\n",
    "            return\n",
    "\n",
    "        gpu_indices = {}\n",
    "        gpu_num = 0\n",
    "        gpu_nums = {}\n",
    "        gpu_node = {} #mapping from gpu_uuid to node_name\n",
    "        node_gpus = {} #mapping from node_name to gpu_uuid to int [0, 7]\n",
    "        print(f'interval {intervals}')\n",
    "        for i, (key, value) in enumerate(intervals.items()):\n",
    "            try:\n",
    "                print(f'{cluster_type} value {value}')\n",
    "                if cluster_type == 'cloud':\n",
    "                    #print(key)\n",
    "                    job_id = str(key)\n",
    "                else:\n",
    "                    job_id = re.findall(r'\\d+', key)[0] #e.g. \"sleep-26-100444\"\n",
    "                job_names[i] = key\n",
    "                jobs['idx'].append(int(job_id))\n",
    "                jobs['runtime'].append(value['job_end']-value['pod_start'])\n",
    "                jobs['start'].append(value['pod_start'])\n",
    "                jobs['arrival'].append(value['arrival'])\n",
    "                jobs['submission_time'].append(value['submit'])\n",
    "                #print(f'{cluster_type} value {value}')\n",
    "                \n",
    "                if cluster_type == 'cloud':\n",
    "                    #print(value)\n",
    "                    jobs['num_gpus'].append(value['gpu'])\n",
    "                    #TODO: Verify cpu value for cloud jobs\n",
    "                    jobs['cpus'].append(value['cpu'])\n",
    "                else:\n",
    "                    #import pdb; pdb.set_trace()\n",
    "                    jobs['num_gpus'].append(submission_df[int(job_id)]['resources']['gpu'])#['workload']['gpu'])\n",
    "                    jobs['cpus'].append(submission_df[int(job_id)]['resources']['cpu'])#['workload']['cpu'])\n",
    "\n",
    "                # TODO: Cleanup\n",
    "                if avoid_congestion:\n",
    "                    submit_time = cluster['job_creation_times'][key] #Job start time\n",
    "                else:\n",
    "                    #import pdb; pdb.set_trace()\n",
    "                    submit_time = submission_df[int(job_id)]['scheduler_submit_time'] #Job submission time\n",
    "                \n",
    "                if not submit_time:\n",
    "                    jobs['wait_times'].append(0)\n",
    "                else:\n",
    "                    jobs['wait_times'].append(value['pod_start']-value['arrival'])\n",
    "\n",
    "                if cluster_type == \"cloud\":\n",
    "                    jobs['is_local'].append(0)\n",
    "                else:\n",
    "                    jobs['is_local'].append(1)\n",
    "                \n",
    "                #if cluster_type == 'cloud':\n",
    "                \n",
    "                if cluster_type == 'cloud':\n",
    "                    jobs['instance_type'].append(\"unknown\")\n",
    "                    jobs['node'].append(\"cloud\")\n",
    "                    jobs['allocated_gpus'].append({})\n",
    "                    jobs['node_index'].append(len(all_nodes) + 1)\n",
    "                    jobs['allocated_gpus_real'].append({len(all_nodes): [i for i in range(value['gpu'])]})\n",
    "                    #break\n",
    "                    continue\n",
    "                    \n",
    "                #import pdb; pdb.set_trace()\n",
    "                    \n",
    "                contains_pod = False\n",
    "                for i in job_pods[key]:\n",
    "                    if pod in pod_nodes:\n",
    "                        contains_pod = True\n",
    "                        \n",
    "                # TODO: Figure out why there are multiple pods per job in logs\n",
    "                \n",
    "                #if job_pods[key] not in pod_nodes:\n",
    "                if not contains_pod: \n",
    "                    jobs['instance_type'].append(\"unknown\")\n",
    "                    jobs['allocated_gpus'].append({})\n",
    "                    jobs['node_index'].append(None)\n",
    "                    jobs['allocated_gpus_real'].append({1: []})\n",
    "                    break\n",
    "                \n",
    "                #if job_pods[key] in pod_nodes:\n",
    "                #import pdb; pdb.set_trace()\n",
    "                if contains_pod: \n",
    "                    jobs['instance_type'].append(node_instances[pod_nodes[job_pods[key][0]]])\n",
    "                else:\n",
    "                    jobs['instance_type'].append(\"unknown\")\n",
    "\n",
    "                #if job_pods[key] in pod_nodes:\n",
    "                if contains_pod: \n",
    "                    jobs['allocated_gpus'].append({nodes[pod_nodes[job_pods[key][0]]]: []})\n",
    "                    jobs['node_index'].append(nodes[pod_nodes[job_pods[key][0]]])\n",
    "                else:\n",
    "                    jobs['allocated_gpus'].append({})\n",
    "                    jobs['node_index'].append(None)\n",
    "                \n",
    "                #if job_pods[key] in pod_nodes:\n",
    "                if contains_pod: \n",
    "                    jobs['node'].append(pod_nodes[job_pods[key][0]])\n",
    "                else:\n",
    "                    jobs['node'].append(\"unknown\")\n",
    "            \n",
    "                if 'gpu_index' in cluster:\n",
    "                    gpu_index = cluster['gpu_index'][job_pods[key][0]]\n",
    "                    gpu_pod = job_pods[key][0]\n",
    "                    gpu_index = gpu_index.partition(\"||\")[0]\n",
    "                    gpu_index = gpu_index.split(\"\\n\")\n",
    "                    \n",
    "                    for index in gpu_index:\n",
    "                        if index != \"\":\n",
    "                            gpu_node[index] = pod_nodes[gpu_pod]\n",
    "                            if pod_nodes[gpu_pod] not in node_gpus:\n",
    "                                node_gpus[pod_nodes[gpu_pod]] = {}\n",
    "                            if index not in node_gpus[pod_nodes[gpu_pod]]:\n",
    "                                node_gpus[pod_nodes[gpu_pod]][index] = len(node_gpus[pod_nodes[gpu_pod]])\n",
    "\n",
    "                        if index != \"\" and index not in gpu_indices:\n",
    "                            # TODO: Clean up later\n",
    "                            gpu_indices[index] = gpu_num\n",
    "                            gpu_num += 1\n",
    "                    gpu_index = [node_gpus[pod_nodes[gpu_pod]][index] for index in gpu_index if index]\n",
    "                    jobs['allocated_gpus_real'].append({nodes[pod_nodes[job_pods[key][0]]]: gpu_index})\n",
    "                else:\n",
    "                    jobs['allocated_gpus_real'].append({nodes[pod_nodes[job_pods[key][0]]]: []})\n",
    "            except Exception as e:\n",
    "                import traceback\n",
    "                trace = traceback.format_exc()\n",
    "                print(trace)\n",
    "                if cluster_type == \"cloud\":\n",
    "                    print('cloud')\n",
    "                else:\n",
    "                    print('onprem')\n",
    "                \n",
    "    if not jobs['arrival']:\n",
    "        print(\"No job arrival times logged!\")\n",
    "    \n",
    "    #print(f'nodes {nodes}')\n",
    "    print(jobs)\n",
    "    modified_arrival = [a for a in jobs['arrival'] if a]\n",
    "    #min_arrival = min(modified_arrival)\n",
    "    min_arrival = min(jobs['arrival'])\n",
    "    #print(f'minarrival {min_arrival}')\n",
    "    modified_submission = [s for s in jobs['submission_time'] if s]\n",
    "    #min_submission = min(modified_submission)\n",
    "    min_submission = min(jobs['submission_time'])\n",
    "    #print(f'minsubmission {min_submission}')\n",
    "    min_arrival = min_submission\n",
    "    #min_arrival = min(jobs['submission_time'])\n",
    "    jobs['arrival'] = [i - min_arrival for i in jobs['arrival']]\n",
    "    jobs['submission_time'] = [i - min_arrival for i in jobs['submission_time']]\n",
    "    jobs['start'] = [i - min_arrival for i in jobs['start']]\n",
    "    #jobs['arrival'] = np.array(jobs['arrival'])\n",
    "    jobs['num_gpus'] =  np.array(jobs['num_gpus'])\n",
    "    #import pdb; pdb.set_trace()\n",
    "    #hyperparameters = submission_df['hyperparameters']\n",
    "\n",
    "    for k, v in hyperparameters.items():\n",
    "        jobs[k] = v\n",
    "\n",
    "    \n",
    "    sweep_metrics = sweep_df[int(run_id)]#str(run_id)]\n",
    "    \n",
    "    jobs['config'] = dict(sweep_df['config'])\n",
    "    #import pdb; pdb.set_trace()\n",
    "    #jobs[\"varying_values\"] = sweep_df[\"varying_values\"].keys()\n",
    "    #jobs[\"fixed_values\"] = sweep_df[\"fixed_values\"].keys()\n",
    "    jobs[\"varying_values\"] = []\n",
    "    jobs[\"fixed_values\"] = []\n",
    "    for key, value in jobs['config'].items():\n",
    "        #import pdb; pdb.set_trace()\n",
    "        if isinstance(value, list):\n",
    "            jobs[\"varying_values\"].append(key)\n",
    "        else: \n",
    "            jobs[\"fixed_values\"].append(key)\n",
    "    \n",
    "    #import pdb; pdb.set_trace()\n",
    "    for k, v in sweep_metrics.items():\n",
    "        jobs[k + \"_sweep\"] = v\n",
    "    \n",
    "    #import pdb; pdb.set_trace()\n",
    "    #with open()\n",
    "    with open(\"wait\" + str(sweep_df['config']['min_waiting_time']) + \"uni\" + str(sweep_df['config']['arrival_dist']) + \".pkl\", 'wb') as file:\n",
    "        pickle.dump(jobs, file)\n",
    "\n",
    "    return jobs, len(all_nodes), hyperparameters\n",
    "\n",
    "def parse_logs(event_number=logs, avoid_congestion=False):\n",
    "    #test = log_jobs.retrieve_events_df(event_number=logs, avoid_congestion=False, only_dict=False)\n",
    "    #print(test)\n",
    "    #print(len(test))\n",
    "    #TODO: Move log_jobs from local to remote repo\n",
    "    events_dfs, sweep_df = log_jobs.retrieve_events_df(event_number=logs, avoid_congestion=False, only_dict=False)\n",
    "    #cluster_event_data_df, submission_data_df, sweep_data_df\n",
    "    columns=['idx', 'runtime', 'arrival', 'num_gpus', 'allocated_gpus', 'allocated_gpus_real', 'start', 'instance_type', 'node_index', 'node', 'cpus', 'submission_time', 'wait_times', 'is_local']\n",
    "    runs = {}\n",
    "    runs_list = []\n",
    "    for run_id, events_df in events_dfs.items():\n",
    "        cluster_event_df, submission_df, cloud_log_list = events_df\n",
    "        display(submission_df)\n",
    "        estimated_runtimes = []\n",
    "        for job in submission_df:\n",
    "            if job == 'hyperparameters':\n",
    "                continue\n",
    "            #estimated_runtimes.append((job, submission_df[job][\"job_duration\"]))\n",
    "            estimated_runtimes.append(submission_df[job][\"job_duration\"])\n",
    "            #print(job)\n",
    "            #print(submission_df[job][\"job_duration\"])\n",
    "        print(estimated_runtimes)\n",
    "        onprem_df, cloud_df = cluster_event_df\n",
    "        try:\n",
    "            run, _, _ = parse_job_df(cluster_event_df=cluster_event_df, submission_df=submission_df, sweep_df=sweep_df, avoid_congestion=False, columns=columns, run_id=run_id, cloud_log_list=cloud_log_list)\n",
    "            runs[run_id] = pd.Series(run)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            trace = traceback.format_exc()\n",
    "            print(trace)\n",
    "    runs_df = pd.DataFrame.from_dict(runs)\n",
    "    runs_df = runs_df.transpose()\n",
    "    return runs_df\n",
    "\n",
    "jobs_df = parse_logs(event_number=logs, avoid_congestion=False)\n",
    "#jobs_df = jobs_df[0:2]\n",
    "display(jobs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea33d423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_sleep\n",
      "12\n",
      "12\n",
      "9\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "[3.544623613357544, 6, 7, 8, 8, 9, 12.801997423171997, 15, 19, 19.453369140625, 29, 37]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
      "[-0.12833786010742188, 4.8717570304870605, 49.88222908973694, 54.87146878242493, 9.851678371429443, 14.904291152954102, 34.877389907836914, 39.8607714176178, 44.89211940765381, 30.457319736480713, 35.46555209159851, 40.47335910797119]\n",
      "[1, 6, 58, 61, 12, 22, 42, 44, 52, 22.442091703414917, 27.449460983276367, 32.457295179367065]\n",
      "0    [0, 5, 57, 60, 10, 21, 41, 43, 51, 20.44209170...\n",
      "Name: submission_time, dtype: object\n",
      "0    [7, 37, 6, 29, 9, 19, 15, 8, 8, 12.80199742317...\n",
      "Name: runtime, dtype: object\n",
      "0    [0, 1, 0, 1, 0, 0, 0, 1, 1, 3, 3, 3]\n",
      "Name: node_index, dtype: object\n",
      "['gke-mluo-onprem-onprem-pool-6e17a3a5-9l8l', 'gke-mluo-onprem-onprem-pool-6e17a3a5-g0nb', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9l8l', 'gke-mluo-onprem-onprem-pool-6e17a3a5-g0nb', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9l8l', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9l8l', 'gke-mluo-onprem-onprem-pool-6e17a3a5-9l8l', 'gke-mluo-onprem-onprem-pool-6e17a3a5-g0nb', 'gke-mluo-onprem-onprem-pool-6e17a3a5-g0nb', 'cloud', 'cloud', 'cloud']\n",
      "['n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'n2-standard-2', 'unknown', 'unknown', 'unknown']\n",
      "[{0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {0: []}, {0: []}, {1: []}, {1: []}, {}, {}, {}]\n",
      "[{0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {0: []}, {0: []}, {1: []}, {1: []}, {2: []}, {2: []}, {2: []}]\n"
     ]
    }
   ],
   "source": [
    "if 'workload_type' in jobs_df: \n",
    "    print(jobs_df['workload_type'][0])\n",
    "print(len(jobs_df['runtime'][0]))\n",
    "print(len(jobs_df['is_local'][0]))\n",
    "print(sum(jobs_df['is_local'][0]))\n",
    "print(len(jobs_df['arrival'][0]))\n",
    "print(len(jobs_df['start'][0]))\n",
    "print(len(jobs_df['submission_time'][0]))\n",
    "print(len(jobs_df['runtime'][0]))\n",
    "print(len(jobs_df['node'][0]))\n",
    "print(len(jobs_df['node_index'][0]))\n",
    "print(len(jobs_df['instance_type'][0]))\n",
    "print(len(jobs_df['allocated_gpus'][0]))\n",
    "print(len(jobs_df['allocated_gpus_real'][0]))\n",
    "\n",
    "print(sorted(jobs_df['runtime'][0]))\n",
    "print(jobs_df['is_local'][0])\n",
    "print(jobs_df['arrival'][0])\n",
    "print(jobs_df['start'][0])\n",
    "print(jobs_df['submission_time'])\n",
    "print(jobs_df['runtime'])\n",
    "print(jobs_df['node_index'])\n",
    "print(jobs_df['node'][0])\n",
    "print(jobs_df['instance_type'][0])\n",
    "print(jobs_df['allocated_gpus'][0])\n",
    "print(jobs_df['allocated_gpus_real'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9682cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobs_df['arrival_mask'] = jobs_df['start'].apply(lambda x: [0 if not i else 1 for i in x])\n",
    "jobs_df['arrival_mask'] = jobs_df['is_local']#.apply(lambda x: [0 if not i else 1 for i in x])\n",
    "jobs_df['onprem_mask'] = jobs_df['arrival_mask']\n",
    "\n",
    "# CLIP WAITS\n",
    "\n",
    "def cloud_wait_unclipped(row): \n",
    "    cloud_wait = [row['wait_times'][i] for i, n in enumerate(row['arrival_mask']) if n == 0]\n",
    "    return cloud_wait\n",
    "jobs_df['cloud_wait_unclipped'] = jobs_df.apply(cloud_wait_unclipped, axis=1)\n",
    "\n",
    "def clipped_wait(row): \n",
    "    k8s_scheduling_waiting_constant = 1 #wait_time_2\n",
    "    onprem_wait = [row['wait_times'][i] for i, n in enumerate(row['arrival_mask']) if n == 1]\n",
    "    cloud_wait = [k8s_scheduling_waiting_constant + row['wait_times'][i] for i, n in enumerate(row['arrival_mask']) if n == 0]\n",
    "    #cloud_wait = [k8s_scheduling_waiting_constant + row['wait_times'] for i, n in enumerate(row['arrival_mask']) if n == 0]\n",
    "    new_wait = onprem_wait + cloud_wait\n",
    "    return new_wait\n",
    "\n",
    "jobs_df['wait_times'] = jobs_df.apply(clipped_wait, axis=1)\n",
    "\n",
    "def cloud_wait(row): \n",
    "    k8s_scheduling_waiting_constant = 1 #wait_time_2\n",
    "    cloud_wait = [k8s_scheduling_waiting_constant + row['wait_times'][i] for i, n in enumerate(row['arrival_mask']) if n == 0]\n",
    "    #cloud_wait = [k8s_scheduling_waiting_constant + row['wait_time'] for i, n in enumerate(row['arrival_mask']) if n == 0]\n",
    "    return cloud_wait\n",
    "jobs_df['cloud_wait'] = jobs_df.apply(cloud_wait, axis=1)\n",
    "\n",
    "\n",
    "def onprem_wait(row): \n",
    "    k8s_scheduling_waiting_constant = 1 #wait_time_2\n",
    "    onprem_wait = [row['wait_times'][i] for i, n in enumerate(row['arrival_mask']) if n == 1]\n",
    "    return onprem_wait\n",
    "\n",
    "jobs_df['onprem_wait'] = jobs_df.apply(onprem_wait, axis=1)\n",
    "\n",
    "# COMPUTE METRICS\n",
    "\n",
    "jobs_df['avg_wait'] = jobs_df['wait_times'].apply(lambda x: sum(x)/len(x))\n",
    "jobs_df['avg_runtime'] = jobs_df['runtime'].apply(lambda x: sum(x)/len(x))\n",
    "\n",
    "def compute_total_time(row):\n",
    "    total_time = [row['wait_times'][i] + row['runtime'][i] for i in range(len(row['wait_times']))]\n",
    "    return total_time\n",
    "\n",
    "\n",
    "jobs_df['total_time'] = jobs_df.apply(compute_total_time, axis=1)\n",
    "\n",
    "def compute_completion_time(row):\n",
    "    # TODO: Submission time is time submitted to starburst \n",
    "    #completion_time = [row['total_time'][i] + row['submission_time'][i] for i in range(len(row['wait_times']))]\n",
    "    completion_time = [row['total_time'][i] + row['arrival'][i] for i in range(len(row['wait_times']))]\n",
    "    return completion_time\n",
    "\n",
    "jobs_df['completion_time'] = jobs_df.apply(compute_completion_time, axis=1)\n",
    "#jobs_df['avg_jct'] = jobs_df['total_time'].apply(lambda x: sum(x)/len(x))\n",
    "\n",
    "def compute_avg_jct(row):\n",
    "    arrival_times = row['arrival']\n",
    "    run_time = row['runtime']\n",
    "    wait_time = row['wait_times']\n",
    "    resources = row['num_gpus']\n",
    "    starts = row['start']\n",
    "    idxes = row['idx']\n",
    "    is_locals = row['is_local']\n",
    "    sort_zip = sorted(zip(idxes, arrival_times, run_time, starts, resources, wait_time))\n",
    "    \n",
    "    #start = sort_zip[10][1]\n",
    "    #end = sort_zip[-10][1]\n",
    "    \n",
    "    total_used_space = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for l in sort_zip:\n",
    "        #job_idx = l[0]\n",
    "        #job_arrival = l[1]\n",
    "        job_runtime = l[2]\n",
    "        job_wait_time = l[1]\n",
    "        #job_start = l[3]\n",
    "        job_gpus = l[4]\n",
    "        wait_time = l[5]\n",
    "        #inter_start = max(job_start, start)\n",
    "        #inter_end = min(job_start + job_runtime, end)\n",
    "        #if inter_end >= inter_start:\n",
    "        #    total_used_space+= job_gpus * (inter_end - inter_start)\n",
    "        total_time += job_runtime\n",
    "        total_time += wait_time\n",
    "        \n",
    "    jct = total_time/len(sort_zip)#total_used_space/(row['cluster_size']*4*row['gpus_per_node']*(end-start))\n",
    "    jct = jct/3600\n",
    "    return jct\n",
    "jobs_df['avg_jct'] = jobs_df.apply(compute_avg_jct, axis=1)\n",
    "\n",
    "def compute_cluster_utilization(row):\n",
    "    arrival_times = row['arrival']\n",
    "    run_time = row['runtime']\n",
    "    resources = row['num_gpus']\n",
    "    starts = row['start']\n",
    "    idxes = row['idx']\n",
    "    is_locals = row['is_local']\n",
    "    sort_zip = sorted(zip(idxes, arrival_times, run_time, starts, resources, is_locals))\n",
    "    \n",
    "    start = sort_zip[0][1]\n",
    "    end = sort_zip[-1][1]\n",
    "    \n",
    "    total_used_space = 0\n",
    "    for l in sort_zip:\n",
    "        job_idx = l[0]\n",
    "        job_arrival = l[1]\n",
    "        job_runtime = l[2]\n",
    "        job_start = l[3]\n",
    "        job_gpus = l[4]\n",
    "        is_local = l[5]\n",
    "        if is_local==1:\n",
    "            inter_start = max(job_start, start)\n",
    "            inter_end = min(job_start + job_runtime, end)\n",
    "            #import pdb; pdb.set_trace()\n",
    "            if inter_end >= inter_start:\n",
    "                total_used_space+= job_gpus * (inter_end - inter_start)\n",
    "    #import pdb; pdb.set_trace()\n",
    "    #cluster_utilization = total_used_space/(row['cluster_size']*4*row['gpus_per_node']*(end-start))\n",
    "    resources_per_node = 0\n",
    "    if row['instance_type']:\n",
    "        gpus_per_node = INSTANCE_GPUS[row['instance_type'][0]]\n",
    "        cpus_per_node = INSTANCE_CPUS[row['instance_type'][0]]\n",
    "        if not gpus_per_node:\n",
    "            resources_per_node = cpus_per_node\n",
    "        else: \n",
    "            resources_per_node = gpus_per_node\n",
    "    #import pdb; pdb.set_trace()\n",
    "    cluster_utilization = total_used_space/(row['cluster_size']*4*resources_per_node*(end-start))\n",
    "    #cluster_utilization = total_used_space/(row['cluster_size']*4*row['gpus_per_node']*(end-start))\n",
    "    #import pdb; pdb.set_trace()\n",
    "    return cluster_utilization\n",
    "        \n",
    "#     # TODO: Remove previous arrival and \n",
    "#     print(row['arrival'])\n",
    "#     surface_area = [row['runtime'][i] * row['num_gpus'][i] for i in range(len(row['runtime']))]\n",
    "#     utilized_surface_area = sum(surface_area)\n",
    "#     total_surface_area = (max(row['completion_time']) - min(row['submission_time'])) * (row['gpus_per_node'] * 1) #row['cluster_size'])\n",
    "#     cluster_utilization = utilized_surface_area/total_surface_area\n",
    "#     return cluster_utilization\n",
    "\n",
    "jobs_df['cluster_utilization'] = jobs_df.apply(compute_cluster_utilization, axis=1)\n",
    "\n",
    "def compute_system_utilization(row):\n",
    "    arrival_times = row['arrival']\n",
    "    run_time = row['runtime']\n",
    "    resources = row['num_gpus']\n",
    "    starts = row['start']\n",
    "    idxes = row['idx']\n",
    "    is_locals = row['is_local']\n",
    "    sort_zip = sorted(zip(idxes, arrival_times, run_time, starts, resources, is_locals))\n",
    "    \n",
    "    start = sort_zip[0][1]\n",
    "    end = sort_zip[-1][1]\n",
    "    \n",
    "    total_used_space = 0\n",
    "    for l in sort_zip:\n",
    "        job_idx = l[0]\n",
    "        job_arrival = l[1]\n",
    "        job_runtime = l[2]\n",
    "        job_start = l[3]\n",
    "        job_gpus = l[4]\n",
    "        is_local = l[5]\n",
    "        inter_start = max(job_start, start)\n",
    "        inter_end = min(job_start + job_runtime, end)\n",
    "        if inter_end >= inter_start:\n",
    "            total_used_space += job_gpus * (inter_end - inter_start)\n",
    "    resources_per_node = 0\n",
    "    if row['instance_type']:\n",
    "        gpus_per_node = INSTANCE_GPUS[row['instance_type'][0]]\n",
    "        cpus_per_node = INSTANCE_CPUS[row['instance_type'][0]]\n",
    "        if not gpus_per_node:\n",
    "            resources_per_node = cpus_per_node\n",
    "        else: \n",
    "            resources_per_node = gpus_per_node\n",
    "    system_utilization = total_used_space/(row['cluster_size']*4*resources_per_node*(end-start))\n",
    "    #system_utilization = total_used_space/(row['cluster_size']*4*row['gpus_per_node']*(end-start))\n",
    "    \n",
    "    return system_utilization\n",
    "\n",
    "jobs_df['system_utilization'] = jobs_df.apply(compute_system_utilization, axis=1)\n",
    "\n",
    "        \n",
    "#     # TODO: Remove previous arrival and \n",
    "#     print(row['arrival'])\n",
    "#     surface_area = [row['runtime'][i] * row['num_gpus'][i] for i in range(len(row['runtime']))]\n",
    "#     utilized_surface_area = sum(surface_area)\n",
    "#     total_surface_area = (max(row['completion_time']) - min(row['submission_time'])) * (row['gpus_per_node'] * 1) #row['cluster_size'])\n",
    "#     cluster_utilization = utilized_surface_area/total_surface_area\n",
    "#     return cluster_utilization\n",
    "\n",
    "\n",
    "#def compute_system_utilization(row):\n",
    "    # TODO: Compute this value correctly\n",
    "    #return system_utilization\n",
    "\n",
    "#jobs_df['cluster_utilization'] = jobs_df.apply(compute_cluster_utilization, axis=1)\n",
    "GCP_PRICES = {\n",
    "    \"e2-medium\": 0.038795,\n",
    "    \"e2-standard-8\": 0.31036,\n",
    "    \"unknown\": 0.038795,\n",
    "    \"n1-standard-96\": 4.56 \n",
    "}\n",
    "\n",
    "\n",
    "def compute_total_cost(row):\n",
    "    run_time = row['runtime']\n",
    "    resources = row['num_gpus']\n",
    "    idxes = row['idx']\n",
    "    is_locals = row['is_local']\n",
    "    sort_zip = sorted(zip(idxes, run_time, resources, is_locals))\n",
    "\n",
    "    \n",
    "    total_cloud_cost = 0\n",
    "    for l in sort_zip:\n",
    "        job_idx = l[0]\n",
    "        job_runtime = l[1]\n",
    "        job_gpus = l[2]\n",
    "        is_local = l[3]\n",
    "        if is_local==0:\n",
    "            total_cloud_cost += job_runtime * job_gpus\n",
    "\n",
    "    return total_cloud_cost/3600\n",
    "    # TODO: Compute this value correctly\n",
    "    # Get all cloud runtimes + submit \n",
    "#     total_time = [row['runtime'][i] * row['num_gpus'][i] * (1 - row['arrival_mask'][i]) * GCP_PRICES[row['instance_type'][i]] for i in range(len(row['arrival_mask']))]\n",
    "#     return sum(total_time)\n",
    "\n",
    "jobs_df['total_cloud_cost'] = jobs_df.apply(compute_total_cost, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "609cf673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gke-mluo-onprem-onprem-pool-6e17a3a5-9l8l',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-g0nb',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-9l8l',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-g0nb',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-9l8l',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-9l8l',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-9l8l',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-g0nb',\n",
       " 'gke-mluo-onprem-onprem-pool-6e17a3a5-g0nb',\n",
       " 'cloud',\n",
       " 'cloud',\n",
       " 'cloud']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df\n",
    "jobs_df['node'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55400294",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 6), (2, 58), (3, 61), (4, 12), (5, 22), (6, 42), (7, 44), (8, 52), (9, 30.457319736480713), (10, 35.46555209159851), (11, 40.47335910797119)]\n",
      "start times\n",
      "[1, 6, 58, 61, 12, 22, 42, 44, 52, 22.442091703414917, 27.449460983276367, 32.457295179367065]\n",
      "[0, 5, 57, 60, 10, 21, 41, 43, 51, 20.442091703414917, 25.449460983276367, 30.457295179367065]\n",
      "pod scheduling time (seconds)\n",
      "[1, 1, 1, 1, 2, 1, 1, 1, 1, 2.0, 2.0, 2.0]\n",
      "run locally (1=local, 0=cloud)\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
      "allocated_gpus_real\n",
      "[{0: []}, {1: []}, {0: []}, {1: []}, {0: []}, {0: []}, {0: []}, {1: []}, {1: []}, {2: []}, {2: []}, {2: []}]\n",
      "allocated_gpus\n",
      "[{0: [1]}, {1: [1]}, {0: [1]}, {1: [1]}, {0: [2]}, {0: [2]}, {0: [2]}, {1: [2]}, {1: [2]}, {3: [1]}, {3: [2]}, {3: [2]}]\n",
      "[-0.12833786010742188, 4.8717570304870605, 49.88222908973694, 54.87146878242493, 9.851678371429443, 14.904291152954102, 34.877389907836914, 39.8607714176178, 44.89211940765381, 30.457319736480713, 35.46555209159851, 40.47335910797119]\n",
      "IDs\n",
      "[0, 1, 10, 11, 2, 3, 7, 8, 9, 4, 5, 6]\n",
      "RUNTIME\n",
      "[7, 37, 6, 29, 9, 19, 15, 8, 8, 12.801997423171997, 3.544623613357544, 19.453369140625]\n",
      "VERIFYING\n",
      "[-0.12833786010742188, 4.8717570304870605, 9.851678371429443, 14.904291152954102, 30.457319736480713, 34.877389907836914, 35.46555209159851, 39.8607714176178, 40.47335910797119, 44.89211940765381, 49.88222908973694, 54.87146878242493]\n",
      "cloud runtimes (seconds)\n",
      "[12.801997423171997, 3.544623613357544, 19.453369140625]\n",
      "onprem runtimes (seconds)\n",
      "[7, 37, 6, 29, 9, 19, 15, 8, 8]\n",
      "0 12 12 12\n",
      "workload type\n",
      "cpu_sleep\n",
      "gpus\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "cpus list\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "allocated_gpus\n",
      "[{0: [1]}, {1: [1]}, {0: [1]}, {1: [1]}, {0: [2]}, {0: [2]}, {0: [2]}, {1: [2]}, {1: [2]}, {3: [1]}, {3: [2]}, {3: [2]}]\n",
      "j_idx 9\n",
      "gpu_idx 1\n",
      "j_idx 10\n",
      "gpu_idx 2\n",
      "j_idx 11\n",
      "gpu_idx 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workload type\n",
      "cpu_sleep\n",
      "gpus\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "cpus list\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [1]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "job_cpu_size 1\n",
      "allocated resources -- cpus or gpus: [2]\n",
      "allocated_gpus\n",
      "[{0: [1]}, {1: [1]}, {0: [1]}, {1: [1]}, {0: [2]}, {0: [2]}, {0: [2]}, {1: [2]}, {1: [2]}, {3: [1]}, {3: [2]}, {3: [2]}]\n",
      "j_idx 0\n",
      "gpu_idx 31\n",
      "j_idx 1\n",
      "gpu_idx 23\n",
      "j_idx 2\n",
      "gpu_idx 31\n",
      "j_idx 3\n",
      "gpu_idx 23\n",
      "j_idx 4\n",
      "gpu_idx 30\n",
      "j_idx 5\n",
      "gpu_idx 30\n",
      "j_idx 6\n",
      "gpu_idx 30\n",
      "j_idx 7\n",
      "gpu_idx 22\n",
      "j_idx 8\n",
      "gpu_idx 22\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def index_mapping(jobs=None, gpus_per_node=8, resource='cpu'):#gpu_value=None):\n",
    "    '''\n",
    "    Implement greedly algorithm with heap to place jobs to free resource indicies\n",
    "    \n",
    "    Specify which resource (e.g. gpu, cpu) to use fitting jobs to indices\n",
    "    \n",
    "    (1) Add all jobs to queue, then greedily assign indicies \n",
    "    (2) Have priority queue for each node with \"Free indices\" sorted by index number \n",
    "    (3) Iterate over all start times \n",
    "\n",
    "    TODO: Fix 1-off CPU index error \n",
    "    TODO: Don't let any job_idx values to be -1, and ensure it starts at node 1\n",
    "    TODO: Verify allocated_nodes\n",
    "    TODO: Determine how parsing changes between http_info and default values \n",
    "    TODO: Verify arrival value is accurate\n",
    "    TODO: Create a list of times that include all arrival times and completion times in the same list in numerical order \n",
    "    '''\n",
    "    '''\n",
    "    if gpu_jobs: \n",
    "        gpu_value = 'allocated_gpus_index'\n",
    "    else: \n",
    "        gpu_value = 'allocated_gpus'\n",
    "    '''\n",
    "    workload = 'gpu'\n",
    "    if 'workload_type' in jobs: \n",
    "        print('workload type')\n",
    "        print(jobs['workload_type'])\n",
    "        workload = jobs['workload_type']\n",
    "    print('gpus')\n",
    "    print(jobs['num_gpus'])\n",
    "    print('cpus list')\n",
    "    print(jobs['cpus'])\n",
    "    #import pdb; pdb.set_trace()\n",
    "    GPUS_PER_NODE = gpus_per_node\n",
    "    allocated_nodes = jobs['node_index']\n",
    "    \n",
    "    \n",
    "    #if resource == 'gpu':\n",
    "    if workload == 'gpu':\n",
    "        cpus = jobs['num_gpus']\n",
    "    else: \n",
    "        cpus = jobs['cpus']\n",
    "    #gpus = jobs['gpus']\n",
    "    nodes = set(allocated_nodes)\n",
    "    \n",
    "    node_jobs ={}\n",
    "    node_queues = {}\n",
    "    for node in nodes:\n",
    "        node_queues[node] = [i + 1 for i in range(GPUS_PER_NODE)]\n",
    "        node_jobs[node] = []\n",
    "\n",
    "    global_queue = [] # Queue sorted on end time -- earliest to latest end time\n",
    "    job_id_to_index = {} \n",
    "\n",
    "    for i in range(len(jobs['arrival'])):\n",
    "        #Remove values from queue\n",
    "        #import pdb; pdb.set_trace()\n",
    "        job_id = jobs['idx'][i]\n",
    "        job_id_to_index[job_id] = i\n",
    "        job_node = jobs['node_index'][i]\n",
    "        #if resource == 'gpu':\n",
    "        if workload == 'gpu':\n",
    "            job_cpu_size = jobs['num_gpus'][i]\n",
    "        else: \n",
    "            job_cpu_size = jobs['cpus'][i]\n",
    "        job_arrival = jobs['arrival_plot'][i]\n",
    "        job_runtime = jobs['runtime'][i]\n",
    "        \n",
    "        while global_queue and global_queue[0][0] <= job_arrival: \n",
    "            end_time, end_job_id = heapq.heappop(global_queue)\n",
    "            released_index = job_id_to_index[end_job_id]\n",
    "            for released_node in jobs['allocated_gpus'][released_index]: \n",
    "                released_cpus = jobs['allocated_gpus'][released_index][released_node]\n",
    "                released_node_queue = node_queues[released_node]\n",
    "                try:\n",
    "                    node_jobs[released_node].remove(end_job_id)\n",
    "                except:\n",
    "                    #import pdb; pdb.set_trace()\n",
    "                    print(\"Job Id not found\")\n",
    "                    print(end_job_id)\n",
    "                    print(node_jobs[released_node])\n",
    "                    continue\n",
    "                for cpu in released_cpus:\n",
    "                    heapq.heappush(released_node_queue, cpu)\n",
    "\n",
    "        heapq.heappush(global_queue, (job_arrival + job_runtime, job_id))\n",
    "        job_allocated_cpus = []\n",
    "        node_queue = node_queues[job_node]\n",
    "        node_jobs[job_node].append(job_id)\n",
    "    \n",
    "        print(f'job_cpu_size {job_cpu_size}')\n",
    "        try:\n",
    "            for j in range(job_cpu_size):\n",
    "                cpu_index = heapq.heappop(node_queue)\n",
    "                job_allocated_cpus.append(cpu_index)\n",
    "        except:\n",
    "            print(\"not enough cpus to fit jobs\")\n",
    "            print(node_queue)\n",
    "            print(job_allocated_cpus)\n",
    "        \n",
    "        print(f'allocated resources -- cpus or gpus: {job_allocated_cpus}')\n",
    "\n",
    "        jobs['allocated_gpus'][i] = {job_node: job_allocated_cpus}\n",
    "        #print(jobs['allocated_gpus'][i])\n",
    "        #import pdb; pdb.set_trace()\n",
    "\n",
    "    return jobs\n",
    "\n",
    "def generate_gantt_chart(row=None, gpus_per_node=None, ratio=None, scale=None, gpu_jobs=None):\n",
    "    '''\n",
    "    Create \"threads index\" that track CPU jobs running together\n",
    "    #TODO: Modify function to plot CPU jobs --> number of jobs concurrently running may exceed cpu count\n",
    "    #TODO: Plot color based on job start time and not job index\n",
    "    #TODO: Determine why jobs dissapaear when strings labels are used for nodes\n",
    "    #TODO: Label each row of jobs with the name of the node -- not just integers \n",
    "    #TODO: Plot cloud values in a separate plot\n",
    "    '''\n",
    "    workload = \"gpu\"\n",
    "    if 'workload_type' in row: \n",
    "        workload = row['workload_type']\n",
    "        \n",
    "    #if 'workload_type' in row and row['workload_type'] == 'cpu': \n",
    "    if workload == 'cpu':\n",
    "        gpus_per_nodes = 2\n",
    "        \n",
    "    graphs = ['cloud', 'onprem']\n",
    "    for graph in graphs:\n",
    "        #import pdb; pdb.set_trace()\n",
    "        save=False; path=None; subplt=None; plt_index=None; tag=None; plot_sweep=False\n",
    "        varying_values = row['varying_values']\n",
    "        tag = \"\"\n",
    "\n",
    "        count = 0 \n",
    "        for value in varying_values: \n",
    "            tag += str(value)\n",
    "            tag += \":\"\n",
    "            if isinstance(row[value], str) and len(row[value]) < 50: \n",
    "                tag += str(row[value])\n",
    "            tag += \" | \"\n",
    "            count += 1\n",
    "            if count % 5 == 0: \n",
    "                tag += '\\n'\n",
    "                \n",
    "        gpu_value = 'allocated_gpus'#_real'\n",
    "        \n",
    "        '''\n",
    "        if 'workload_type' in row and row['workload_type'] == 'cpu': \n",
    "            gpu_value = 'allocated_gpus'\n",
    "        elif gpu_jobs: \n",
    "            gpu_value = 'allocated_gpus_real'\n",
    "        else: \n",
    "            gpu_value = 'allocated_gpus'\n",
    "        '''\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        #GPUS_PER_NODE = row['cpus_per_node']\n",
    "        GPUS_PER_NODE = gpus_per_node\n",
    "        \n",
    "        '''\n",
    "        if 'workload_type' in row: \n",
    "            print('workload type')\n",
    "            print(row['workload_type'])\n",
    "            row = index_mapping(row, GPUS_PER_NODE, row['workload_type'])\n",
    "        else: \n",
    "            row = index_mapping(row, GPUS_PER_NODE, 'gpu')\n",
    "        '''\n",
    "        \n",
    "        row = index_mapping(row, GPUS_PER_NODE, 'gpu')\n",
    "        \n",
    "        '''\n",
    "        if 'workload_type' in row and row['workload_type'] == 'cpu':\n",
    "            print(\"mapped indices\")\n",
    "            row = index_mapping(row, GPUS_PER_NODE, 'cpu')\n",
    "        #if not gpu_jobs: \n",
    "        elif graph == 'cloud':\n",
    "            GPUS_PER_NODE = 32\n",
    "            #print(row['allocated_gpus'])\n",
    "            row = index_mapping(row, GPUS_PER_NODE, 'gpu')\n",
    "            #print(row['allocated_gpus'])\n",
    "        #import pdb; pdb.set_trace()\n",
    "        #if row['workload_type'] == 'cpu':\n",
    "        '''\n",
    "\n",
    "        \n",
    "        #print(\"allocated_gpus_real\")\n",
    "        #print(row['allocated_gpus_real'])\n",
    "        print(\"allocated_gpus\")\n",
    "        print(row['allocated_gpus'])\n",
    "        \n",
    "        NUM_COLORS = len(row['idx'])\n",
    "        cm = plt.get_cmap('gist_rainbow')\n",
    "        colors = [cm(1. * i / NUM_COLORS) for i in range(NUM_COLORS)]\n",
    "\n",
    "        y_lim_min = 1000\n",
    "        y_lim_max = -1000\n",
    "        num_nodes = row['cluster_size'] + row['cluster_size']\n",
    "        #num_nodes = row['cluster_size'] + row['cloud_cluster_nodes']\n",
    "\n",
    "        total_gpus = num_nodes * GPUS_PER_NODE #GPUs equivalent to CPUs -- if no GPU's then GPUS_PER_NODE reflects cpus\n",
    "        segment_height_list = {}\n",
    "        gpu_indices = {}\n",
    "        gpu_rows = set()\n",
    "        node_name = \"\"\n",
    "\n",
    "        # TODO: Plot infinite cloud spillover \n",
    "        try: \n",
    "            #import pdb; pdb.set_trace()\n",
    "            for j_idx in range(len(row['idx'])):\n",
    "                allocated_gpus = row[gpu_value][j_idx]\n",
    "                \n",
    "                #if graph == 'cloud':\n",
    "                #    allocated_gpus = row['allocated_gpus'][j_idx]\n",
    "                \n",
    "                #print(allocated_gpus)\n",
    "                #print(allocated_gpus)\n",
    "                #segment = (row['arrival'][j_idx],\n",
    "                #            row['arrival'][j_idx] + row['runtime'][j_idx], j_idx)\n",
    "                #segment = (row['submission_time'][j_idx],\n",
    "                #            row['submission_time'][j_idx] + row['runtime'][j_idx], j_idx)\n",
    "                segment = (row['arrival_plot'][j_idx],\n",
    "                            row['arrival_plot'][j_idx] + row['runtime'][j_idx], j_idx)\n",
    "\n",
    "                node_name = row['node'][j_idx]\n",
    "                if graph == 'onprem' and node_name == 'cloud': \n",
    "                    continue\n",
    "                elif graph == 'cloud' and node_name != 'cloud':\n",
    "                    continue\n",
    "                \n",
    "                print(f'j_idx {j_idx}')\n",
    "                \n",
    "                #if graph == 'cloud' and node_name == 'cloud':\n",
    "                #    print(allocated_gpus)\n",
    "                \n",
    "                for node_idx in allocated_gpus.keys():\n",
    "                    for node_gpu_idx in allocated_gpus[node_idx]:\n",
    "                        if graph == 'cloud': \n",
    "                            gpu_idx = node_gpu_idx\n",
    "                            #print(gpu_idx)\n",
    "                        else: \n",
    "                            gpu_idx = total_gpus - (GPUS_PER_NODE * node_idx + node_gpu_idx)\n",
    "                        print(f'gpu_idx {gpu_idx}')\n",
    "                        \n",
    "                        gpu_rows.add(gpu_idx)\n",
    "                        #print(node_gpu_idx)\n",
    "                        #print(gpu_rows)\n",
    "                        gpu_indices[node_name] = [gpu_idx]\n",
    "                        y_lim_min = min(y_lim_min, gpu_idx) #- 8)#if gpu_idx > 0 else gpu_index - 8)\n",
    "                        \n",
    "                        y_lim_max = max(y_lim_max, gpu_idx + 1) #+ 8)\n",
    "                        if graph == 'cloud':\n",
    "                            y_lim_max = GPUS_PER_NODE\n",
    "\n",
    "                        plt.barh(gpu_idx,\n",
    "                                    width=row['runtime'][j_idx],\n",
    "                                    edgecolor='black',\n",
    "                                    height=1.0,\n",
    "                                    left=segment[0],\n",
    "                                    align='edge',\n",
    "                                    color=colors[row['idx'][j_idx]] if row['idx'][j_idx] < len(colors) else None,\n",
    "                                    alpha = 0.5)    \n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            t = traceback.format_exc()\n",
    "            print(t)\n",
    "            print(e)\n",
    "\n",
    "        for i in range(total_gpus + 1):\n",
    "            multiplier = math.ceil(num_nodes / 32)\n",
    "            if (i + 1) % GPUS_PER_NODE == 1:\n",
    "                plt.axhline(y=i + 1, linewidth=3 / multiplier, color='black')\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        max_arrival = max(row['arrival_plot'])\n",
    "        completions = [row['arrival_plot'][i] + row['runtime'][i] for i in range(len(row['arrival_plot']))]\n",
    "        max_completion = max(completions)\n",
    "\n",
    "        x_lim_max = max_completion\n",
    "        last_job_time = max(row['completion_time'])\n",
    "        #print(last_job_time)\n",
    "        #26913.0\n",
    "        #18405.78506708145\n",
    "        last_job_time= 1000#18405.78506708145#26913\n",
    "        dim=(y_lim_min, y_lim_max, 0, last_job_time)\n",
    "        bottom, top, left, right = dim\n",
    "        plt.ylim(bottom=bottom, top=top)\n",
    "        plt.xlim(left=left, right=right)\n",
    "        plt.axvline(x=max_arrival, color='brown', linewidth=0.75)\n",
    "        plt.xlabel('Time (hrs)')\n",
    "        plt.ylabel('Nodes ')\n",
    "        #if graph == 'cloud'\n",
    "        plt.title(str(tag))\n",
    "        if graph == 'cloud':\n",
    "            plt.title(f'Cloud {workload} Jobs')\n",
    "        elif graph == 'onprem':\n",
    "            plt.title(f'Onprem {workload} Jobs')\n",
    "        #plt.title(graph)\n",
    "\n",
    "        gpu_labels = sorted([(v, k) for k, v in gpu_indices.items()])\n",
    "        ticks = [label[0] for label in gpu_labels]\n",
    "        ticks = np.array(ticks)\n",
    "        ticks = ticks.flatten()\n",
    "        labels = [label[1] for label in gpu_labels]\n",
    "        labels = np.array(labels)\n",
    "        labels = labels.flatten()\n",
    "        plt.yticks(ticks)\n",
    "        labels = [i for i in range(len(labels))]\n",
    "        ax.set_yticklabels(labels)\n",
    "        new_labels = {}\n",
    "        node_count = 0\n",
    "        #for k, v in labels.items():\n",
    "            #new_labels[node_count] = k #node_count\n",
    "            #node_count += 1\n",
    "            #new_labels.append(node_count)\n",
    "        #labels = {1.0: 'High', 0.0: 'Medium', -1.0: 'Low'}\n",
    "        #ax.set_yticks(list(labels.keys()))\n",
    "        #ax.set_yticks(list(new_labels.keys()))\n",
    "        plt.rcParams.update({'font.size': 20})\n",
    "        plt.tick_params(axis='y', which='both', bottom=False, top=False, labelbottom=False, right=False, left=False, labelleft=False)\n",
    "        ax.set_ylabel('')\n",
    "        \n",
    "        def divide(x, pos):\n",
    "            return '{}'.format(round(x / 3600, 1))\n",
    "\n",
    "        # Set the formatter\n",
    "        import matplotlib.ticker as ticker\n",
    "        formatter = ticker.FuncFormatter(divide)\n",
    "        ax.xaxis.set_major_formatter(formatter)\n",
    "        \n",
    "        if save:\n",
    "            if path: \n",
    "                plt.savefig(path)\n",
    "                plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "        \n",
    "def remap_cloud_arrival(row):\n",
    "    new_arrival = [row['start'][i] if row['is_local'][i] == 1 else row['arrival'][i] for i in range(len(row['arrival']))]\n",
    "    #new_arrival = [1 if row['is_local'] == 1 else 0 for i in range(len(row['arrival']))]\n",
    "    return new_arrival\n",
    "\n",
    "jobs_df['arrival_plot'] = jobs_df.apply(remap_cloud_arrival, axis=1)\n",
    "print(list(enumerate(jobs_df['arrival_plot'][0])))\n",
    "#print(jobs_df['is_local'][0])\n",
    "print('start times')\n",
    "print(jobs_df['start'][0])\n",
    "print(jobs_df['submission_time'][0])\n",
    "schedule_time = [jobs_df['start'][0][i] - jobs_df['submission_time'][0][i] for i in range(len(jobs_df['start'][0]))]\n",
    "print(\"pod scheduling time (seconds)\")\n",
    "print(schedule_time)\n",
    "print(\"run locally (1=local, 0=cloud)\")\n",
    "print(jobs_df['is_local'][0])\n",
    "print(\"allocated_gpus_real\")\n",
    "print(jobs_df['allocated_gpus_real'][0])\n",
    "print(\"allocated_gpus\")\n",
    "print(jobs_df['allocated_gpus'][0])\n",
    "print(jobs_df['arrival'][0])\n",
    "print(\"IDs\")\n",
    "print(jobs_df['idx'][0])\n",
    "print(\"RUNTIME\")\n",
    "print(jobs_df['runtime'][0])\n",
    "print(\"VERIFYING\")\n",
    "print(sorted(jobs_df['arrival'][0]))\n",
    "\n",
    "for j in range(len(jobs_df)):\n",
    "    cloud_time = [jobs_df['runtime'][j][i] for i in range(len(jobs_df['runtime'][j])) if jobs_df['is_local'][j][i] == 0  ]\n",
    "    print(\"cloud runtimes (seconds)\")\n",
    "    print(cloud_time)\n",
    "    onprem_time = [jobs_df['runtime'][j][i] for i in range(len(jobs_df['runtime'][j])) if jobs_df['is_local'][j][i] == 1  ]\n",
    "    print(\"onprem runtimes (seconds)\")\n",
    "    print(onprem_time)\n",
    "\n",
    "for j in range(len(jobs_df)):\n",
    "    total_job_arrival = len(jobs_df['arrival'][j])\n",
    "    total_job_submission = len(jobs_df['start'][j])\n",
    "    total_job_completion = len(jobs_df['completion_time'][j])\n",
    "    print(f'{j} {total_job_arrival} {total_job_submission} {total_job_completion}')\n",
    "gpus_per_node = 8 #TODO: Parse this value from the job\n",
    "ratio = (1, 1)\n",
    "scale = 1\n",
    "\n",
    "jobs_df.apply(generate_gantt_chart, axis=1, args=(gpus_per_node, ratio, scale, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ceeda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_starburst_log(event_number=logs):\n",
    "    log = log_jobs.retrieve_log(event_number=logs)\n",
    "    return log \n",
    "\n",
    "log_df = parse_starburst_log(event_number=logs)\n",
    "log_df\n",
    "\n",
    "loop_times = []\n",
    "interloop_times = []\n",
    "process_queue_times = []\n",
    "process_event_times = []\n",
    "queue_add_times = []\n",
    "await_times = []\n",
    "times = []\n",
    "events = []\n",
    "\n",
    "for i in range(len(log_df)):\n",
    "    log = log_df[0][i]\n",
    "    parts = log.split('||')\n",
    "    if len(parts) > 1:\n",
    "        log = parts[1]\n",
    "        \n",
    "    if log.find(\"TICK TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        if len(parts) > 8: \n",
    "            time = parts[4]\n",
    "            times.append(float(time))\n",
    "            eventtype = parts[6] + parts[7]\n",
    "            events.append(eventtype)\n",
    "            \n",
    "    if log.find(\"LOOP TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        time = parts[4]\n",
    "        loop_times.append(float(time))\n",
    "        \n",
    "    if log.find(\"INTERLOOP TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        time = parts[4]\n",
    "        interloop_times.append(float(time))\n",
    "        \n",
    "    if log.find(\"PROCESSQUEUE TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        time = parts[4]\n",
    "        process_queue_times.append(float(time))\n",
    "        \n",
    "    if log.find(\"PROCESSEVENT TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        time = parts[4]\n",
    "        process_event_times.append(float(time))\n",
    "    \n",
    "    if log.find(\"QUEUEADD TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        time = parts[4]\n",
    "        queue_add_times.append(float(time))\n",
    "        \n",
    "    if log.find(\"AWAIT TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        time = parts[4]\n",
    "        await_times.append(float(time))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=9,figsize=(12,3)) \n",
    "\n",
    "#loop_times = [loop_times[i + 1] - loop_times[i] for i in range(len(loop_times) - 1)]\n",
    "\n",
    "overflows = []\n",
    "addtimes = []\n",
    "ticktimes = []\n",
    "for i in range(len(times)):\n",
    "    time = times[i]\n",
    "    event = events[i]\n",
    "    if event == 'JobAddEvent:Job,':\n",
    "        addtimes.append(time)\n",
    "    if event == 'SchedTick,':\n",
    "        ticktimes.append(time)\n",
    "    if time > 0.6: \n",
    "        overflows.append((time, event))\n",
    "\n",
    "axs[0].set_title('All Event Times', fontsize =10)\n",
    "axs[0].hist(times)\n",
    "axs[0].set_xlabel('Time (sec)')\n",
    "axs[0].set_ylabel('Frequency')\n",
    "\n",
    "axs[1].set_title('Job Add Event Times', fontsize =10)\n",
    "axs[1].hist(addtimes)\n",
    "axs[1].set_xlabel('Time (sec)')\n",
    "axs[1].set_ylabel('Frequency')\n",
    "\n",
    "axs[2].set_title('Sched Tick Event Times', fontsize =10)\n",
    "axs[2].hist(ticktimes)\n",
    "axs[2].set_xlabel('Time (sec)')\n",
    "axs[2].set_ylabel('Frequency')\n",
    "\n",
    "axs[3].set_title('Loop Times', fontsize =10)\n",
    "axs[3].hist(loop_times)\n",
    "axs[3].set_xlabel('Time (sec)')\n",
    "axs[3].set_ylabel('Frequency')\n",
    "\n",
    "axs[4].set_title('Inter Loop Times', fontsize =10)\n",
    "axs[4].hist(interloop_times)\n",
    "axs[4].set_xlabel('Time (sec)')\n",
    "axs[4].set_ylabel('Frequency')\n",
    "\n",
    "axs[5].set_title('Process Queue Times', fontsize =10)\n",
    "axs[5].hist(process_queue_times)\n",
    "axs[5].set_xlabel('Time (sec)')\n",
    "axs[5].set_ylabel('Frequency')\n",
    "\n",
    "axs[6].set_title('Process Event Times', fontsize =10)\n",
    "axs[6].hist(process_event_times)\n",
    "axs[6].set_xlabel('Time (sec)')\n",
    "axs[6].set_ylabel('Frequency')\n",
    "\n",
    "axs[7].set_title('Queue Add Times', fontsize =10)\n",
    "axs[7].hist(queue_add_times)\n",
    "axs[7].set_xlabel('Time (sec)')\n",
    "axs[7].set_ylabel('Frequency')\n",
    "\n",
    "axs[8].set_title('Await Times', fontsize =10)\n",
    "axs[8].hist(queue_add_times)\n",
    "axs[8].set_xlabel('Time (sec)')\n",
    "axs[8].set_ylabel('Frequency')\n",
    "\n",
    "print(process_event_times)\n",
    "print(process_queue_times)\n",
    "print(loop_times)\n",
    "print(interloop_times)\n",
    "print(queue_add_times)\n",
    "print(sum(loop_times)/len(loop_times))\n",
    "\n",
    "add_count = 0 \n",
    "sched_count = 0\n",
    "for t, e in overflows: \n",
    "    if e == 'JobAddEvent:Job,':\n",
    "        add_count += 1\n",
    "    if e == 'SchedTick,':\n",
    "        sched_count += 1\n",
    "\n",
    "#print(add_count)\n",
    "#print(sched_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1933e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(jobs_df)):\n",
    "    print(i)\n",
    "    print(len(jobs_df['is_local'][i]))\n",
    "    print(sum(jobs_df['is_local'][i]))\n",
    "    print(len(jobs_df['arrival'][i]))\n",
    "    print(len(jobs_df['start'][i]))\n",
    "    print(len(jobs_df['submission_time'][i]))\n",
    "    print(len(jobs_df['runtime'][i]))\n",
    "    print(len(jobs_df['allocated_gpus_real'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310e3c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df\n",
    "#print(len(jobs_df['idx'][0]))\n",
    "'''\n",
    "print(jobs_df['is_local'][0][:-18])\n",
    "print(jobs_df['arrival'][0][:-18])\n",
    "print(jobs_df['start'][0][:-18])\n",
    "print(jobs_df['submission_time'][0][:-18])\n",
    "print(jobs_df['runtime'][0][:-18])\n",
    "print(jobs_df['allocated_gpus_real'][0][:-18])\n",
    "'''\n",
    "print(len(jobs_df['is_local'][0]))\n",
    "print(len(jobs_df['arrival'][0]))\n",
    "print(len(jobs_df['start'][0]))\n",
    "print(len(jobs_df['submission_time'][0]))\n",
    "print(len(jobs_df['runtime'][0]))\n",
    "print(len(jobs_df['allocated_gpus_real'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bbd5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jobs_df['total_cloud_cost'])\n",
    "print(jobs_df['avg_jct'])\n",
    "print(jobs_df['cluster_utilization'])\n",
    "\n",
    "jobs_df['completion_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9317035",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in jobs_df['runtime']:\n",
    "    print(i)\n",
    "    print(len(i))\n",
    "\n",
    "for i in jobs_df['arrival_mask']:\n",
    "    print(i)\n",
    "    print(len(i))\n",
    "    \n",
    "for i in jobs_df['onprem_mask']:\n",
    "    print(i)\n",
    "    print(len(i))\n",
    "    \n",
    "for i in jobs_df['num_gpus']:\n",
    "    print(i)\n",
    "    print(len(i))\n",
    "    \n",
    "for i in jobs_df['start']:\n",
    "    print(i)\n",
    "    print(len(i))\n",
    "    \n",
    "for i in jobs_df['instance_type']:\n",
    "    print(i)\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9c7931",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def wait_time_histograms(row):\n",
    "    \"\"\"Plots waiting time for onprem, cloud, and cloud clipped\"\"\"\n",
    "    #import pdb; pdb.set_trace()\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(12,3)) \n",
    "    \n",
    "    axs[0].set_title(\"ONPREM \" + \"wait \" + str(row['wait_time']) +  \" arr \" + str(row['arrival_rate']), fontsize=10)\n",
    "    axs[0].hist(row['onprem_wait'])\n",
    "    if row['onprem_wait'] != []:\n",
    "        average = sum(row['onprem_wait'])/len(row['onprem_wait'])\n",
    "        axs[0].axvline(average, color='r', linewidth=0.5)\n",
    "\n",
    "    axs[1].set_title(\"CLOUD \" + \"wait \" + str(row['wait_time']) +  \" arr \" + str(row['arrival_rate']), fontsize=10)\n",
    "    axs[1].hist(row['cloud_wait'])\n",
    "      \n",
    "    axs[2].set_title(\"CLOUD UNCLIPPED \" + \"wait \" + str(row['wait_time']) +  \" arr \" + str(row['arrival_rate']), fontsize=10)\n",
    "    axs[2].hist(row['cloud_wait_unclipped'])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "jobs_df.apply(wait_time_histograms, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a0496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df\n",
    "jobs_df['allocated_gpus_real'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad96d33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_uuid = list(jobs_df['idx'])[0]\n",
    "job_runtimes = list(jobs_df['runtime'])[0]\n",
    "job_gpus = list(jobs_df['num_gpus'])[0]\n",
    "job_gpus = [int(i) for i in job_gpus]\n",
    "print(job_uuid)\n",
    "print(job_runtimes)\n",
    "print(job_gpus)\n",
    "print(sum(job_runtimes)/len(job_runtimes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2baf853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def set_plotting_setting(ax):\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    ax.grid(True, which='both')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(True)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    #ax.tick_params(bottom=False, left=False)\n",
    "    ax.tick_params(bottom=True, left=False)\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "label_dict = {\n",
    "    'avg_jct': 'Avg. JCT (sec)',\n",
    "    'cost_mult': '% Cost Savings\\nover No Wait',\n",
    "    'cost_diff': 'Cost Savings\\nover No Wait',\n",
    "    'cluster_size': 'Cluster Size (# Nodes)',\n",
    "    'norm_system_utilization': 'System Utilization',\n",
    "    'system_utilization': 'System Utilization',\n",
    "    'cluster_utilization': 'Cluster Utilization',\n",
    "    'total_cloud_cost': 'Cloud Cost',\n",
    "    'arrival_rate': 'Arrival Rate',\n",
    "    'uniform_arrival': 'Uniform Inter Arrival Time',\n",
    "}\n",
    "\n",
    "legend_dict = {\n",
    "    'constant': 'Constant',\n",
    "    'linear_runtime': 'Runtime',\n",
    "    'linear_cost': 'Cost',\n",
    "    'zero': 'No Wait',\n",
    "    'linear_runtime_filter_cpu': 'Runtime-Preempt-CPU'\n",
    "}\n",
    "\n",
    "def simulator_plotting_fn(df, \n",
    "                          x_axis: str,\n",
    "                          y_axis: list = ['cost_mult', 'avg_jct'],\n",
    "                          df_filter: dict = {},\n",
    "                          baseline_filter: dict={'waiting_policy': 'zero',},\n",
    "                          groupby_values=['waiting_policy', 'waiting_factor'],\n",
    "                          normalize_x_axis=False,\n",
    "                          fig_ratio=(5, 3.5),\n",
    "                          intermediate_df={\"baseline_df\": False, \"merged_df\": False, \"metrics_df\": False, \"groups_df\": False},\n",
    "                          return_df=False):\n",
    "    \"\"\"\n",
    "    Takes a baseline filter to plot metrics of different policies against\n",
    "    \n",
    "    Creates a product of the baseline filter against each existing run\n",
    "        - Values ending with _y are values from the baseline\n",
    "    \n",
    "    Takes a groupby value to compress to set of useful pairs\n",
    "    \"\"\"\n",
    "    \n",
    "    def cost_multiplier(row):\n",
    "        baseline_cost = row['total_cloud_cost_y']\n",
    "        cost = row['total_cloud_cost_x']\n",
    "        if baseline_cost == 0 and cost==0:\n",
    "            return 0\n",
    "        #elif baseline_cost <=10000:\n",
    "            # Small cloud cost for No wait\n",
    "            # Savings over small cloud cost is negligible for organizations.\n",
    "        #    return 0\n",
    "        elif baseline_cost == 0 and cost>0:\n",
    "            return 100\n",
    "        return 100* (1 - (cost/baseline_cost))\n",
    "    \n",
    "    def cost_difference(row):\n",
    "        baseline_cost = row['total_cloud_cost_y']\n",
    "        cost = row['total_cloud_cost_x']\n",
    "        return baseline_cost - cost\n",
    "    \n",
    "    \n",
    "    if isinstance(y_axis, str):\n",
    "        y_axis = [y_axis]\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=len(y_axis), figsize=(fig_ratio[0]*len(y_axis), fig_ratio[1]))\n",
    "    \n",
    "    if len(y_axis) == 1: \n",
    "        if not isinstance(axs, list):\n",
    "            axs = [axs]\n",
    "    #print(axs)\n",
    "    '''\n",
    "    for k,v in df_filter.items():\n",
    "        if isinstance(v, list):\n",
    "            df = df[df[k]==v]\n",
    "    '''\n",
    "\n",
    "    for k,v in df_filter.items():        \n",
    "        mask = df[k].apply(lambda x: x == v)\n",
    "        if isinstance(v, list):\n",
    "            df = df[mask]\n",
    "            \n",
    "    #TODO: get_default = df after mask \n",
    "    baseline_df = df\n",
    "    if intermediate_df['baseline_df']:\n",
    "        print(\"baseline\")\n",
    "        display(baseline_df)\n",
    "    \n",
    "    for k,v in baseline_filter.items():\n",
    "        assert not isinstance(v, list)\n",
    "        baseline_df = baseline_df[baseline_df[k]==v]\n",
    "        #df = df[df[k]!=v]\n",
    "         \n",
    "    # Merge to check for baseline\n",
    "    diff_df = pd.merge(df, baseline_df, left_on=x_axis,right_on=x_axis)\n",
    "    \n",
    "    #TODO: join_baseline = diff_df after merge\n",
    "    if intermediate_df['merged_df']:\n",
    "        print(\"merged\")\n",
    "        display(diff_df)\n",
    "    \n",
    "    if normalize_x_axis:\n",
    "        if x_axis == 'cluster_size':\n",
    "            # Hardcoded in Philly trace, precomputed ahead of time\n",
    "            if df['dataset'].iloc[0] == 'philly':\n",
    "                total_job_volume = 1155998.77277777\n",
    "                job_makespan = 2559.3205555555555\n",
    "            elif df['dataset'].iloc[0] == 'helios':\n",
    "                total_job_volume = 1853756.1241666232\n",
    "                job_makespan = 4651.911388888889\n",
    "            diff_df['norm_system_utilization'] = total_job_volume/(job_makespan*diff_df['cluster_size']*df['gpus_per_node'].iloc[0])\n",
    "            x_axis = 'norm_system_utilization'\n",
    "        elif x_axis == 'arrival_rate' or x_axis == 'uniform_arrival':\n",
    "            # Volume rate => runtime must be in either hours or seconds \n",
    "            '''\n",
    "            Verification: \n",
    "            - Arrival_Rate = VERIFIED ~ error \n",
    "            - Num_gpus = Verified\n",
    "            - Runtime = Verified \n",
    "            '''\n",
    "            #arrival_rate = diff_df['arrival_rate'] # Jobs per second \n",
    "            arrival_rate = 1/df['uniform_arrival'] # uniform_arrival => time between jobs in seconds \n",
    "            #avg_job_volume_rate = arrival_rate * np.mean(df['num_gpus'].iloc[0]* df['runtime'].iloc[0])\n",
    "            df['volume'] = df['num_gpus'] * df['runtime']\n",
    "            #df['avg_job_volume_rate'] = sum(df['volume'])/len(df['volume']) * arrival_rate\n",
    "            df['avg_volume'] = df['volume'].apply(lambda arr: np.mean(arr))\n",
    "            df['avg_job_volume_rate'] = df['avg_volume'] * arrival_rate\n",
    "            #import pdb; pdb.set_trace()\n",
    "            #avg_job_volume_rate = arrival_rate * ([df['num_gpus'] * df['runtime'][i] for i in range(len(df['runtime']))])/len(df['runtime'])\n",
    "            #df['avg_job_volume_rate'] = avg_job_volume_rate\n",
    "            df['verify_mean_runtime'] = np.mean(df['num_gpus'].iloc[0]* df['runtime'].iloc[0])\n",
    "            df['verify_cluster_nodes'] = (df['cluster_size'].iloc[0]*df['gpus_per_node'].iloc[0])\n",
    "            #print(avg_job_volume_rate)\n",
    "            #print(df['cluster_size'].iloc[0])\n",
    "            #print(df['gpus_per_node'].iloc[0])\n",
    "            #print(df['cluster_size'].iloc[0]*df['gpus_per_node'].iloc[0])\n",
    "            #diff_df['norm_system_utilization'] = avg_job_volume_rate/(df['cluster_size'].iloc[0]*df['gpus_per_node'].iloc[0])\n",
    "            #df['cluster_size'] = 1 #TODO: Remove this value\n",
    "            diff_df['norm_system_utilization'] = df['avg_job_volume_rate']/(df['cluster_size']*df['gpus_per_node'])\n",
    "            diff_df['norm_system_utilization'] = pd.to_numeric(diff_df['norm_system_utilization'], errors='coerce')\n",
    "            diff_df['norm_system_utilization'] = diff_df['norm_system_utilization'].round(4)\n",
    "            x_axis = 'norm_system_utilization'\n",
    "            diff_df = diff_df.sort_values('norm_system_utilization')\n",
    "    \n",
    "    \n",
    "    diff_df['cost_mult'] = diff_df.apply(cost_multiplier, axis=1)\n",
    "    diff_df['cost_diff'] = diff_df.apply(cost_difference, axis=1)\n",
    "    \n",
    "    if intermediate_df['metrics_df']:\n",
    "        print(\"merged metrics\")\n",
    "        display(diff_df)\n",
    "        \n",
    "    #TODO: get_baseline = df after normalizing axis\n",
    "    if groupby_values: \n",
    "        groupby_values = [f'{g}_x' for g in groupby_values]\n",
    "    mod_y_axis = [f'{y}_x' if y!='cost_mult' and y!='cost_diff' else y for y in y_axis]\n",
    "    \n",
    "    markers = itertools.cycle(('v', '^','.', 'o', '*',',', '+',)) \n",
    "    groups = diff_df.groupby(groupby_values)\n",
    "    \n",
    "    if intermediate_df['groups_df']:\n",
    "        for name, group in groups:\n",
    "            print(f\"Group: {name}\")\n",
    "            #'cost_mult', 'cost_diff', 'wait_time_x', 'wait_time_y' , 'wait_time_x', 'wait_time_y'\n",
    "            group = group[['cost_mult', 'cost_diff', 'wait_time_x', 'wait_time_y', 'uniform_arrival_sweep_x', 'uniform_arrival_sweep_y', 'total_cloud_cost_x', 'total_cloud_cost_y']]\n",
    "            \n",
    "            display(group)\n",
    "        \n",
    "    for idx, (label, grp) in enumerate(groups):\n",
    "        marker = next(markers)\n",
    "#         if 'waiting_policy' in groupby_values[0]:\n",
    "#             label = [legend_dict[label[0]]] + list(label[1:])\n",
    "#             print(label)\n",
    "        for ax_idx, ax in enumerate(axs):           \n",
    "            grp.plot(x = x_axis, y = mod_y_axis[ax_idx],ylabel=label_dict[y_axis[ax_idx]], \\\n",
    "                     xlabel=label_dict[x_axis], marker=marker, ax = ax, label = label, legend=None)\n",
    "    \n",
    "    if return_df: \n",
    "        return diff_df \n",
    "    for ax in axs:\n",
    "        set_plotting_setting(ax)\n",
    "    #axs[1].set_xlim(right=36, left=20)\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(lines, labels, ncol=len(labels), \\\n",
    "               bbox_to_anchor=(0, 0.92, 1, 0.2),loc='upper center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "'''\n",
    "# TODO: Add spec to increase plot size\n",
    "# TODO: pull the first distribution value\n",
    "# TODO: retrieve sweep value based on the log value \n",
    "# TODO: Clean up ipynb to avoid overwriting jobs_df values\n",
    "'''\n",
    "def generate_system_util_plots(event_number=None, scale=4):\n",
    "    events_dict, sweep_dict = log_jobs.retrieve_events_df(event_number=logs, avoid_congestion=False, only_dict=True)\n",
    "    sweep_dict = OrderedDict(sweep_dict['varying_values'])\n",
    "    \n",
    "    # Make sure baseline filter is one row in dataframe\n",
    "    # Make sure the baseline filter subtracts each corresponding arrival_rate\n",
    "    for sweep_dim in sweep_dict: \n",
    "        for sweep_value in sweep_dict[sweep_dim]:\n",
    "            print(sweep_dim + \"_sweep\")\n",
    "            print(sweep_value)\n",
    "            df = simulator_plotting_fn(jobs_df, \\\n",
    "                                       #x_axis='arrival_rate', \\\n",
    "                                       x_axis='uniform_arrival', \\\n",
    "                                       y_axis=['avg_jct', 'cluster_utilization', 'total_cloud_cost', 'cost_mult', 'cost_diff'], \\\n",
    "                                       baseline_filter= {'wait_time': 2}, \\\n",
    "                                       groupby_values=['wait_time'], \\\n",
    "                                       #'uniform_submission_sweep', \n",
    "                                       #'arrival_rate': 'Arrival Rate',\n",
    "                                       #'uniform_arrival_sweep',\n",
    "                                       normalize_x_axis=True, \\\n",
    "                                       intermediate_df={\"baseline_df\": False, \"merged_df\": True, \"metrics_df\": False, \"groups_df\": True}, \\\n",
    "                                       fig_ratio=(5*scale, 3.5*scale), \\\n",
    "                                       return_df=False)\n",
    "            display(df)\n",
    "            break \n",
    "        break\n",
    "        \n",
    "generate_system_util_plots(event_number=logs, scale=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
