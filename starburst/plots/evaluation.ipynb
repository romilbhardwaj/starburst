{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f2329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "import sys\n",
    "import os\n",
    "path = os.getcwd()\n",
    "path += '/../../'\n",
    "sys.path.append(path)\n",
    "\n",
    "import starburst\n",
    "from starburst import utils\n",
    "import log_jobs\n",
    "import submit_jobs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import time \n",
    "import copy \n",
    "from collections import OrderedDict \n",
    "import math\n",
    "import heapq\n",
    "import re\n",
    "from IPython.display import display\n",
    "import itertools\n",
    "import pickle\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26235ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "VMS = {\n",
    "    \"05_01_2023\": 1682925843,\n",
    "    \"05_02_2023\": 1683099273,\n",
    "    \"05_03_2023\": 1683132152,\n",
    "    \"05_03_2023_2\": 1683173965,\n",
    "    \"05_04_2023_1\": 1683184792, \n",
    "    \"05_04_2023_2\": 1683196845,\n",
    "    \"05_04_2023_3\": 1683259533,\n",
    "    \"05_05_2023_4\": 1683343491,\n",
    "    \"05_06_2023_4\": 1683410859,\n",
    "    \"05_06_2023_5\": 1683418719,\n",
    "    \"05_06_2023_6\": 1683442154,\n",
    "    \"05_06_2023_7\": 1683452077,\n",
    "    \"05_07_2023_1\": 1683486242,\n",
    "    \"05_07_2023_2\": 1683489564,\n",
    "    \"05_07_2023_3\": 1683496107,\n",
    "    \"05_07_2023_4\": 1683497538,\n",
    "    \"1683498468\": 1683497538, \n",
    "    \"1683498857\": 1683498857,\n",
    "    \"1683499283\": 1683499283,\n",
    "    \"1683528723\": 1683528723, # Fixed JCT values\n",
    "    \"1683534589\": 1683534589, # Large sweep with greater arrival rates\n",
    "    \"1683607638\": 1683607638, # Modified arrival rate values to match simulator\n",
    "    \"1683625643\": 1683625643, # Policy waits until cluster state is updated\n",
    "    \"1683627780\": 1683627780, # Policy waits until cluster state and running pods are updated\n",
    "    \"1683680278\": 1683680278, # Sweep with uniform wait (4 sec) and constant timeout (3 sec)\n",
    "    \"1683705558\": 1683705558, # 30 second inter arrival time and 5 second job time\n",
    "    \"1683707012\": 1683707012, # 30 second inter arrival time and 5 second job time (ROUND 2)\n",
    "    \"1683757260\": 1683757260, # 30 second inter arrival time and 5 second job time (ROUND 3)\n",
    "    \"1683758384\": 1683758384, # 5 second inter arrival time and 5 second job time (ROUND 3)\n",
    "    \"1683759834\": 1683759834, # 5 second arrival 5 second job 1 second wait\n",
    "    \"1683939895\": 1683939895, \n",
    "    \"1683959890\": 1683959890, # Waiting until all jobs submitted\n",
    "    \"1683961793\": 1683961793, # Waiting until jobs submitted and relogging with poroper config second time\n",
    "    \"1683999940\": 1683999940, # Fixed unscheduled gpu pod error\n",
    "    \"1684025542\": 1684025542, # Resolved last job logging error\n",
    "    \"1684027483\": 1684027483, # Decreased interarrival times\n",
    "    \"1684034550\": 1684034550, # Replace gpu index with uuid\n",
    "    \"1684035873\": 1684035873, # Varying interarrival rate of gpu jobs\n",
    "    \"1684038713\": 1684038713, # Included GPUS per node value to sweep and fixed values [PLOTS WORK]\n",
    "    \"1684107011\": 1684107011, # Run with varying timeout values to test cost saving plots\n",
    "    \"1684127501\": 1684127501, # Higher range of arrival rates (from 3 arrival rates to 5 rates) \n",
    "    \"1684211347\": 1684211347, # Use loop_time instead of curr_time when comparing job wait_time\n",
    "    \"1684211782\": 1684211782, # Doesn't check if job on queue is less than timeout, when submitting on prem\n",
    "    \"1684214027\": 1684214027, # Dropped schedule tick from 1 to 0.1\n",
    "    \"1684219829\": 1684219829, # Fixed checking cluster state if job completed -- set to 0.5 sched tick\n",
    "    \"1684222781\": 1684222781, # Interarrival rate to 3 seconds \n",
    "    \"1684223508\": 1684223508, # Rerun 1684107011 log w/ 3 inter arrival and 10 wait\n",
    "    \"1684279856\": 1684279856, # Checks if previous job submitted has been scheduled to avoid onprem congestion\n",
    "    \"1684282049\": 1684282049, # Removes the 50 length limit from http_info +  Handles case when next job not found in the cluster yet -- moves onto next job in the meantime\n",
    "    \"1684282536\": 1684282536, # Removed 50 limit for both check cluster state and get if last job scheduled\n",
    "    \"1684283565\": 1684283565, # Handling tuple jobname and jobstatus error\n",
    "    \"1684295134\": 1684295134, # Read the logs\n",
    "    \"1684300887\": 1684300887, # Added loop time and dropped schedule tick event\n",
    "    \"1684301139\": 1684301139, # Removed Job Add Event\n",
    "    \"1684301369\": 1684301369, # Removed everything except process_queue\n",
    "    \"1684301655\": 1684301655, # No 0.5 pause within the event loop\n",
    "    \"1684307219\": 1684307219, # New VM\n",
    "    \"1684311915\": 1684311915, # Debugged new VM\n",
    "    \"1684312326\": 1684312326, # Loop time\n",
    "    \"1684312971\": 1684312971, # Process Queue and Event Queue Times\n",
    "    \"1684313238\": 1684313238, # Log time\n",
    "    \"1684313922\": 1684313922, # Queue Add Time\n",
    "    \"1684366876\": 1684366876, # Fixed interloop time to 1 second \n",
    "    \"1684368494\": 1684368494, # Fixed loop time between loops\n",
    "    \"1684369123\": 1684369123, # Rerun because jobs corrupted\n",
    "    \"1684371614\": 1684371614, # Tried to ensure all previous running jobs are deleted\n",
    "    \"1684380753\": 1684380753, # Sweep different wait time values\n",
    "    \"1684382045\": 1684382045, # Multi Node 8 GPU \n",
    "    \"1684397749\": 1684397749, # Removed regex for scheudled_node event\n",
    "    \"1684433340\": 1684433340, # Modified onprem submission conditional\n",
    "    \"1684445674\": 1684445674, # Event tracked in events.log\n",
    "    \"1684449505\": 1684449505, # Testing new gpu_index parsing code -- waiting till run finishes \n",
    "    \"1684452105\": 1684452105, # 60 jobs modified policy all onprem\n",
    "    \"1684452497\": 1684452497, # 360 jobs on prem\n",
    "    \"1684470801\": 1684470801, # New terminating conditions\n",
    "    \"1684471163\": 1684471163, # Added end variable loop\n",
    "    \"1684471393\": 1684471393, # Cloud spill new termination\n",
    "    \"1684471749\": 1684471749, # Large spillover \n",
    "    \"1684473449\": 1684473449, # Check cloud spill over policy only \n",
    "    \"1684475422\": 1684475422, # Cloud only with 4 gpus\n",
    "    \"1684477231\": 1684477231, # Cloud only with 4 gpus without setup script bug\n",
    "    \"1684478946\": 1684478946, # Spill over from cloud to onprem 4 nodes each -- constant wait 10 seconds\n",
    "    \"1684480072\": 1684480072, # Constant wait 30 seconds -- 4 onprem, 4 cloud, 60 second batch\n",
    "    \"1684480621\": 1684480621, # Constant wait 60 seconds -- 4 onprem, 4 cloud, 60 second batch \n",
    "    \"1684486650\": 1684486650, # Constant wait 5 seconds -- 4 onprem, 4 cloud, 60 second batch\n",
    "    \"1684487285\": 1684487285, # Wait 0, 1, 2 seocnds -- 4 onprem, 4 cloud, 60 second batch\n",
    "    \"1684489189\": 1684489189, # Wait 2, 3, 5, 10 seconds -- 30 second mean duration\n",
    "    \"1684532430\": 1684532430, # Sweep over different poicies \n",
    "    \"1684534781\": 1684534781, # Philly trace sweep \n",
    "    \"1684536405\": 1684536405, # Reduced uniform arrival \n",
    "    \"1684537269\": 1684537269, # 30 second average job duration\n",
    "    \"1684538298\": 1684538298, # Modified compute wait threshold\n",
    "    \"1684543740\": 1684543740, # Integrating chakra \n",
    "    \"1684545298\": 1684545298, # New node name\n",
    "    \"1684548233\": 1684548233, # Updated chakra and sweep of final jobs (starburst', 'compute_optimal', 'constant_optimal', 'constant')\n",
    "    \"1684609979\": 1684609979, # Working chakra, mnist with starburst\n",
    "    \"1684611837\": 1684611837, # Pending 4 gpu job error\n",
    "    \"1684621271\": 1684621271, # Removed cloud cluster\n",
    "    \"1684630465\": 1684630465, # Removed cloud cluster w/ modified logs\n",
    "    \"1684720040\": 2,\n",
    "    \"1684726518\": 2,\n",
    "    \"1684704725\": 1, # Real sweep of training jobs from Ryan\n",
    "    \"1684726518\": 2, \n",
    "    \"1684727264\": 2, \n",
    "    \"1684731034\": 2, # More jobs ~ 15 minutes each\n",
    "    \"1684755479\": 2, # overloaded sys util - 20 jobs/sec\n",
    "    \"1684754864\": 1, # high sys util - arrival 12 jobs/sec\n",
    "    \"1684795422\": 2, # overloaded sys util - 32 jobs/sec\n",
    "    \"1684795437\": 1, # high sys util - arrival 24 jobs/sec\n",
    "    \"1684804876\": 2, # overloaded with continous arrival time logs\n",
    "    \"1684804861\": 1, # high sys util with continous arrival time logs,\n",
    "    \"1684807867\": 2, # overloaded \n",
    "    \"1684808264\": 1, # high load\n",
    "    \"1684814611\": 2, # overloaded\n",
    "    \"1684814629\": 1, # high sys\n",
    "    \"1684825502\": 1, # high sys\n",
    "    \"1684842795\": 2, # Final experiment high sys util\n",
    "    \"1684842093\": 1, # Final experiment overloaded sys util # Poster data\n",
    "    \"1686798842\": 1, # CPU Sleep jobs \n",
    "    \"1687837800\": 1, # CPU Sleep jobs w/ simulated cloud logging\n",
    "}\n",
    "# TODO: Support both GPU and CPU (e.g. \"workload_type\")\n",
    "logs =  \"1687837800\"#\"1686798842\"#\"1684842093\"#\"1684842795\"#\"1686798842\"# \"1684842093\"#\"1686798842\" #\"1684842795\" ##\"1684842795\" #\"1684755479\" #\"1684754864\" #\"1684731034\" #LOGS[\"1684630465\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b8d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check for ground truth  -- Compare the datapoints from parse_job_df to ensure there are no missing jobs \n",
    "\n",
    "def parse_job_df(cluster_event_df=None, submission_df=None, sweep_df=None, avoid_congestion=True, columns=None, run_id=None, cloud_log_list=None):\n",
    "    '''\n",
    "    Parse onprem jobs first\n",
    "    '''\n",
    "    hyperparameters = None\n",
    "    if 'hyperparameters' in submission_df: \n",
    "        hyperparameters = submission_df['hyperparameters']\n",
    "    \n",
    "    onprem_event_df = cluster_event_df['onprem']\n",
    "    cloud_event_df = cluster_event_df['cloud']\n",
    "    \n",
    "    job_names = {}\n",
    "    jobs = {}\n",
    "    for col in columns: \n",
    "        jobs[col] = []\n",
    "\n",
    "    all_nodes = set()\n",
    "    nodes = {}\n",
    "    node_counter = 0\n",
    "    types = ['onprem', 'cloud']\n",
    "    nodes_indices = {}\n",
    "    \n",
    "    #import pdb; pdb.set_trace()\n",
    "    print(cloud_log_list)\n",
    "    \n",
    "    for cluster_type in types: \n",
    "        event_df = cluster_event_df[cluster_type]\n",
    "        try:\n",
    "            job_times = {}\n",
    "            pod_times = {}\n",
    "            if cluster_type == 'cloud':\n",
    "                for job in cloud_log_list[1:-1]:\n",
    "                    match = re.search(r\"Cloud Job \\|\\| job id (\\S+) \\| job name (\\S+) \\| estimated cloud start time (\\S+) \\| estimated job duration (\\S+) \\| submission time (\\S+) \\| gpus (\\S+) \\| cpus (\\S+)\", job)\n",
    "                    match = match.groups()\n",
    "                    if match:\n",
    "                        job_id = int(match[0])\n",
    "                        job_name = str(match[1])\n",
    "                        submit = float(match[2])\n",
    "                        duration = float(match[3])\n",
    "                        arrival = float(match[4])\n",
    "                        gpu = int(match[5])\n",
    "                        cpu = int(match[6])\n",
    "                        end = submit + 2 + duration \n",
    "                        \n",
    "                        times = {\"arrival\": arrival,\"submit\": submit,\"pod_start\": submit + 2, \"job_end\": end, \"gpu\": gpu, \"cpu\":cpu}\n",
    "                        print(f'matched time {times}')\n",
    "\n",
    "                        missing = False\n",
    "                        for v, k in times.items(): \n",
    "                            if not k: \n",
    "                                print(f'Missing {v} {k}')\n",
    "                                missing = True\n",
    "                        print(f'value {times}')\n",
    "                    \n",
    "                        pod_times[job_id] = times\n",
    "                intervals = pod_times\n",
    "                nodes[\"cloud\"] = node_counter\n",
    "                #print(pod_times)\n",
    "                print(f'Cloud Jobs {len(intervals)}')       \n",
    "            else:   \n",
    "                cluster = event_df\n",
    "                start_times = cluster['container_start_times']\n",
    "                creation_times = cluster['job_creation_times']\n",
    "                completion_times = cluster['job_completion_times']\n",
    "                # TODO: Verify node names works as intended\n",
    "                pod_nodes = cluster['node_name']\n",
    "                job_pods = cluster['job_pods']\n",
    "                pod_jobs = {value: key for key, value in job_pods.items()}\n",
    "                node_instances = cluster['node_instances']\n",
    "\n",
    "                job_start_times = {}\n",
    "                job_end_times = {}\n",
    "                pod_start_times = {}\n",
    "\n",
    "                for pod in start_times:\n",
    "                    pod_name = pod\n",
    "                    pod_start_time = start_times[pod]\n",
    "                    pod_start_times[pod_name] = pod_start_time   \n",
    "\n",
    "                for job in creation_times:\n",
    "                    job_name = job\n",
    "                    job_start_time = creation_times[job]\n",
    "                    job_start_times[job_name] = job_start_time\n",
    "\n",
    "                for job in completion_times:\n",
    "                    job_name = job\n",
    "                    job_end_time = completion_times[job]\n",
    "                    job_end_times[job_name] = job_end_time\n",
    "                       \n",
    "                for pod in pod_nodes: \n",
    "                    all_nodes.add(pod_nodes[pod])\n",
    "\n",
    "                for job in job_start_times:\n",
    "                    if job in job_end_times:\n",
    "                        job_times[job] = [job_start_times[job], job_end_times[job]]\n",
    "                    \n",
    "                    job_name = job\n",
    "                    if job_name in {'job-87', 'job-85'}: \n",
    "                            if job_name in job_start_times and job_name not in job_end_times: \n",
    "                                #1684842795\n",
    "                                missing_times = {\n",
    "                                    'job-87': 7897,\n",
    "                                    'job-85': 8999\n",
    "\n",
    "                                }\n",
    "                                job_end_times[job_name] = job_start_times[job_name] + missing_times[job_name]\n",
    "\n",
    "                for pod in pod_start_times:\n",
    "                    if pod in pod_jobs:\n",
    "                        job = pod_jobs[pod]\n",
    "                        if job not in job_end_times:\n",
    "                            print(\"MISSING JOB \" + str(job))\n",
    "                        job_id = re.findall(r'\\d+', job)[0]\n",
    "                            \n",
    "                        sub_time = submission_df[job_id]['scheduler_submit_time']\n",
    "                        if job not in job_end_times: \n",
    "                            job_end_times[job] = sub_time + 100000\n",
    "                            print(\"MISSING JOB \" + str(job))\n",
    "                            \n",
    "                        pod_times[job] = [sub_time, job_end_times[job]]\n",
    "                        #import pdb; pdb.set_trace()\n",
    "\n",
    "                        times = {\"arrival\": submission_df[job_id]['scheduler_submit_time'], \\\n",
    "                                 # Submit is also job start time\n",
    "                                 \"submit\": job_start_times[job], \\\n",
    "                                 \"pod_start\": pod_start_times[pod], \\\n",
    "                                 \"job_end\": job_end_times[job], \\\n",
    "                                }\n",
    "                        print(f'matched time {times}')\n",
    "                        missing = False\n",
    "                        for v, k in times.items(): \n",
    "                            if not k: \n",
    "                                print(f'Missing {v} {k}')\n",
    "                                missing = True\n",
    "                                #continue\n",
    "                        #if not missing:\n",
    "                        print(f'value {times}')\n",
    "                        if not times['job_end']:\n",
    "                            times['job_end'] = times['submit'] + 1000000\n",
    "                            \n",
    "                        if job_id in {'87', '85'}: \n",
    "                            missing_runtime = times['job_end'] - times['pod_start']\n",
    "                            print(f'MISSING RUNTIME {job_id} {missing_runtime}')\n",
    "                        pod_times[job] = times\n",
    "                        #else: \n",
    "                            #print(\"MISSING JOB \" + str(job))\n",
    "\n",
    "                # TODO: Possible cause of error \n",
    "                for n in all_nodes:\n",
    "                    nodes[n] = node_counter\n",
    "                    node_counter += 1\n",
    "\n",
    "                intervals = pod_times\n",
    "                print(f'Onprem Jobs {len(intervals)}')\n",
    "                \n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            print(f'matched time {times}')\n",
    "            trace = traceback.format_exc()\n",
    "            print(trace)\n",
    "\n",
    "        gpu_indices = {}\n",
    "        gpu_num = 0\n",
    "        gpu_nums = {}\n",
    "        gpu_node = {} #mapping from gpu_uuid to node_name\n",
    "        node_gpus = {} #mapping from node_name to gpu_uuid to int [0, 7]\n",
    "        print(f'interval {intervals}')\n",
    "        for i, (key, value) in enumerate(intervals.items()):\n",
    "            try:\n",
    "                print(f'{cluster_type} value {value}')\n",
    "                if cluster_type == 'cloud':\n",
    "                    #print(key)\n",
    "                    job_id = str(key)\n",
    "                else:\n",
    "                    job_id = re.findall(r'\\d+', key)[0] #e.g. \"sleep-26-100444\"\n",
    "                job_names[i] = key\n",
    "                jobs['idx'].append(int(job_id))\n",
    "                jobs['runtime'].append(value['job_end']-value['pod_start'])\n",
    "                jobs['start'].append(value['pod_start'])\n",
    "                jobs['arrival'].append(value['arrival'])\n",
    "                jobs['submission_time'].append(value['submit'])\n",
    "                #print(f'{cluster_type} value {value}')\n",
    "                \n",
    "                if cluster_type == 'cloud':\n",
    "                    #print(value)\n",
    "                    jobs['num_gpus'].append(value['gpu'])\n",
    "                    #TODO: Verify cpu value for cloud jobs\n",
    "                    jobs['cpus'].append(value['cpu'])\n",
    "                else:\n",
    "                    jobs['num_gpus'].append(submission_df[job_id]['workload']['gpu'])\n",
    "                    jobs['cpus'].append(submission_df[job_id]['workload']['cpu'])\n",
    "\n",
    "                # TODO: Cleanup\n",
    "                if avoid_congestion:\n",
    "                    submit_time = cluster['job_creation_times'][key] #Job start time\n",
    "                else:\n",
    "                    submit_time = submission_df[job_id]['scheduler_submit_time'] #Job submission time\n",
    "                \n",
    "                if not submit_time:\n",
    "                    jobs['wait_times'].append(0)\n",
    "                else:\n",
    "                    jobs['wait_times'].append(value['pod_start']-value['arrival'])\n",
    "\n",
    "                if cluster_type == \"cloud\":\n",
    "                    jobs['is_local'].append(0)\n",
    "                else:\n",
    "                    jobs['is_local'].append(1)\n",
    "                \n",
    "                #if cluster_type == 'cloud':\n",
    "                \n",
    "                if cluster_type == 'cloud':\n",
    "                    jobs['instance_type'].append(\"unknown\")\n",
    "                    jobs['node'].append(\"cloud\")\n",
    "                    jobs['allocated_gpus'].append({})\n",
    "                    jobs['node_index'].append(len(all_nodes) + 1)\n",
    "                    jobs['allocated_gpus_real'].append({len(all_nodes): [i for i in range(value['gpu'])]})\n",
    "                    #break\n",
    "                    continue\n",
    "                \n",
    "                if job_pods[key] not in pod_nodes:\n",
    "                    jobs['instance_type'].append(\"unknown\")\n",
    "                    jobs['allocated_gpus'].append({})\n",
    "                    jobs['node_index'].append(None)\n",
    "                    jobs['allocated_gpus_real'].append({1: []})\n",
    "                    break\n",
    "                \n",
    "                if job_pods[key] in pod_nodes:\n",
    "                    jobs['instance_type'].append(node_instances[pod_nodes[job_pods[key]]])\n",
    "                else:\n",
    "                    jobs['instance_type'].append(\"unknown\")\n",
    "\n",
    "                if job_pods[key] in pod_nodes:\n",
    "                    jobs['allocated_gpus'].append({nodes[pod_nodes[job_pods[key]]]: []})\n",
    "                    jobs['node_index'].append(nodes[pod_nodes[job_pods[key]]])\n",
    "                else:\n",
    "                    jobs['allocated_gpus'].append({})\n",
    "                    jobs['node_index'].append(None)\n",
    "                \n",
    "                if job_pods[key] in pod_nodes:\n",
    "                    jobs['node'].append(pod_nodes[job_pods[key]])\n",
    "                else:\n",
    "                    jobs['node'].append(\"unknown\")\n",
    "            \n",
    "                if 'gpu_index' in cluster:\n",
    "                    gpu_index = cluster['gpu_index'][job_pods[key]]\n",
    "                    gpu_pod = job_pods[key]\n",
    "                    gpu_index = gpu_index.partition(\"||\")[0]\n",
    "                    gpu_index = gpu_index.split(\"\\n\")\n",
    "                    \n",
    "                    for index in gpu_index:\n",
    "                        if index != \"\":\n",
    "                            gpu_node[index] = pod_nodes[gpu_pod]\n",
    "                            if pod_nodes[gpu_pod] not in node_gpus:\n",
    "                                node_gpus[pod_nodes[gpu_pod]] = {}\n",
    "                            if index not in node_gpus[pod_nodes[gpu_pod]]:\n",
    "                                node_gpus[pod_nodes[gpu_pod]][index] = len(node_gpus[pod_nodes[gpu_pod]])\n",
    "\n",
    "                        if index != \"\" and index not in gpu_indices:\n",
    "                            # TODO: Clean up later\n",
    "                            gpu_indices[index] = gpu_num\n",
    "                            gpu_num += 1\n",
    "                    gpu_index = [node_gpus[pod_nodes[gpu_pod]][index] for index in gpu_index if index]\n",
    "                    jobs['allocated_gpus_real'].append({nodes[pod_nodes[job_pods[key]]]: gpu_index})\n",
    "                else:\n",
    "                    jobs['allocated_gpus_real'].append({nodes[pod_nodes[job_pods[key]]]: []})\n",
    "            except Exception as e:\n",
    "                import traceback\n",
    "                trace = traceback.format_exc()\n",
    "                print(trace)\n",
    "                if cluster_type == \"cloud\":\n",
    "                    print('cloud')\n",
    "                else:\n",
    "                    print('onprem')\n",
    "                \n",
    "    if not jobs['arrival']:\n",
    "        print(\"No job arrival times logged!\")\n",
    "    \n",
    "    #print(f'nodes {nodes}')\n",
    "    print(jobs)\n",
    "    modified_arrival = [a for a in jobs['arrival'] if a]\n",
    "    #min_arrival = min(modified_arrival)\n",
    "    min_arrival = min(jobs['arrival'])\n",
    "    #print(f'minarrival {min_arrival}')\n",
    "    modified_submission = [s for s in jobs['submission_time'] if s]\n",
    "    #min_submission = min(modified_submission)\n",
    "    min_submission = min(jobs['submission_time'])\n",
    "    #print(f'minsubmission {min_submission}')\n",
    "    min_arrival = min_submission\n",
    "    #min_arrival = min(jobs['submission_time'])\n",
    "    jobs['arrival'] = [i - min_arrival for i in jobs['arrival']]\n",
    "    jobs['submission_time'] = [i - min_arrival for i in jobs['submission_time']]\n",
    "    jobs['start'] = [i - min_arrival for i in jobs['start']]\n",
    "    #jobs['arrival'] = np.array(jobs['arrival'])\n",
    "    jobs['num_gpus'] =  np.array(jobs['num_gpus'])\n",
    "    \n",
    "    hyperparameters = submission_df['hyperparameters']\n",
    "\n",
    "    for k, v in hyperparameters.items():\n",
    "        jobs[k] = v\n",
    "\n",
    "    sweep_metrics = sweep_df[str(run_id)]\n",
    "    jobs[\"varying_values\"] = sweep_df[\"varying_values\"].keys()\n",
    "    jobs[\"fixed_values\"] = sweep_df[\"fixed_values\"].keys()\n",
    "\n",
    "    for k, v in sweep_metrics.items():\n",
    "        jobs[k + \"_sweep\"] = v\n",
    "    \n",
    "    with open(\"wait\" + str(submission_df['hyperparameters']['wait_time']) + \"uni\" + str(submission_df['hyperparameters']['uniform_arrival']) + \".pkl\", 'wb') as file:\n",
    "        pickle.dump(jobs, file)\n",
    "\n",
    "    return jobs, len(all_nodes), hyperparameters\n",
    "\n",
    "def parse_jobs_df(event_number=logs, avoid_congestion=False):\n",
    "    #test = log_jobs.retrieve_events_df(event_number=logs, avoid_congestion=False, only_dict=False)\n",
    "    #print(test)\n",
    "    #print(len(test))\n",
    "    #TODO: Move log_jobs from local to remote repo\n",
    "    events_dfs, sweep_df = log_jobs.retrieve_events_df(event_number=logs, avoid_congestion=False, only_dict=False)\n",
    "    #cluster_event_data_df, submission_data_df, sweep_data_df\n",
    "    columns=['idx', 'runtime', 'arrival', 'num_gpus', 'allocated_gpus', 'allocated_gpus_real', 'start', 'instance_type', 'node_index', 'node', 'cpus', 'submission_time', 'wait_times', 'is_local']\n",
    "    runs = {}\n",
    "    runs_list = []\n",
    "    for run_id, events_df in events_dfs.items():\n",
    "        cluster_event_df, submission_df, cloud_log_list = events_df\n",
    "        display(submission_df)\n",
    "        estimated_runtimes = []\n",
    "        for job in submission_df:\n",
    "            if job == 'hyperparameters':\n",
    "                continue\n",
    "            #estimated_runtimes.append((job, submission_df[job][\"job_duration\"]))\n",
    "            estimated_runtimes.append(submission_df[job][\"job_duration\"])\n",
    "            #print(job)\n",
    "            #print(submission_df[job][\"job_duration\"])\n",
    "        print(estimated_runtimes)\n",
    "        onprem_df, cloud_df = cluster_event_df\n",
    "        try:\n",
    "            run, _, _ = parse_job_df(cluster_event_df=cluster_event_df, submission_df=submission_df, sweep_df=sweep_df, avoid_congestion=False, columns=columns, run_id=run_id, cloud_log_list=cloud_log_list)\n",
    "            runs[run_id] = pd.Series(run)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            trace = traceback.format_exc()\n",
    "            print(trace)\n",
    "    runs_df = pd.DataFrame.from_dict(runs)\n",
    "    runs_df = runs_df.transpose()\n",
    "    return runs_df\n",
    "\n",
    "jobs_df = parse_jobs_df(event_number=logs, avoid_congestion=False)\n",
    "#jobs_df = jobs_df[0:2]\n",
    "display(jobs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea33d423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'workload_type' in jobs_df: \n",
    "    print(jobs_df['workload_type'][0])\n",
    "print(len(jobs_df['runtime'][0]))\n",
    "print(len(jobs_df['is_local'][0]))\n",
    "print(sum(jobs_df['is_local'][0]))\n",
    "print(len(jobs_df['arrival'][0]))\n",
    "print(len(jobs_df['start'][0]))\n",
    "print(len(jobs_df['submission_time'][0]))\n",
    "print(len(jobs_df['runtime'][0]))\n",
    "print(len(jobs_df['node'][0]))\n",
    "print(len(jobs_df['node_index'][0]))\n",
    "print(len(jobs_df['instance_type'][0]))\n",
    "print(len(jobs_df['allocated_gpus'][0]))\n",
    "print(len(jobs_df['allocated_gpus_real'][0]))\n",
    "\n",
    "print(sorted(jobs_df['runtime'][0]))\n",
    "print(jobs_df['is_local'][0])\n",
    "print(jobs_df['arrival'][0])\n",
    "print(jobs_df['start'][0])\n",
    "print(jobs_df['submission_time'])\n",
    "print(jobs_df['runtime'])\n",
    "print(jobs_df['node_index'])\n",
    "print(jobs_df['node'][0])\n",
    "print(jobs_df['instance_type'][0])\n",
    "print(jobs_df['allocated_gpus'][0])\n",
    "print(jobs_df['allocated_gpus_real'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9682cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jobs_df['arrival_mask'] = jobs_df['start'].apply(lambda x: [0 if not i else 1 for i in x])\n",
    "jobs_df['arrival_mask'] = jobs_df['is_local']#.apply(lambda x: [0 if not i else 1 for i in x])\n",
    "jobs_df['onprem_mask'] = jobs_df['arrival_mask']\n",
    "\n",
    "# CLIP WAITS\n",
    "\n",
    "def cloud_wait_unclipped(row): \n",
    "    cloud_wait = [row['wait_times'][i] for i, n in enumerate(row['arrival_mask']) if n == 0]\n",
    "    return cloud_wait\n",
    "jobs_df['cloud_wait_unclipped'] = jobs_df.apply(cloud_wait_unclipped, axis=1)\n",
    "\n",
    "def clipped_wait(row): \n",
    "    k8s_scheduling_waiting_constant = 1 #wait_time_2\n",
    "    onprem_wait = [row['wait_times'][i] for i, n in enumerate(row['arrival_mask']) if n == 1]\n",
    "    cloud_wait = [k8s_scheduling_waiting_constant + row['wait_time'] for i, n in enumerate(row['arrival_mask']) if n == 0]\n",
    "    new_wait = onprem_wait + cloud_wait\n",
    "    return new_wait\n",
    "\n",
    "jobs_df['wait_times'] = jobs_df.apply(clipped_wait, axis=1)\n",
    "\n",
    "def cloud_wait(row): \n",
    "    k8s_scheduling_waiting_constant = 1 #wait_time_2\n",
    "    cloud_wait = [k8s_scheduling_waiting_constant + row['wait_time'] for i, n in enumerate(row['arrival_mask']) if n == 0]\n",
    "    return cloud_wait\n",
    "jobs_df['cloud_wait'] = jobs_df.apply(cloud_wait, axis=1)\n",
    "\n",
    "\n",
    "def onprem_wait(row): \n",
    "    k8s_scheduling_waiting_constant = 1 #wait_time_2\n",
    "    onprem_wait = [row['wait_times'][i] for i, n in enumerate(row['arrival_mask']) if n == 1]\n",
    "    return onprem_wait\n",
    "\n",
    "jobs_df['onprem_wait'] = jobs_df.apply(onprem_wait, axis=1)\n",
    "\n",
    "# COMPUTE METRICS\n",
    "\n",
    "jobs_df['avg_wait'] = jobs_df['wait_times'].apply(lambda x: sum(x)/len(x))\n",
    "jobs_df['avg_runtime'] = jobs_df['runtime'].apply(lambda x: sum(x)/len(x))\n",
    "\n",
    "def compute_total_time(row):\n",
    "    total_time = [row['wait_times'][i] + row['runtime'][i] for i in range(len(row['wait_times']))]\n",
    "    return total_time\n",
    "\n",
    "\n",
    "jobs_df['total_time'] = jobs_df.apply(compute_total_time, axis=1)\n",
    "\n",
    "def compute_completion_time(row):\n",
    "    # TODO: Submission time is time submitted to starburst \n",
    "    #completion_time = [row['total_time'][i] + row['submission_time'][i] for i in range(len(row['wait_times']))]\n",
    "    completion_time = [row['total_time'][i] + row['arrival'][i] for i in range(len(row['wait_times']))]\n",
    "    return completion_time\n",
    "\n",
    "jobs_df['completion_time'] = jobs_df.apply(compute_completion_time, axis=1)\n",
    "#jobs_df['avg_jct'] = jobs_df['total_time'].apply(lambda x: sum(x)/len(x))\n",
    "\n",
    "def compute_avg_jct(row):\n",
    "    arrival_times = row['arrival']\n",
    "    run_time = row['runtime']\n",
    "    wait_time = row['wait_times']\n",
    "    resources = row['num_gpus']\n",
    "    starts = row['start']\n",
    "    idxes = row['idx']\n",
    "    is_locals = row['is_local']\n",
    "    sort_zip = sorted(zip(idxes, arrival_times, run_time, starts, resources, wait_time))\n",
    "    \n",
    "    #start = sort_zip[10][1]\n",
    "    #end = sort_zip[-10][1]\n",
    "    \n",
    "    total_used_space = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for l in sort_zip:\n",
    "        #job_idx = l[0]\n",
    "        #job_arrival = l[1]\n",
    "        job_runtime = l[2]\n",
    "        job_wait_time = l[1]\n",
    "        #job_start = l[3]\n",
    "        job_gpus = l[4]\n",
    "        wait_time = l[5]\n",
    "        #inter_start = max(job_start, start)\n",
    "        #inter_end = min(job_start + job_runtime, end)\n",
    "        #if inter_end >= inter_start:\n",
    "        #    total_used_space+= job_gpus * (inter_end - inter_start)\n",
    "        total_time += job_runtime\n",
    "        total_time += wait_time\n",
    "        \n",
    "    jct = total_time/len(sort_zip)#total_used_space/(row['cluster_size']*4*row['gpus_per_node']*(end-start))\n",
    "    jct = jct/3600\n",
    "    return jct\n",
    "jobs_df['avg_jct'] = jobs_df.apply(compute_avg_jct, axis=1)\n",
    "\n",
    "def compute_cluster_utilization(row):\n",
    "    arrival_times = row['arrival']\n",
    "    run_time = row['runtime']\n",
    "    resources = row['num_gpus']\n",
    "    starts = row['start']\n",
    "    idxes = row['idx']\n",
    "    is_locals = row['is_local']\n",
    "    sort_zip = sorted(zip(idxes, arrival_times, run_time, starts, resources, is_locals))\n",
    "    \n",
    "    start = sort_zip[0][1]\n",
    "    end = sort_zip[-1][1]\n",
    "    \n",
    "    total_used_space = 0\n",
    "    for l in sort_zip:\n",
    "        job_idx = l[0]\n",
    "        job_arrival = l[1]\n",
    "        job_runtime = l[2]\n",
    "        job_start = l[3]\n",
    "        job_gpus = l[4]\n",
    "        is_local = l[5]\n",
    "        if is_local==1:\n",
    "            inter_start = max(job_start, start)\n",
    "            inter_end = min(job_start + job_runtime, end)\n",
    "            #import pdb; pdb.set_trace()\n",
    "            if inter_end >= inter_start:\n",
    "                total_used_space+= job_gpus * (inter_end - inter_start)\n",
    "    cluster_utilization = total_used_space/(row['cluster_size']*4*row['gpus_per_node']*(end-start))\n",
    "    #import pdb; pdb.set_trace()\n",
    "    return cluster_utilization\n",
    "        \n",
    "#     # TODO: Remove previous arrival and \n",
    "#     print(row['arrival'])\n",
    "#     surface_area = [row['runtime'][i] * row['num_gpus'][i] for i in range(len(row['runtime']))]\n",
    "#     utilized_surface_area = sum(surface_area)\n",
    "#     total_surface_area = (max(row['completion_time']) - min(row['submission_time'])) * (row['gpus_per_node'] * 1) #row['cluster_size'])\n",
    "#     cluster_utilization = utilized_surface_area/total_surface_area\n",
    "#     return cluster_utilization\n",
    "\n",
    "jobs_df['cluster_utilization'] = jobs_df.apply(compute_cluster_utilization, axis=1)\n",
    "\n",
    "def compute_system_utilization(row):\n",
    "    arrival_times = row['arrival']\n",
    "    run_time = row['runtime']\n",
    "    resources = row['num_gpus']\n",
    "    starts = row['start']\n",
    "    idxes = row['idx']\n",
    "    is_locals = row['is_local']\n",
    "    sort_zip = sorted(zip(idxes, arrival_times, run_time, starts, resources, is_locals))\n",
    "    \n",
    "    start = sort_zip[0][1]\n",
    "    end = sort_zip[-1][1]\n",
    "    \n",
    "    total_used_space = 0\n",
    "    for l in sort_zip:\n",
    "        job_idx = l[0]\n",
    "        job_arrival = l[1]\n",
    "        job_runtime = l[2]\n",
    "        job_start = l[3]\n",
    "        job_gpus = l[4]\n",
    "        is_local = l[5]\n",
    "        inter_start = max(job_start, start)\n",
    "        inter_end = min(job_start + job_runtime, end)\n",
    "        if inter_end >= inter_start:\n",
    "            total_used_space += job_gpus * (inter_end - inter_start)\n",
    "    system_utilization = total_used_space/(row['cluster_size']*4*row['gpus_per_node']*(end-start))\n",
    "    \n",
    "    return system_utilization\n",
    "\n",
    "jobs_df['system_utilization'] = jobs_df.apply(compute_system_utilization, axis=1)\n",
    "\n",
    "        \n",
    "#     # TODO: Remove previous arrival and \n",
    "#     print(row['arrival'])\n",
    "#     surface_area = [row['runtime'][i] * row['num_gpus'][i] for i in range(len(row['runtime']))]\n",
    "#     utilized_surface_area = sum(surface_area)\n",
    "#     total_surface_area = (max(row['completion_time']) - min(row['submission_time'])) * (row['gpus_per_node'] * 1) #row['cluster_size'])\n",
    "#     cluster_utilization = utilized_surface_area/total_surface_area\n",
    "#     return cluster_utilization\n",
    "\n",
    "\n",
    "#def compute_system_utilization(row):\n",
    "    # TODO: Compute this value correctly\n",
    "    #return system_utilization\n",
    "\n",
    "#jobs_df['cluster_utilization'] = jobs_df.apply(compute_cluster_utilization, axis=1)\n",
    "GCP_PRICES = {\n",
    "    \"e2-medium\": 0.038795,\n",
    "    \"e2-standard-8\": 0.31036,\n",
    "    \"unknown\": 0.038795,\n",
    "    \"n1-standard-96\": 4.56 \n",
    "}\n",
    "\n",
    "\n",
    "def compute_total_cost(row):\n",
    "    run_time = row['runtime']\n",
    "    resources = row['num_gpus']\n",
    "    idxes = row['idx']\n",
    "    is_locals = row['is_local']\n",
    "    sort_zip = sorted(zip(idxes, run_time, resources, is_locals))\n",
    "\n",
    "    \n",
    "    total_cloud_cost = 0\n",
    "    for l in sort_zip:\n",
    "        job_idx = l[0]\n",
    "        job_runtime = l[1]\n",
    "        job_gpus = l[2]\n",
    "        is_local = l[3]\n",
    "        if is_local==0:\n",
    "            total_cloud_cost += job_runtime * job_gpus\n",
    "\n",
    "    return total_cloud_cost/3600\n",
    "    # TODO: Compute this value correctly\n",
    "    # Get all cloud runtimes + submit \n",
    "#     total_time = [row['runtime'][i] * row['num_gpus'][i] * (1 - row['arrival_mask'][i]) * GCP_PRICES[row['instance_type'][i]] for i in range(len(row['arrival_mask']))]\n",
    "#     return sum(total_time)\n",
    "\n",
    "jobs_df['total_cloud_cost'] = jobs_df.apply(compute_total_cost, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609cf673",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df\n",
    "jobs_df['node'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55400294",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def index_mapping(jobs=None, gpus_per_node=8, resource='cpu'):#gpu_value=None):\n",
    "    '''\n",
    "    Implement greedly algorithm with heap to place jobs to free resource indicies\n",
    "    \n",
    "    Specify which resource (e.g. gpu, cpu) to use fitting jobs to indices\n",
    "    \n",
    "    (1) Add all jobs to queue, then greedily assign indicies \n",
    "    (2) Have priority queue for each node with \"Free indices\" sorted by index number \n",
    "    (3) Iterate over all start times \n",
    "\n",
    "    TODO: Fix 1-off CPU index error \n",
    "    TODO: Don't let any job_idx values to be -1, and ensure it starts at node 1\n",
    "    TODO: Verify allocated_nodes\n",
    "    TODO: Determine how parsing changes between http_info and default values \n",
    "    TODO: Verify arrival value is accurate\n",
    "    TODO: Create a list of times that include all arrival times and completion times in the same list in numerical order \n",
    "    '''\n",
    "    '''\n",
    "    if gpu_jobs: \n",
    "        gpu_value = 'allocated_gpus_index'\n",
    "    else: \n",
    "        gpu_value = 'allocated_gpus'\n",
    "    '''\n",
    "    workload = 'gpu'\n",
    "    if 'workload_type' in jobs: \n",
    "        print('workload type')\n",
    "        print(jobs['workload_type'])\n",
    "        workload = jobs['workload_type']\n",
    "    print('gpus')\n",
    "    print(jobs['num_gpus'])\n",
    "    print('cpus list')\n",
    "    print(jobs['cpus'])\n",
    "    #import pdb; pdb.set_trace()\n",
    "    GPUS_PER_NODE = gpus_per_node\n",
    "    allocated_nodes = jobs['node_index']\n",
    "    \n",
    "    \n",
    "    #if resource == 'gpu':\n",
    "    if workload == 'gpu':\n",
    "        cpus = jobs['num_gpus']\n",
    "    else: \n",
    "        cpus = jobs['cpus']\n",
    "    #gpus = jobs['gpus']\n",
    "    nodes = set(allocated_nodes)\n",
    "    \n",
    "    node_jobs ={}\n",
    "    node_queues = {}\n",
    "    for node in nodes:\n",
    "        node_queues[node] = [i + 1 for i in range(GPUS_PER_NODE)]\n",
    "        node_jobs[node] = []\n",
    "\n",
    "    global_queue = [] # Queue sorted on end time -- earliest to latest end time\n",
    "    job_id_to_index = {} \n",
    "\n",
    "    for i in range(len(jobs['arrival'])):\n",
    "        #Remove values from queue\n",
    "        #import pdb; pdb.set_trace()\n",
    "        job_id = jobs['idx'][i]\n",
    "        job_id_to_index[job_id] = i\n",
    "        job_node = jobs['node_index'][i]\n",
    "        #if resource == 'gpu':\n",
    "        if workload == 'gpu':\n",
    "            job_cpu_size = jobs['num_gpus'][i]\n",
    "        else: \n",
    "            job_cpu_size = jobs['cpus'][i]\n",
    "        job_arrival = jobs['arrival_plot'][i]\n",
    "        job_runtime = jobs['runtime'][i]\n",
    "        \n",
    "        while global_queue and global_queue[0][0] <= job_arrival: \n",
    "            end_time, end_job_id = heapq.heappop(global_queue)\n",
    "            released_index = job_id_to_index[end_job_id]\n",
    "            for released_node in jobs['allocated_gpus'][released_index]: \n",
    "                released_cpus = jobs['allocated_gpus'][released_index][released_node]\n",
    "                released_node_queue = node_queues[released_node]\n",
    "                try:\n",
    "                    node_jobs[released_node].remove(end_job_id)\n",
    "                except:\n",
    "                    #import pdb; pdb.set_trace()\n",
    "                    print(\"Job Id not found\")\n",
    "                    print(end_job_id)\n",
    "                    print(node_jobs[released_node])\n",
    "                    continue\n",
    "                for cpu in released_cpus:\n",
    "                    heapq.heappush(released_node_queue, cpu)\n",
    "\n",
    "        heapq.heappush(global_queue, (job_arrival + job_runtime, job_id))\n",
    "        job_allocated_cpus = []\n",
    "        node_queue = node_queues[job_node]\n",
    "        node_jobs[job_node].append(job_id)\n",
    "    \n",
    "        print(f'job_cpu_size {job_cpu_size}')\n",
    "        try:\n",
    "            for j in range(job_cpu_size):\n",
    "                cpu_index = heapq.heappop(node_queue)\n",
    "                job_allocated_cpus.append(cpu_index)\n",
    "        except:\n",
    "            print(\"not enough cpus to fit jobs\")\n",
    "            print(node_queue)\n",
    "            print(job_allocated_cpus)\n",
    "        \n",
    "        print(f'allocated resources -- cpus or gpus: {job_allocated_cpus}')\n",
    "\n",
    "        jobs['allocated_gpus'][i] = {job_node: job_allocated_cpus}\n",
    "        #print(jobs['allocated_gpus'][i])\n",
    "        #import pdb; pdb.set_trace()\n",
    "\n",
    "    return jobs\n",
    "\n",
    "def generate_gantt_chart(row=None, gpus_per_node=None, ratio=None, scale=None, gpu_jobs=None):\n",
    "    '''\n",
    "    Create \"threads index\" that track CPU jobs running together\n",
    "    #TODO: Modify function to plot CPU jobs --> number of jobs concurrently running may exceed cpu count\n",
    "    #TODO: Plot color based on job start time and not job index\n",
    "    #TODO: Determine why jobs dissapaear when strings labels are used for nodes\n",
    "    #TODO: Label each row of jobs with the name of the node -- not just integers \n",
    "    #TODO: Plot cloud values in a separate plot\n",
    "    '''\n",
    "    workload = \"gpu\"\n",
    "    if 'workload_type' in row: \n",
    "        workload = row['workload_type']\n",
    "        \n",
    "    #if 'workload_type' in row and row['workload_type'] == 'cpu': \n",
    "    if workload == 'cpu':\n",
    "        gpus_per_nodes = 2\n",
    "        \n",
    "    graphs = ['cloud', 'onprem']\n",
    "    for graph in graphs:\n",
    "        #import pdb; pdb.set_trace()\n",
    "        save=False; path=None; subplt=None; plt_index=None; tag=None; plot_sweep=False\n",
    "        varying_values = row['varying_values']\n",
    "        tag = \"\"\n",
    "\n",
    "        count = 0 \n",
    "        for value in varying_values: \n",
    "            tag += str(value)\n",
    "            tag += \":\"\n",
    "            if isinstance(row[value], str) and len(row[value]) < 50: \n",
    "                tag += str(row[value])\n",
    "            tag += \" | \"\n",
    "            count += 1\n",
    "            if count % 5 == 0: \n",
    "                tag += '\\n'\n",
    "                \n",
    "        gpu_value = 'allocated_gpus'#_real'\n",
    "        \n",
    "        '''\n",
    "        if 'workload_type' in row and row['workload_type'] == 'cpu': \n",
    "            gpu_value = 'allocated_gpus'\n",
    "        elif gpu_jobs: \n",
    "            gpu_value = 'allocated_gpus_real'\n",
    "        else: \n",
    "            gpu_value = 'allocated_gpus'\n",
    "        '''\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        #GPUS_PER_NODE = row['cpus_per_node']\n",
    "        GPUS_PER_NODE = gpus_per_node\n",
    "        \n",
    "        '''\n",
    "        if 'workload_type' in row: \n",
    "            print('workload type')\n",
    "            print(row['workload_type'])\n",
    "            row = index_mapping(row, GPUS_PER_NODE, row['workload_type'])\n",
    "        else: \n",
    "            row = index_mapping(row, GPUS_PER_NODE, 'gpu')\n",
    "        '''\n",
    "        \n",
    "        row = index_mapping(row, GPUS_PER_NODE, 'gpu')\n",
    "        \n",
    "        '''\n",
    "        if 'workload_type' in row and row['workload_type'] == 'cpu':\n",
    "            print(\"mapped indices\")\n",
    "            row = index_mapping(row, GPUS_PER_NODE, 'cpu')\n",
    "        #if not gpu_jobs: \n",
    "        elif graph == 'cloud':\n",
    "            GPUS_PER_NODE = 32\n",
    "            #print(row['allocated_gpus'])\n",
    "            row = index_mapping(row, GPUS_PER_NODE, 'gpu')\n",
    "            #print(row['allocated_gpus'])\n",
    "        #import pdb; pdb.set_trace()\n",
    "        #if row['workload_type'] == 'cpu':\n",
    "        '''\n",
    "\n",
    "        \n",
    "        #print(\"allocated_gpus_real\")\n",
    "        #print(row['allocated_gpus_real'])\n",
    "        print(\"allocated_gpus\")\n",
    "        print(row['allocated_gpus'])\n",
    "        \n",
    "        NUM_COLORS = len(row['idx'])\n",
    "        cm = plt.get_cmap('gist_rainbow')\n",
    "        colors = [cm(1. * i / NUM_COLORS) for i in range(NUM_COLORS)]\n",
    "\n",
    "        y_lim_min = 1000\n",
    "        y_lim_max = -1000\n",
    "        num_nodes = row['cluster_size'] + row['cloud_cluster_nodes']\n",
    "\n",
    "        total_gpus = num_nodes * GPUS_PER_NODE #GPUs equivalent to CPUs -- if no GPU's then GPUS_PER_NODE reflects cpus\n",
    "        segment_height_list = {}\n",
    "        gpu_indices = {}\n",
    "        gpu_rows = set()\n",
    "        node_name = \"\"\n",
    "\n",
    "        # TODO: Plot infinite cloud spillover \n",
    "        try: \n",
    "            #import pdb; pdb.set_trace()\n",
    "            for j_idx in range(len(row['idx'])):\n",
    "                allocated_gpus = row[gpu_value][j_idx]\n",
    "                \n",
    "                #if graph == 'cloud':\n",
    "                #    allocated_gpus = row['allocated_gpus'][j_idx]\n",
    "                \n",
    "                #print(allocated_gpus)\n",
    "                #print(allocated_gpus)\n",
    "                #segment = (row['arrival'][j_idx],\n",
    "                #            row['arrival'][j_idx] + row['runtime'][j_idx], j_idx)\n",
    "                #segment = (row['submission_time'][j_idx],\n",
    "                #            row['submission_time'][j_idx] + row['runtime'][j_idx], j_idx)\n",
    "                segment = (row['arrival_plot'][j_idx],\n",
    "                            row['arrival_plot'][j_idx] + row['runtime'][j_idx], j_idx)\n",
    "\n",
    "                node_name = row['node'][j_idx]\n",
    "                if graph == 'onprem' and node_name == 'cloud': \n",
    "                    continue\n",
    "                elif graph == 'cloud' and node_name != 'cloud':\n",
    "                    continue\n",
    "                \n",
    "                print(f'j_idx {j_idx}')\n",
    "                \n",
    "                #if graph == 'cloud' and node_name == 'cloud':\n",
    "                #    print(allocated_gpus)\n",
    "                \n",
    "                for node_idx in allocated_gpus.keys():\n",
    "                    for node_gpu_idx in allocated_gpus[node_idx]:\n",
    "                        if graph == 'cloud': \n",
    "                            gpu_idx = node_gpu_idx\n",
    "                            #print(gpu_idx)\n",
    "                        else: \n",
    "                            gpu_idx = total_gpus - (GPUS_PER_NODE * node_idx + node_gpu_idx)\n",
    "                        print(f'gpu_idx {gpu_idx}')\n",
    "                        \n",
    "                        gpu_rows.add(gpu_idx)\n",
    "                        #print(node_gpu_idx)\n",
    "                        #print(gpu_rows)\n",
    "                        gpu_indices[node_name] = [gpu_idx]\n",
    "                        y_lim_min = min(y_lim_min, gpu_idx) #- 8)#if gpu_idx > 0 else gpu_index - 8)\n",
    "                        \n",
    "                        y_lim_max = max(y_lim_max, gpu_idx + 1) #+ 8)\n",
    "                        if graph == 'cloud':\n",
    "                            y_lim_max = GPUS_PER_NODE\n",
    "\n",
    "                        plt.barh(gpu_idx,\n",
    "                                    width=row['runtime'][j_idx],\n",
    "                                    edgecolor='black',\n",
    "                                    height=1.0,\n",
    "                                    left=segment[0],\n",
    "                                    align='edge',\n",
    "                                    color=colors[row['idx'][j_idx]] if row['idx'][j_idx] < len(colors) else None,\n",
    "                                    alpha = 0.5)    \n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            t = traceback.format_exc()\n",
    "            print(t)\n",
    "            print(e)\n",
    "\n",
    "        for i in range(total_gpus + 1):\n",
    "            multiplier = math.ceil(num_nodes / 32)\n",
    "            if (i + 1) % GPUS_PER_NODE == 1:\n",
    "                plt.axhline(y=i + 1, linewidth=3 / multiplier, color='black')\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        max_arrival = max(row['arrival_plot'])\n",
    "        completions = [row['arrival_plot'][i] + row['runtime'][i] for i in range(len(row['arrival_plot']))]\n",
    "        max_completion = max(completions)\n",
    "\n",
    "        x_lim_max = max_completion\n",
    "        last_job_time = max(row['completion_time'])\n",
    "        #print(last_job_time)\n",
    "        #26913.0\n",
    "        #18405.78506708145\n",
    "        last_job_time= 1000#18405.78506708145#26913\n",
    "        dim=(y_lim_min, y_lim_max, 0, last_job_time)\n",
    "        bottom, top, left, right = dim\n",
    "        plt.ylim(bottom=bottom, top=top)\n",
    "        plt.xlim(left=left, right=right)\n",
    "        plt.axvline(x=max_arrival, color='brown', linewidth=0.75)\n",
    "        plt.xlabel('Time (hrs)')\n",
    "        plt.ylabel('Nodes ')\n",
    "        #if graph == 'cloud'\n",
    "        plt.title(str(tag))\n",
    "        if graph == 'cloud':\n",
    "            plt.title(f'Cloud {workload} Jobs')\n",
    "        elif graph == 'onprem':\n",
    "            plt.title(f'Onprem {workload} Jobs')\n",
    "        #plt.title(graph)\n",
    "\n",
    "        gpu_labels = sorted([(v, k) for k, v in gpu_indices.items()])\n",
    "        ticks = [label[0] for label in gpu_labels]\n",
    "        ticks = np.array(ticks)\n",
    "        ticks = ticks.flatten()\n",
    "        labels = [label[1] for label in gpu_labels]\n",
    "        labels = np.array(labels)\n",
    "        labels = labels.flatten()\n",
    "        plt.yticks(ticks)\n",
    "        labels = [i for i in range(len(labels))]\n",
    "        ax.set_yticklabels(labels)\n",
    "        new_labels = {}\n",
    "        node_count = 0\n",
    "        #for k, v in labels.items():\n",
    "            #new_labels[node_count] = k #node_count\n",
    "            #node_count += 1\n",
    "            #new_labels.append(node_count)\n",
    "        #labels = {1.0: 'High', 0.0: 'Medium', -1.0: 'Low'}\n",
    "        #ax.set_yticks(list(labels.keys()))\n",
    "        #ax.set_yticks(list(new_labels.keys()))\n",
    "        plt.rcParams.update({'font.size': 20})\n",
    "        plt.tick_params(axis='y', which='both', bottom=False, top=False, labelbottom=False, right=False, left=False, labelleft=False)\n",
    "        ax.set_ylabel('')\n",
    "        \n",
    "        def divide(x, pos):\n",
    "            return '{}'.format(round(x / 3600, 1))\n",
    "\n",
    "        # Set the formatter\n",
    "        import matplotlib.ticker as ticker\n",
    "        formatter = ticker.FuncFormatter(divide)\n",
    "        ax.xaxis.set_major_formatter(formatter)\n",
    "        \n",
    "        if save:\n",
    "            if path: \n",
    "                plt.savefig(path)\n",
    "                plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "        \n",
    "def remap_cloud_arrival(row):\n",
    "    new_arrival = [row['start'][i] if row['is_local'][i] == 1 else row['arrival'][i] for i in range(len(row['arrival']))]\n",
    "    #new_arrival = [1 if row['is_local'] == 1 else 0 for i in range(len(row['arrival']))]\n",
    "    return new_arrival\n",
    "\n",
    "jobs_df['arrival_plot'] = jobs_df.apply(remap_cloud_arrival, axis=1)\n",
    "print(list(enumerate(jobs_df['arrival_plot'][0])))\n",
    "#print(jobs_df['is_local'][0])\n",
    "print('start times')\n",
    "print(jobs_df['start'][0])\n",
    "print(jobs_df['submission_time'][0])\n",
    "schedule_time = [jobs_df['start'][0][i] - jobs_df['submission_time'][0][i] for i in range(len(jobs_df['start'][0]))]\n",
    "print(\"pod scheduling time (seconds)\")\n",
    "print(schedule_time)\n",
    "print(\"run locally (1=local, 0=cloud)\")\n",
    "print(jobs_df['is_local'][0])\n",
    "print(\"allocated_gpus_real\")\n",
    "print(jobs_df['allocated_gpus_real'][0])\n",
    "print(\"allocated_gpus\")\n",
    "print(jobs_df['allocated_gpus'][0])\n",
    "print(jobs_df['arrival'][0])\n",
    "print(\"IDs\")\n",
    "print(jobs_df['idx'][0])\n",
    "print(\"RUNTIME\")\n",
    "print(jobs_df['runtime'][0])\n",
    "print(\"VERIFYING\")\n",
    "print(sorted(jobs_df['arrival'][0]))\n",
    "\n",
    "for j in range(len(jobs_df)):\n",
    "    cloud_time = [jobs_df['runtime'][j][i] for i in range(len(jobs_df['runtime'][j])) if jobs_df['is_local'][j][i] == 0  ]\n",
    "    print(\"cloud runtimes (seconds)\")\n",
    "    print(cloud_time)\n",
    "    onprem_time = [jobs_df['runtime'][j][i] for i in range(len(jobs_df['runtime'][j])) if jobs_df['is_local'][j][i] == 1  ]\n",
    "    print(\"onprem runtimes (seconds)\")\n",
    "    print(onprem_time)\n",
    "\n",
    "for j in range(len(jobs_df)):\n",
    "    total_job_arrival = len(jobs_df['arrival'][j])\n",
    "    total_job_submission = len(jobs_df['start'][j])\n",
    "    total_job_completion = len(jobs_df['completion_time'][j])\n",
    "    print(f'{j} {total_job_arrival} {total_job_submission} {total_job_completion}')\n",
    "gpus_per_node = 8 #TODO: Parse this value from the job\n",
    "ratio = (1, 1)\n",
    "scale = 1\n",
    "\n",
    "jobs_df.apply(generate_gantt_chart, axis=1, args=(gpus_per_node, ratio, scale, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ceeda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_starburst_log(event_number=logs):\n",
    "    log = log_jobs.retrieve_log(event_number=logs)\n",
    "    return log \n",
    "\n",
    "log_df = parse_starburst_log(event_number=logs)\n",
    "log_df\n",
    "\n",
    "loop_times = []\n",
    "interloop_times = []\n",
    "process_queue_times = []\n",
    "process_event_times = []\n",
    "queue_add_times = []\n",
    "await_times = []\n",
    "times = []\n",
    "events = []\n",
    "\n",
    "for i in range(len(log_df)):\n",
    "    log = log_df[0][i]\n",
    "    parts = log.split('||')\n",
    "    if len(parts) > 1:\n",
    "        log = parts[1]\n",
    "        \n",
    "    if log.find(\"TICK TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        if len(parts) > 8: \n",
    "            time = parts[4]\n",
    "            times.append(float(time))\n",
    "            eventtype = parts[6] + parts[7]\n",
    "            events.append(eventtype)\n",
    "            \n",
    "    if log.find(\"LOOP TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        time = parts[4]\n",
    "        loop_times.append(float(time))\n",
    "        \n",
    "    if log.find(\"INTERLOOP TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        time = parts[4]\n",
    "        interloop_times.append(float(time))\n",
    "        \n",
    "    if log.find(\"PROCESSQUEUE TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        time = parts[4]\n",
    "        process_queue_times.append(float(time))\n",
    "        \n",
    "    if log.find(\"PROCESSEVENT TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        time = parts[4]\n",
    "        process_event_times.append(float(time))\n",
    "    \n",
    "    if log.find(\"QUEUEADD TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        time = parts[4]\n",
    "        queue_add_times.append(float(time))\n",
    "        \n",
    "    if log.find(\"AWAIT TIME (())\") != -1:\n",
    "        parts = log.split(' ')\n",
    "        time = parts[4]\n",
    "        await_times.append(float(time))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=9,figsize=(12,3)) \n",
    "\n",
    "#loop_times = [loop_times[i + 1] - loop_times[i] for i in range(len(loop_times) - 1)]\n",
    "\n",
    "overflows = []\n",
    "addtimes = []\n",
    "ticktimes = []\n",
    "for i in range(len(times)):\n",
    "    time = times[i]\n",
    "    event = events[i]\n",
    "    if event == 'JobAddEvent:Job,':\n",
    "        addtimes.append(time)\n",
    "    if event == 'SchedTick,':\n",
    "        ticktimes.append(time)\n",
    "    if time > 0.6: \n",
    "        overflows.append((time, event))\n",
    "\n",
    "axs[0].set_title('All Event Times', fontsize =10)\n",
    "axs[0].hist(times)\n",
    "axs[0].set_xlabel('Time (sec)')\n",
    "axs[0].set_ylabel('Frequency')\n",
    "\n",
    "axs[1].set_title('Job Add Event Times', fontsize =10)\n",
    "axs[1].hist(addtimes)\n",
    "axs[1].set_xlabel('Time (sec)')\n",
    "axs[1].set_ylabel('Frequency')\n",
    "\n",
    "axs[2].set_title('Sched Tick Event Times', fontsize =10)\n",
    "axs[2].hist(ticktimes)\n",
    "axs[2].set_xlabel('Time (sec)')\n",
    "axs[2].set_ylabel('Frequency')\n",
    "\n",
    "axs[3].set_title('Loop Times', fontsize =10)\n",
    "axs[3].hist(loop_times)\n",
    "axs[3].set_xlabel('Time (sec)')\n",
    "axs[3].set_ylabel('Frequency')\n",
    "\n",
    "axs[4].set_title('Inter Loop Times', fontsize =10)\n",
    "axs[4].hist(interloop_times)\n",
    "axs[4].set_xlabel('Time (sec)')\n",
    "axs[4].set_ylabel('Frequency')\n",
    "\n",
    "axs[5].set_title('Process Queue Times', fontsize =10)\n",
    "axs[5].hist(process_queue_times)\n",
    "axs[5].set_xlabel('Time (sec)')\n",
    "axs[5].set_ylabel('Frequency')\n",
    "\n",
    "axs[6].set_title('Process Event Times', fontsize =10)\n",
    "axs[6].hist(process_event_times)\n",
    "axs[6].set_xlabel('Time (sec)')\n",
    "axs[6].set_ylabel('Frequency')\n",
    "\n",
    "axs[7].set_title('Queue Add Times', fontsize =10)\n",
    "axs[7].hist(queue_add_times)\n",
    "axs[7].set_xlabel('Time (sec)')\n",
    "axs[7].set_ylabel('Frequency')\n",
    "\n",
    "axs[8].set_title('Await Times', fontsize =10)\n",
    "axs[8].hist(queue_add_times)\n",
    "axs[8].set_xlabel('Time (sec)')\n",
    "axs[8].set_ylabel('Frequency')\n",
    "\n",
    "print(process_event_times)\n",
    "print(process_queue_times)\n",
    "print(loop_times)\n",
    "print(interloop_times)\n",
    "print(queue_add_times)\n",
    "print(sum(loop_times)/len(loop_times))\n",
    "\n",
    "add_count = 0 \n",
    "sched_count = 0\n",
    "for t, e in overflows: \n",
    "    if e == 'JobAddEvent:Job,':\n",
    "        add_count += 1\n",
    "    if e == 'SchedTick,':\n",
    "        sched_count += 1\n",
    "\n",
    "#print(add_count)\n",
    "#print(sched_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1933e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(jobs_df)):\n",
    "    print(i)\n",
    "    print(len(jobs_df['is_local'][i]))\n",
    "    print(sum(jobs_df['is_local'][i]))\n",
    "    print(len(jobs_df['arrival'][i]))\n",
    "    print(len(jobs_df['start'][i]))\n",
    "    print(len(jobs_df['submission_time'][i]))\n",
    "    print(len(jobs_df['runtime'][i]))\n",
    "    print(len(jobs_df['allocated_gpus_real'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310e3c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df\n",
    "#print(len(jobs_df['idx'][0]))\n",
    "'''\n",
    "print(jobs_df['is_local'][0][:-18])\n",
    "print(jobs_df['arrival'][0][:-18])\n",
    "print(jobs_df['start'][0][:-18])\n",
    "print(jobs_df['submission_time'][0][:-18])\n",
    "print(jobs_df['runtime'][0][:-18])\n",
    "print(jobs_df['allocated_gpus_real'][0][:-18])\n",
    "'''\n",
    "print(len(jobs_df['is_local'][0]))\n",
    "print(len(jobs_df['arrival'][0]))\n",
    "print(len(jobs_df['start'][0]))\n",
    "print(len(jobs_df['submission_time'][0]))\n",
    "print(len(jobs_df['runtime'][0]))\n",
    "print(len(jobs_df['allocated_gpus_real'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bbd5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jobs_df['total_cloud_cost'])\n",
    "print(jobs_df['avg_jct'])\n",
    "print(jobs_df['cluster_utilization'])\n",
    "\n",
    "jobs_df['completion_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9317035",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in jobs_df['runtime']:\n",
    "    print(i)\n",
    "    print(len(i))\n",
    "\n",
    "for i in jobs_df['arrival_mask']:\n",
    "    print(i)\n",
    "    print(len(i))\n",
    "    \n",
    "for i in jobs_df['onprem_mask']:\n",
    "    print(i)\n",
    "    print(len(i))\n",
    "    \n",
    "for i in jobs_df['num_gpus']:\n",
    "    print(i)\n",
    "    print(len(i))\n",
    "    \n",
    "for i in jobs_df['start']:\n",
    "    print(i)\n",
    "    print(len(i))\n",
    "    \n",
    "for i in jobs_df['instance_type']:\n",
    "    print(i)\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9c7931",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def wait_time_histograms(row):\n",
    "    \"\"\"Plots waiting time for onprem, cloud, and cloud clipped\"\"\"\n",
    "    #import pdb; pdb.set_trace()\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(12,3)) \n",
    "    \n",
    "    axs[0].set_title(\"ONPREM \" + \"wait \" + str(row['wait_time']) +  \" arr \" + str(row['arrival_rate']), fontsize=10)\n",
    "    axs[0].hist(row['onprem_wait'])\n",
    "    if row['onprem_wait'] != []:\n",
    "        average = sum(row['onprem_wait'])/len(row['onprem_wait'])\n",
    "        axs[0].axvline(average, color='r', linewidth=0.5)\n",
    "\n",
    "    axs[1].set_title(\"CLOUD \" + \"wait \" + str(row['wait_time']) +  \" arr \" + str(row['arrival_rate']), fontsize=10)\n",
    "    axs[1].hist(row['cloud_wait'])\n",
    "      \n",
    "    axs[2].set_title(\"CLOUD UNCLIPPED \" + \"wait \" + str(row['wait_time']) +  \" arr \" + str(row['arrival_rate']), fontsize=10)\n",
    "    axs[2].hist(row['cloud_wait_unclipped'])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "jobs_df.apply(wait_time_histograms, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a0496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df\n",
    "jobs_df['allocated_gpus_real'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad96d33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_uuid = list(jobs_df['idx'])[0]\n",
    "job_runtimes = list(jobs_df['runtime'])[0]\n",
    "job_gpus = list(jobs_df['num_gpus'])[0]\n",
    "job_gpus = [int(i) for i in job_gpus]\n",
    "print(job_uuid)\n",
    "print(job_runtimes)\n",
    "print(job_gpus)\n",
    "print(sum(job_runtimes)/len(job_runtimes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2baf853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def set_plotting_setting(ax):\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "    ax.grid(True, which='both')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(True)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    #ax.tick_params(bottom=False, left=False)\n",
    "    ax.tick_params(bottom=True, left=False)\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "label_dict = {\n",
    "    'avg_jct': 'Avg. JCT (sec)',\n",
    "    'cost_mult': '% Cost Savings\\nover No Wait',\n",
    "    'cost_diff': 'Cost Savings\\nover No Wait',\n",
    "    'cluster_size': 'Cluster Size (# Nodes)',\n",
    "    'norm_system_utilization': 'System Utilization',\n",
    "    'system_utilization': 'System Utilization',\n",
    "    'cluster_utilization': 'Cluster Utilization',\n",
    "    'total_cloud_cost': 'Cloud Cost',\n",
    "    'arrival_rate': 'Arrival Rate',\n",
    "    'uniform_arrival': 'Uniform Inter Arrival Time',\n",
    "}\n",
    "\n",
    "legend_dict = {\n",
    "    'constant': 'Constant',\n",
    "    'linear_runtime': 'Runtime',\n",
    "    'linear_cost': 'Cost',\n",
    "    'zero': 'No Wait',\n",
    "    'linear_runtime_filter_cpu': 'Runtime-Preempt-CPU'\n",
    "}\n",
    "\n",
    "def simulator_plotting_fn(df, \n",
    "                          x_axis: str,\n",
    "                          y_axis: list = ['cost_mult', 'avg_jct'],\n",
    "                          df_filter: dict = {},\n",
    "                          baseline_filter: dict={'waiting_policy': 'zero',},\n",
    "                          groupby_values=['waiting_policy', 'waiting_factor'],\n",
    "                          normalize_x_axis=False,\n",
    "                          fig_ratio=(5, 3.5),\n",
    "                          intermediate_df={\"baseline_df\": False, \"merged_df\": False, \"metrics_df\": False, \"groups_df\": False},\n",
    "                          return_df=False):\n",
    "    \"\"\"\n",
    "    Takes a baseline filter to plot metrics of different policies against\n",
    "    \n",
    "    Creates a product of the baseline filter against each existing run\n",
    "        - Values ending with _y are values from the baseline\n",
    "    \n",
    "    Takes a groupby value to compress to set of useful pairs\n",
    "    \"\"\"\n",
    "    \n",
    "    def cost_multiplier(row):\n",
    "        baseline_cost = row['total_cloud_cost_y']\n",
    "        cost = row['total_cloud_cost_x']\n",
    "        if baseline_cost == 0 and cost==0:\n",
    "            return 0\n",
    "        #elif baseline_cost <=10000:\n",
    "            # Small cloud cost for No wait\n",
    "            # Savings over small cloud cost is negligible for organizations.\n",
    "        #    return 0\n",
    "        elif baseline_cost == 0 and cost>0:\n",
    "            return 100\n",
    "        return 100* (1 - (cost/baseline_cost))\n",
    "    \n",
    "    def cost_difference(row):\n",
    "        baseline_cost = row['total_cloud_cost_y']\n",
    "        cost = row['total_cloud_cost_x']\n",
    "        return baseline_cost - cost\n",
    "    \n",
    "    \n",
    "    if isinstance(y_axis, str):\n",
    "        y_axis = [y_axis]\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=len(y_axis), figsize=(fig_ratio[0]*len(y_axis), fig_ratio[1]))\n",
    "    \n",
    "    if len(y_axis) == 1: \n",
    "        if not isinstance(axs, list):\n",
    "            axs = [axs]\n",
    "    #print(axs)\n",
    "    '''\n",
    "    for k,v in df_filter.items():\n",
    "        if isinstance(v, list):\n",
    "            df = df[df[k]==v]\n",
    "    '''\n",
    "\n",
    "    for k,v in df_filter.items():        \n",
    "        mask = df[k].apply(lambda x: x == v)\n",
    "        if isinstance(v, list):\n",
    "            df = df[mask]\n",
    "            \n",
    "    #TODO: get_default = df after mask \n",
    "    baseline_df = df\n",
    "    if intermediate_df['baseline_df']:\n",
    "        print(\"baseline\")\n",
    "        display(baseline_df)\n",
    "    \n",
    "    for k,v in baseline_filter.items():\n",
    "        assert not isinstance(v, list)\n",
    "        baseline_df = baseline_df[baseline_df[k]==v]\n",
    "        #df = df[df[k]!=v]\n",
    "         \n",
    "    # Merge to check for baseline\n",
    "    diff_df = pd.merge(df, baseline_df, left_on=x_axis,right_on=x_axis)\n",
    "    \n",
    "    #TODO: join_baseline = diff_df after merge\n",
    "    if intermediate_df['merged_df']:\n",
    "        print(\"merged\")\n",
    "        display(diff_df)\n",
    "    \n",
    "    if normalize_x_axis:\n",
    "        if x_axis == 'cluster_size':\n",
    "            # Hardcoded in Philly trace, precomputed ahead of time\n",
    "            if df['dataset'].iloc[0] == 'philly':\n",
    "                total_job_volume = 1155998.77277777\n",
    "                job_makespan = 2559.3205555555555\n",
    "            elif df['dataset'].iloc[0] == 'helios':\n",
    "                total_job_volume = 1853756.1241666232\n",
    "                job_makespan = 4651.911388888889\n",
    "            diff_df['norm_system_utilization'] = total_job_volume/(job_makespan*diff_df['cluster_size']*df['gpus_per_node'].iloc[0])\n",
    "            x_axis = 'norm_system_utilization'\n",
    "        elif x_axis == 'arrival_rate' or x_axis == 'uniform_arrival':\n",
    "            # Volume rate => runtime must be in either hours or seconds \n",
    "            '''\n",
    "            Verification: \n",
    "            - Arrival_Rate = VERIFIED ~ error \n",
    "            - Num_gpus = Verified\n",
    "            - Runtime = Verified \n",
    "            '''\n",
    "            #arrival_rate = diff_df['arrival_rate'] # Jobs per second \n",
    "            arrival_rate = 1/df['uniform_arrival'] # uniform_arrival => time between jobs in seconds \n",
    "            #avg_job_volume_rate = arrival_rate * np.mean(df['num_gpus'].iloc[0]* df['runtime'].iloc[0])\n",
    "            df['volume'] = df['num_gpus'] * df['runtime']\n",
    "            #df['avg_job_volume_rate'] = sum(df['volume'])/len(df['volume']) * arrival_rate\n",
    "            df['avg_volume'] = df['volume'].apply(lambda arr: np.mean(arr))\n",
    "            df['avg_job_volume_rate'] = df['avg_volume'] * arrival_rate\n",
    "            #import pdb; pdb.set_trace()\n",
    "            #avg_job_volume_rate = arrival_rate * ([df['num_gpus'] * df['runtime'][i] for i in range(len(df['runtime']))])/len(df['runtime'])\n",
    "            #df['avg_job_volume_rate'] = avg_job_volume_rate\n",
    "            df['verify_mean_runtime'] = np.mean(df['num_gpus'].iloc[0]* df['runtime'].iloc[0])\n",
    "            df['verify_cluster_nodes'] = (df['cluster_size'].iloc[0]*df['gpus_per_node'].iloc[0])\n",
    "            #print(avg_job_volume_rate)\n",
    "            #print(df['cluster_size'].iloc[0])\n",
    "            #print(df['gpus_per_node'].iloc[0])\n",
    "            #print(df['cluster_size'].iloc[0]*df['gpus_per_node'].iloc[0])\n",
    "            #diff_df['norm_system_utilization'] = avg_job_volume_rate/(df['cluster_size'].iloc[0]*df['gpus_per_node'].iloc[0])\n",
    "            #df['cluster_size'] = 1 #TODO: Remove this value\n",
    "            diff_df['norm_system_utilization'] = df['avg_job_volume_rate']/(df['cluster_size']*df['gpus_per_node'])\n",
    "            diff_df['norm_system_utilization'] = pd.to_numeric(diff_df['norm_system_utilization'], errors='coerce')\n",
    "            diff_df['norm_system_utilization'] = diff_df['norm_system_utilization'].round(4)\n",
    "            x_axis = 'norm_system_utilization'\n",
    "            diff_df = diff_df.sort_values('norm_system_utilization')\n",
    "    \n",
    "    \n",
    "    diff_df['cost_mult'] = diff_df.apply(cost_multiplier, axis=1)\n",
    "    diff_df['cost_diff'] = diff_df.apply(cost_difference, axis=1)\n",
    "    \n",
    "    if intermediate_df['metrics_df']:\n",
    "        print(\"merged metrics\")\n",
    "        display(diff_df)\n",
    "        \n",
    "    #TODO: get_baseline = df after normalizing axis\n",
    "    if groupby_values: \n",
    "        groupby_values = [f'{g}_x' for g in groupby_values]\n",
    "    mod_y_axis = [f'{y}_x' if y!='cost_mult' and y!='cost_diff' else y for y in y_axis]\n",
    "    \n",
    "    markers = itertools.cycle(('v', '^','.', 'o', '*',',', '+',)) \n",
    "    groups = diff_df.groupby(groupby_values)\n",
    "    \n",
    "    if intermediate_df['groups_df']:\n",
    "        for name, group in groups:\n",
    "            print(f\"Group: {name}\")\n",
    "            #'cost_mult', 'cost_diff', 'wait_time_x', 'wait_time_y' , 'wait_time_x', 'wait_time_y'\n",
    "            group = group[['cost_mult', 'cost_diff', 'wait_time_x', 'wait_time_y', 'uniform_arrival_sweep_x', 'uniform_arrival_sweep_y', 'total_cloud_cost_x', 'total_cloud_cost_y']]\n",
    "            \n",
    "            display(group)\n",
    "        \n",
    "    for idx, (label, grp) in enumerate(groups):\n",
    "        marker = next(markers)\n",
    "#         if 'waiting_policy' in groupby_values[0]:\n",
    "#             label = [legend_dict[label[0]]] + list(label[1:])\n",
    "#             print(label)\n",
    "        for ax_idx, ax in enumerate(axs):           \n",
    "            grp.plot(x = x_axis, y = mod_y_axis[ax_idx],ylabel=label_dict[y_axis[ax_idx]], \\\n",
    "                     xlabel=label_dict[x_axis], marker=marker, ax = ax, label = label, legend=None)\n",
    "    \n",
    "    if return_df: \n",
    "        return diff_df \n",
    "    for ax in axs:\n",
    "        set_plotting_setting(ax)\n",
    "    #axs[1].set_xlim(right=36, left=20)\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(lines, labels, ncol=len(labels), \\\n",
    "               bbox_to_anchor=(0, 0.92, 1, 0.2),loc='upper center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "'''\n",
    "# TODO: Add spec to increase plot size\n",
    "# TODO: pull the first distribution value\n",
    "# TODO: retrieve sweep value based on the log value \n",
    "# TODO: Clean up ipynb to avoid overwriting jobs_df values\n",
    "'''\n",
    "def generate_system_util_plots(event_number=None, scale=4):\n",
    "    events_dict, sweep_dict = log_jobs.retrieve_events_df(event_number=logs, avoid_congestion=False, only_dict=True)\n",
    "    sweep_dict = OrderedDict(sweep_dict['varying_values'])\n",
    "    \n",
    "    # Make sure baseline filter is one row in dataframe\n",
    "    # Make sure the baseline filter subtracts each corresponding arrival_rate\n",
    "    for sweep_dim in sweep_dict: \n",
    "        for sweep_value in sweep_dict[sweep_dim]:\n",
    "            print(sweep_dim + \"_sweep\")\n",
    "            print(sweep_value)\n",
    "            df = simulator_plotting_fn(jobs_df, \\\n",
    "                                       #x_axis='arrival_rate', \\\n",
    "                                       x_axis='uniform_arrival', \\\n",
    "                                       y_axis=['avg_jct', 'cluster_utilization', 'total_cloud_cost', 'cost_mult', 'cost_diff'], \\\n",
    "                                       baseline_filter= {'wait_time': 2}, \\\n",
    "                                       groupby_values=['wait_time'], \\\n",
    "                                       #'uniform_submission_sweep', \n",
    "                                       #'arrival_rate': 'Arrival Rate',\n",
    "                                       #'uniform_arrival_sweep',\n",
    "                                       normalize_x_axis=True, \\\n",
    "                                       intermediate_df={\"baseline_df\": False, \"merged_df\": True, \"metrics_df\": False, \"groups_df\": True}, \\\n",
    "                                       fig_ratio=(5*scale, 3.5*scale), \\\n",
    "                                       return_df=False)\n",
    "            display(df)\n",
    "            break \n",
    "        break\n",
    "        \n",
    "generate_system_util_plots(event_number=logs, scale=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
